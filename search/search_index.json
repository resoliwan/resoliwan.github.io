{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"README.md I enjoy solving problem at the right time and at the right quality. I have over 9 years of experience building scalable & highly available back-end systems. I have proficiency in MSA, NOSQL, ML. I define the strategy and implement solution based on current situation. I am excited by constantly learning of many things. Software Engineer I make common solutions for massive online games. I implement framework from front to back-end. I use machine learning to solve real world problem. More HOME resoliwan@gmail.com","title":"README.md"},{"location":"#readmemd","text":"I enjoy solving problem at the right time and at the right quality. I have over 9 years of experience building scalable & highly available back-end systems. I have proficiency in MSA, NOSQL, ML. I define the strategy and implement solution based on current situation. I am excited by constantly learning of many things.","title":"README.md"},{"location":"#software-engineer","text":"I make common solutions for massive online games. I implement framework from front to back-end. I use machine learning to solve real world problem.","title":"Software Engineer"},{"location":"#more","text":"HOME resoliwan@gmail.com","title":"More"},{"location":"dl/1_dl_introduction/","text":"1. Introduction to Introduction to Machine Learning Based AI What is intelligent? Intelligent measures an agent's ability to achieve goals in a wide range of environments $$ \\pi := \\sum_{\\mu\\in E} 2_{}^{-K(\\mu)}V_{\\mu}^{\\pi} $$ $\\pi$ Measure of intelligence $\\sum_{\\mu\\in E}$ Sum of environment. $2_{}^{-K(\\mu)}$ Complexity penalty $V_{\\mu}^{\\pi}$ Value achieve \uc9c0\ub2a5\uc774\ub780 \uc5ec\ub7ec \ud658\uacbd\uc5d0\uc11c \uc5d0\uc774\uc804\ud2b8\uac00 \ubaa9\ud45c\ub4e4\uc744 \ub2ec\uc131\ud558\ub294 \ub2a5\ub825\uc758 \ucd1d\ud569\uc73c\ub85c \uce21\uc815 \ub420 \uc218 \uc788\ub2e4. \ud658\uacbd\uc774 \ubcf5\uc7a1\ud560 \uc218\ub85d \ubcf5\uc7a1\ub3c4 \ud328\ub110\ud2f0\ub294 \ucee4\uc9c4\ub2e4.(\ud658\uacbd\uc774 \ubcf5\uc7a1 \ud560 \uc218\ub85d \uc5ec\ub7ec step \uc774 \uc874\uc7ac \ud568\uc73c\ub85c \uc218\ub834\ud558\uae30 \uc704\ud574\uc11c \uc5b4\uca54\uc218 \uc5c6\ub2e4.) \uac8c\uc784\uc744 \uc2dc\ubbac\ub808\uc774\ud130\ub85c \uc0ac\uc6a9 \ud558\ub294 \uc774\uc720 \ud604\uc2e4\uc758 \uacbd\uc6b0 \uc5ec\ub7ec \uac10\uac01\uc73c\ub85c \ubd80\ud130 \ub370\uc774\ud130\ub97c \uc77d\uc5b4 \uc0c1\uc9d5\ud654\ub41c \uae30\ud638\ub85c \ubcc0\uacbd\ud558\ub294\uac8c \ud798\ub4e4\ub2e4. \uac8c\uc784\uc758 \uacbd\uc6b0 \uac10\uac01\uc774 \ub2e8\uc21c\ud654 \ub418\uc5b4 \uc788\ub2e4. \ubb34\uc81c\ud55c \uc801\uc778 \ub370\uc774\ud130 \uc2e4\ud5d8 \ud3b8\ud5a5\uc774 \uc5c6\ub294\uac83 \ub3d9\uc2dc\uc801 \uc5ec\ub7ec \ud14c\uc2a4\ud305 \uce21\uc815 \uac00\ub2a5\ud55c \uc9c4\ud589\ub3c4 \uba38\uc2e0\ub7ec\ub2dd \ucd94\uc138 \uc608\uc804\uc5d0\ub294 \uc9c1\uc811 \ub9cc\ub4e4\uc5c8\ub2e4\uba74 \uc694\uc0c8\ub294 \uac01\uac01\uc758 \ubaa8\ub4c8 \ub2e8\uc704\ub85c \ud544\uc694\ud55c \ubd80\ubd84\uc744 \uc870\ud569\ud574\uc11c \uc0ac\uc6a9\ud55c\ub2e4. \ud150\uc11c \ud50c\ub85c\uc6b0\ub4f1\uc774 \uc790\ub3d9\uc73c\ub85c \ubbf8\ubd84\uc744 \ud574\uc8fc\uae30 \ub54c\ubb38\uc5d0 End to End \ub85c \ud559\uc2b5 \ud560 \uc218 \uc788\ub2e4. Reference \ucc38\uc870 DeepMind lab RL\uc6a9 1\uc778\uce6d \uc288\ud305 \uac8c\uc784(\uacf5\uac1c\ub418\uc5b4 \uc788\uc74c) From Deepmind","title":"1. Introduction to Introduction to Machine Learning Based AI"},{"location":"dl/1_dl_introduction/#1-introduction-to-introduction-to-machine-learning-based-ai","text":"","title":"1. Introduction to Introduction to Machine Learning Based AI"},{"location":"dl/1_dl_introduction/#what-is-intelligent","text":"Intelligent measures an agent's ability to achieve goals in a wide range of environments $$ \\pi := \\sum_{\\mu\\in E} 2_{}^{-K(\\mu)}V_{\\mu}^{\\pi} $$ $\\pi$ Measure of intelligence $\\sum_{\\mu\\in E}$ Sum of environment. $2_{}^{-K(\\mu)}$ Complexity penalty $V_{\\mu}^{\\pi}$ Value achieve \uc9c0\ub2a5\uc774\ub780 \uc5ec\ub7ec \ud658\uacbd\uc5d0\uc11c \uc5d0\uc774\uc804\ud2b8\uac00 \ubaa9\ud45c\ub4e4\uc744 \ub2ec\uc131\ud558\ub294 \ub2a5\ub825\uc758 \ucd1d\ud569\uc73c\ub85c \uce21\uc815 \ub420 \uc218 \uc788\ub2e4. \ud658\uacbd\uc774 \ubcf5\uc7a1\ud560 \uc218\ub85d \ubcf5\uc7a1\ub3c4 \ud328\ub110\ud2f0\ub294 \ucee4\uc9c4\ub2e4.(\ud658\uacbd\uc774 \ubcf5\uc7a1 \ud560 \uc218\ub85d \uc5ec\ub7ec step \uc774 \uc874\uc7ac \ud568\uc73c\ub85c \uc218\ub834\ud558\uae30 \uc704\ud574\uc11c \uc5b4\uca54\uc218 \uc5c6\ub2e4.)","title":"What is intelligent?"},{"location":"dl/1_dl_introduction/#_1","text":"","title":"\uac8c\uc784\uc744 \uc2dc\ubbac\ub808\uc774\ud130\ub85c \uc0ac\uc6a9 \ud558\ub294 \uc774\uc720"},{"location":"dl/1_dl_introduction/#_2","text":"\uc5ec\ub7ec \uac10\uac01\uc73c\ub85c \ubd80\ud130 \ub370\uc774\ud130\ub97c \uc77d\uc5b4 \uc0c1\uc9d5\ud654\ub41c \uae30\ud638\ub85c \ubcc0\uacbd\ud558\ub294\uac8c \ud798\ub4e4\ub2e4.","title":"\ud604\uc2e4\uc758 \uacbd\uc6b0"},{"location":"dl/1_dl_introduction/#_3","text":"\uac10\uac01\uc774 \ub2e8\uc21c\ud654 \ub418\uc5b4 \uc788\ub2e4. \ubb34\uc81c\ud55c \uc801\uc778 \ub370\uc774\ud130 \uc2e4\ud5d8 \ud3b8\ud5a5\uc774 \uc5c6\ub294\uac83 \ub3d9\uc2dc\uc801 \uc5ec\ub7ec \ud14c\uc2a4\ud305 \uce21\uc815 \uac00\ub2a5\ud55c \uc9c4\ud589\ub3c4","title":"\uac8c\uc784\uc758 \uacbd\uc6b0"},{"location":"dl/1_dl_introduction/#_4","text":"\uc608\uc804\uc5d0\ub294 \uc9c1\uc811 \ub9cc\ub4e4\uc5c8\ub2e4\uba74 \uc694\uc0c8\ub294 \uac01\uac01\uc758 \ubaa8\ub4c8 \ub2e8\uc704\ub85c \ud544\uc694\ud55c \ubd80\ubd84\uc744 \uc870\ud569\ud574\uc11c \uc0ac\uc6a9\ud55c\ub2e4. \ud150\uc11c \ud50c\ub85c\uc6b0\ub4f1\uc774 \uc790\ub3d9\uc73c\ub85c \ubbf8\ubd84\uc744 \ud574\uc8fc\uae30 \ub54c\ubb38\uc5d0 End to End \ub85c \ud559\uc2b5 \ud560 \uc218 \uc788\ub2e4.","title":"\uba38\uc2e0\ub7ec\ub2dd \ucd94\uc138"},{"location":"dl/1_dl_introduction/#reference","text":"\ucc38\uc870 DeepMind lab RL\uc6a9 1\uc778\uce6d \uc288\ud305 \uac8c\uc784(\uacf5\uac1c\ub418\uc5b4 \uc788\uc74c) From Deepmind","title":"Reference"},{"location":"dl/2_dl_tensorflow/","text":"2. Introduction to TensorFlow What is Tensorflow? \ud150\uc11c\ud50c\ub85c\uc6b0\ub294 \uacc4\uc0b0\uc744 \uc704\ud55c \ub77c\uc774\ube14\ub7ec\ub9ac\uc774\ub2e4. \ud150\uc11c\ub780 \uba40\ud2f0\ub514\uba54\uc154\ub110 \uc5b4\ub808\uc774(\ub2e4\ucc28\uc6d0 \ud589\ub82c)\ub97c \uc758\ubbf8\ud55c\ub2e4. flow \ub294 \ud750\ub978\ub2e4\ub294 \ub290\ub08c\uc774\ub2e4. \ud150\uc11c\ud50c\ub85c\uc6b0\ub294 \uc774\ub984\uc5d0\uc11c \ubcf4\ub4ef\uc774 \ud150\uc11c\uac00 \ud750\ub974\ub294\uac78 \uc758\ubbf8\ud55c\ub2e4. TODO: \ud150\uc11c\ud50c\ub85c\uc6b0\ub97c \ubb3c\uc774 \ud750\ub974\ub294 \uae38\uc744 \ud30c\uace0 \uadf8 \uc704\uc5d0 \uc2e4\uc81c \ubb3c\uc744 \ud758\ub9ac\ub294 \ubaa8\uc2b5\uc73c\ub85c \ubb18\uc0ac\ud574\ubcf4\uc790. \ud150\uc11c\ub97c \ubb3c\uc774\ub77c\uace0 \uc0dd\uac01\ud574\ubcf4\uc790. \ubb3c\uc744 \uc6d0\ud558\ub294 \ubc29\ud5a5\uc73c\ub85c \ud750\ub974\uac8c \ud558\uae30 \uc704\ud574\uc11c\ub294 \uc77c\ub2e8 \uae38\uc744 \ud30c\uc57c\ud55c\ub2e4. \uadf8 \uae38 \uc704\uc5d0 \ubb3c\uc744 \ubd80\uc73c\uba74 \uc774\ubbf8 \ud30c\ub454 \uae38\uc744 \ub530\ub77c \ubb3c\uc774 \ud750\ub978\ub2e4. \ubb3c\uc774 \ud569\uccd0\uc9c0\uae30\ub3c4 \ud558\uace0 \uc11e\uc774\uae30\ub3c4 \ud558\uba74\uc11c \uc0c8\ub85c\uc6b4 \ubb3c\ub85c \ubcc0\ud574 \ub9c8\uc9c0\ub9c9\uc5d0 \ub2e4\ub2e4\ub978\ub2e4. \ubb34\uc5c7\uc73c\ub85c \uad6c\uc131\ub418\uc5b4 \uc788\ub294\uac00? \ud150\uc11c\ud50c\ub85c\uc6b0\ub294 \uacc4\uc0b0\uc744 \ud55c\ub2e4. \uacc4\uc0b0\uc744 \ud558\uae30\uc704\ud574\uc11c\ub294 \ud2b9\uc815 \uacc4\uc0b0\uc744 \uc815\uc758\ud558\uace0 \uc2e4\ud589 \ud574\uc57c \ud55c\ub2e4. \ud150\uc11c\ud50c\ub85c\uc6b0\ub294 \uacc4\uc0b0\ub4e4\uc744 \ub2e8 \ubc29\ud5a5 \uadf8\ub798\ud504\ub85c \uc815\uc758\ud55c\ub2e4. \uadf8\ub9ac\uace0 \uc815\uc758 \ub41c \ub2e8 \ubc29\ud5a5 \uadf8\ub798\ud504\ub97c \uc2e4\ud589\ud574 \uacb0\uacfc\uac12\uc744 \uad6c\ud55c\ub2e4. \ud150\uc11c\ud50c\ub85c\uc6b0\ub294 2\uac1c\uc758 \uad6c\uc131 \uc694\uc18c\ub97c \uac00\uc9c4\ub2e4. \uacc4\uc0b0 \uadf8\ub798\ud504\ub97c \uc815\uc758 \ud558\ub294 \ub77c\uc774\ube14\ub7ec\ub9ac. \uc815\uc758\ub41c \uadf8\ub798\ud504\ub97c \uc2e4\ud589 \uc2dc\ucf1c\uc8fc\ub294 \ub7f0\ud0c0\uc784 \ud658\uacbd(\uc5ec\ub7ec \ud558\ub4dc\uc6e8\uc5b4\uc5d0\uc11c \ub3d9\uc2dc\uc801\uc73c\ub85c \ub3cc\ub9b4\uc218 \uc788\ub2e4.) \uacc4\uc0b0 \uadf8\ub798\ud504\ub294 \ubb34\uc5c7\uc778\uac00? \uacc4\uc0b0\uc744 \ub2e8\ubc29\ud5a5 \uadf8\ub798\ud504\ub85c \ucd94\uc0c1\ud654 \ud55c\uac83\uc744 \uc758\ubbf8\ud55c\ub2e4. \uadf8\ub798\ud504\ub294 2\uac00\uc9c0\ub85c \uad6c\uc131\ub418\uc5b4 \uc788\ub2e4. \ubc14\ub85c edge \uc640 node \uc774\ub2e4. edge \ub294 \ub2e4\ucc28\uc6d0 \ud589\ub82c(tensor)\uc5d0 \ub300\uc751\ud55c\ub2e4. node \ub294 \ud150\uc11c\ub97c \uc0dd\uc131 \ub610\ub294 \ud2b9\uc815 \uaddc\uce59\uc73c\ub85c \uc870\uc791\ud55c\ub2e4.(Ops) Example of Computational Graph \uc544\ub798\uc758 \uacc4\uc0b0 \uadf8\ub798\ud504 \uc815\uc758 \ucf54\ub4dc\ub294 \ub2e4\uc74c\uacfc \uac19\uc740 \ub2e8\ubc29\ud5a5 \uadf8\ub798\ud504\ub85c \ub9cc\ub4e4\uc5b4 \uc9c8\uc218 \uc788\ub2e4. (\ud150\uc11c\ub294 \ub7f0\ud0c0\uc784\uc5d0 \ud750\ub978\ub2e4.) red = 1 blue = 2 green = red * blue pink = red + blue purple = green / pink print(purple) \ub2e8\ubc29\ud5a5 \uadf8\ub798\ud504\ub85c \uc5bb\uc744 \uc218 \uc788\ub294 \uac83\ub4e4. \uc758\uc874\uc131\uc744 \uace0\ub824\ud55c \uc2a4\ucf00\uc974\ub9c1\uc744 \ud560 \uc218 \uc788\ub2e4. \uc704\uc758 \uadf8\ub798\ud504\ub85c\uc5d0\uc11c $a*b$ \uc640 $a+b$ \ub294 \uc758\uc874\uc131\uc774 \uc5c6\uae30 \ub54c\ubb38\uc5d0 \ub3d9\uc2dc\uc5d0 \uc2a4\ucf00\uc974\ub9c1 \ud560 \uc218 \uc788\ub2e4. $a * b$ \uc758 \uacb0\uacfc\ub9cc \uc5bb\uace0 \uc2f6\uc744 \uacbd\uc6b0 $a*b$ \ub9cc \uc2e4\ud589 \ud560 \uc218 \uc788\ub2e4. \uc758\uc874\uc131\uc774 \uc5c6\ub294 \uadf8\ub798\ud504\ub97c \ub2e4\ub978 \uba38\uc2e0\uc5d0 \uc2a4\ucf00\uc974\ub9c1 \ud560 \uc218 \uc788\ub2e4. \ud150\uc11c\ud50c\ub85c\uc6b0 operation \uc65c \ud544\uc694 \ud55c\uac00? \ud150\uc11c\ud50c\ub85c\uc6b0\ub294 \uadf8\ub798\ud504\ub97c \uc815\uc758 \ud558\ub294 \uacf3\uacfc \uc2e4\ud589\ub418\ub294 \uacf3\uc774 \ub2e4\ub974\ub2e4. \uc989 \uc5b8\uc5b4\uc5d0\uc11c \uc81c\uacf5\ud558\ub294 \uc77c\ubc18\uc801\uc778 \ubcc0\uc218, \ubd84\uae30\ubb38, for\ubb38\ub4f1\uc744 \uc0ac\uc6a9 \ud560 \uc218 \uc5c6\ub2e4. \uadf8\ub807\ub2e4\uba74 \uc704\uc758 \uae30\ub2a5\uc774 \ud544\uc694\ud55c \uc0c1\ud669\uc774 \uc624\uba74 \uc5b4\ub5bb\uac8c \ud560\uac83\uc778\uac00? \ud574\uacb0\ucc45 \ud150\uc11c\ud50c\ub85c\uc6b0\uc758 \ub178\ub4dc\ub294 ops \ub77c\uace0 \uc704\uc5d0\uc11c \uc815\uc758\ud588\ub2e4. \ud574\ub2f9 \ub178\ub4dc \uc989 ops \uc0ac\uc6a9 \ud574\uc11c \uc704\uc758 \ud544\uc694\ub97c \ub9cc\uc871\uc2dc\ucf1c \uc8fc\uba74 \ub41c\ub2e4. Variable ops: \uc804\uccb4 \ub7f0\ud0c0\uc784 \ud658\uacbd\uc5d0\uc11c \uacf5\uc720 \uac00\ub2a5\ud558\uace0 \ubcc0\uacbd \ud560 \uc218 \uc788\ub294 \uc601\uc18d\uc801 \ubcc0\uc218 Conditional ops: \ub2e4\ub978 \ubd80\ubd84\uc5d0 \uc758\ud574 \ubd84\uae30\ub418\ub294 \uacc4\uc0b0 \ucc98\ub9ac. Loop ops: \ubc18\ubcf5 \uacc4\uc0b0 Control ops: \ub450\uac1c\uc758 ops \ub4e4\uc758 \uacc4\uc0b0 \uc21c\uc11c\ub97c \uac15\uc81c Queue ops: \ube44\ub3d9\uae30 \uacc4\uc0b0\uc744 \uc704\ud574 \uc0ac\uc6a9. \uc815\uc758\uc640 \uc2e4\ud589 \ubaa8\ub4e0 \ud150\uc11c\ud50c\ub85c\uc6b0\ub294 \ub450\uac1c\uc758 \ub2e8\uacc4\ub85c \uc774\ub8e8\uc5b4 \uc9c4\ub2e4. - \uadf8\ub798\ud504\ub97c \uc815\uc758\ud558\ub294 \ub2e8\uacc4(tf.Graph) - \ubb3c\uae38\uc744 \ud30c\ub294 \ub2e8\uacc4 - \uc815\uc758\ub41c \uadf8\ub798\ud504\ub97c \uc2e4\ud589\ud558\ub294 \ub2e8\uacc4 (tf.Session) - \ud30c\uc9c4 \ubb3c\uae38\uc744 \ub530\ub77c \ubb3c\uc744 \ud758\ub9ac\ub294 \ub2e8\uacc4 \ud150\uc11c \ud50c\ub85c\uc6b0 \uc5b8\uc5b4 \ud150\uc11c\ud50c\ub85c\uc6b0\uc758 \ubc31\ub2e8\uc740 cpp \ub85c \ub9cc\ub4e4\uc5b4\uc838 \uc788\ub2e4. \ud558\uc9c0\ub9cc \ud150\uc11c\ud50c\ub85c\uc6b0\ub294 \ud3b8\uc758\ub97c \uc704\ud574 python, cpp \ub4f1 \uc5ec\ub7ec \uc5b8\uc5b4 \uc778\ud130\ud398\uc774\uc2a4\ub97c \uc81c\uacf5\ud55c\ub2e4. cpp \ud568\uc218\uc5d0 \uc0ac\uc6a9\ub420 \uac12\uc744 \ud30c\uc774\uc36c\uc73c\ub85c \uc81c\uacf5\ud574 \uc900\ub2e4\uace0 \uc0dd\uac01\ud558\uba74 \uae30\uc874 \ud30c\uc774\uc36c \ud504\ub85c\uadf8\ub798\ubc0d\uacfc \ud150\uc11c\ud50c\ub85c\uc6b0\uc758 \uc774\uc9c8\uac10\uc744 \uc870\uae08 \uc904\uc77c \uc218 \uc788\ub2e4. Variable Definition \uc804\uccb4 \ub7f0\ud0c0\uc784 \ud658\uacbd\uc5d0\uc11c \uacf5\uc720 \uac00\ub2a5\ud558\uace0 \ubcc0\uacbd \ud560 \uc218 \uc788\ub294 \uc601\uc18d\uc801 \ubcc0\uc218 - \uc815\uc758 \ud560\ub54c name, type, shape, and initialization procedure \uc744 \ubcc0\uacbd \ud560 \uc218 \uc788\ub2e4. v = tf.get_variable( \"name\", dtype=tf.float32, shape[2, 2], initializer=tf.random_normal_initializer(stddev=0.5) ) Use \ub2e4\ub978 \ud150\uc11c \ucc98\ub7fc \uc0ac\uc6a9\ud558\uba74 \ub41c\ub2e4. y = tf.matmul(v, tf.constant([[1,2], [3,4]])) Assign \ubcc0\uc218\uc758 \uac12\uc744 \ubcc0\uacbd \ud558\ub824\uba74 \ud560\ub2f9\ud574\uc918\uc57c \ud558\uace0 \ud560\ub2f9\ub41c \uac12\uc740 \ub2e4\uc74c \uc5c5\ub370\uc774\ud2b8 \uae4c\uc9c0 \uac12\uc744 \uc720\uc9c0 \ud55c\ub2e4. increment_op = v.assign(v + 1) # syntax 1 increment_op = tf.assign(v, v + 1) #syntax2 Initialization \ubcc0\uc218 \uac12\ub4e4\uc740 \ud2b9\uc815 session \uc548\uc5d0\uc11c\ub9cc \uc720\uc9c0 \ub418\uba70 \ubcc0\uc218\ub97c \uc0ac\uc6a9\ud558\uae30 \uc704\ud574\uc11c\ub294 \ucd5c\ucd08\uc5d0 1\ud68c \ucd08\uae30\ud654 \ud574\uc8fc\uc5b4\uc57c \ud55c\ub2e4. create graph() # including variables init = tf.global_variables_initializer() # \ud55c\ubc88\uc5d0 \ubaa8\ub4e0 \ubcc0\uc218 \ucd08\uae30\ud654 with tf.Session() as session: session.run(init) Working with data \ub370\uc774\ud130\ub97c \uc77d\uc5b4 \uadf8\ub798\ud504\uc5d0\uac8c \uc8fc\uc5b4\uc57c \ud560 \uacbd\uc6b0\uac00 \uc788\ub2e4. \ub9cc\uc57d \ub370\uc774\ud130\uac00 \uc791\ub2e4\uba74 \uc6b0\ub9ac\ub294 \uadf8\ub798\ud504 \uc815\uc758\uc2dc\uc810\uc5d0 \ub370\uc774\ud130\ub97c (\uba54\ubaa8\ub9ac\uc5d0 \ub85c\ub529\ud574) \uc0c1\uc218\ub85c \uc815\uc758 \ud560 \uc218 \uc788\ub2e4. d = tf.constant(<some numpy arrary>) \ub370\uc774\ud130\uac00 \uba54\ubaa8\ub9ac\ubcf4\ub2e4 \ud06c\ub2e4\uba74 \uc5d0\ub7ec\uac00 \ubc1c\uc0dd \ub428\uc73c\ub85c \ucd94\ucc9c \ud558\uc9c0 \uc54a\ub294\ub2e4. \ub610\ud55c \uadf8\ub798\ud504 \uc815\uc758\ub97c \uc800\uc7a5 \ud560 \ub54c \ub370\uc774\ud130\ub3c4 \uc800\uc7a5 \ub428\uc73c\ub85c \uc704\uc758 \ubc29\uc2dd\uc744 \uc0ac\uc6a9\ud558\uc9c0 \ub9d0\uc790. Placeholders and Feeds \uadf8\ub807\ub2e4\uba74 \uadf8\ub798\ud504\ub97c \uc815\uc758 \ud560 \ub54c \uac00 \uc544\ub2cc \ub7f0\ud0c0\uc784\uc5d0 \ud544\uc694 \ud560 \ub54c \ub370\uc774\ud130\ub97c \uc8fc\uac8c \ud574\ubcf4\uc790. \uadf8\ub798\ud504\ub97c \ub9cc\ub4e4\uc5b4\uc57c \ud568\uc73c\ub85c \uc5b4\ub5a4 \ub370\uc774\ud130\uac00 \ub4e4\uc5b4\uc628\ub2e4\uace0 \uc815\uc758\ud55c \uac1d\uccb4(placeholder) \ub97c \uc0ac\uc6a9\ud558\uace0 \uc2e4\uc81c \ub7f0\ud0c0\uc784\uc5d0 feed_dict \uc744 \uc0ac\uc6a9\ud574\uc11c \ub370\uc774\ud130\ub97c \uc804\ub2ec\ud558\uc790. a = tf.placeholder(tf.float32, []) b = tf.constant(1.0) c = a + b with tf.Session() as session: print(session.run(c, feed_dict={a: 3.0})) print(session.run(c, feed_dict={a: 4.0})) \ud150\uc11c\ud50c\ub85c\uc6b0\ub294 \ud50c\ub808\uc774\uc2a4 \ud640\ub354\ub97c \uc0ac\uc6a9 \ud560 \uacbd\uc6b0 session.run \ud560 \ub54c numpy array \ub85c \uad6c\uc131\ub41c dictionary \ub370\uc774\ud130 \uad6c\uc870\uac00 \ub4e4\uc5b4\uc628\ub2e4\uace0 \uae30\ub300\ud55c\ub2e4. - \ub85c\ub4dc, \uc804\ucc98\ub9ac, \ubc30\uce58, \ud050\uc789\ub4f1 \ub9c8\uc74c\ub300\ub85c \ud558\uba74\ub41c\ub2e4.(\uc790\uc720\ub3c4\uac00 \ub192\ub2e4.) - \ub610\ud55c \ud30c\uc77c, \uc2a4\ud2b8\ub9bc\ub4f1 \ubc18\ubcf5\ub418\ub294 \uc791\uc5c5\uc740 tf.data \uc5d0\uc11c \uc774\ubbf8 \ub0b4\uc7a5\ub41c \ud568\uc218\ub85c \uc81c\uacf5\ud558\uace0 \uc788\ub2e4. \uc608\uc81c \uac04\ub2e8\ud55c \uc120\ud615 \ud568\uc218\ub97c \ubc30\uc6b0\ub294 \uc608\uc81c\ub97c \uad6c\ud604\ud574 \ubcf4\uc790. \ud55c\uac1c\uc758 \ubcc0\uc218\ub9cc \uc788\ub294 \ud68c\uadc0 \ud568\uc218\ub97c \ubc30\uc6b4\ub2e4\uace0 \ud574\ubcf4\uc790. $f(x): R \\to R$ \uc6b0\ub9ac\ub294 \ud574\ub2f9 \ud568\uc218\uac00 \uc120\ud615\uc774\ub77c\uace0 \uac00\uc815\ud55c\ub2e4. $y = wx + b$ \uadf8\ub807\ub2e4\uba74 \uc6b0\ub9ac\uac00 \ucc3e\ub294 \uc2dd\uc740 \uc544\ub798\uc758 \uc2dd\uc744 \ub9cc\uc871\ud558\ub294 $\\hat w, \\hat b$ \ub97c \ucc3e\uc73c\uba74 \ub41c\ub2e4. $$ \\hat w, \\hat b = argmin_{w, b}\\left(\\frac{\\sum(y_{i} - wx_{i} + b)^{2}}{N}\\right) $$ \uc6b0\ub9ac\uac00 \uc0ac\uc6a9\ud558\ub294 \ub370\uc774\ud130\uc14b\ub3c4 \uc120\ud615\uc2dd \uc73c\ub85c \uc218\ub834 \ud55c\ub2e4\uace0 \uac00\uc815\ud55c\ub2e4. \ub2e4\ub978 \ub9d0\ub85c \uc6b0\ub9ac\ub294 mean squared error (MSE) \ub97c \ub9cc\uc871\ud558\ub294 $\\hat w, \\hat b$\ub97c \ucc3e\uc744 \uac83\uc774\ub2e4. \ud478\ub294 \ubc29\ubc95 \uc704\uc758 \uc2dd\uc740 \ubc29\uc815\uc2dd\uc73c\ub85c \ubc14\ub85c \ud480\uac70\ub098 \uacbd\uc0ac \ud558\uac15\ubc95(gradient descent)\uc744 \uc0ac\uc6a9 \ud560 \uc218 \uc788\ub2e4. $$ \\begin{align} \\hat w = & \\frac{\\sum_{i}(x_{i} - \\bar x)(y_{i} - \\bar y)}{\\sum_{i}(x_{i} - \\bar x)^{2}} \\\\ \\hat b = & \\bar y - w \\bar x \\\\ \\bar x = & \\frac{\\sum_{i}x_{i}}{N} \\\\ \\bar y = & \\frac{\\sum_{i}y_{i}}{N} \\\\ \\end{align} $$ \uc77c\ubc18\uc801\uc73c\ub85c \ubcf5\uc7a1\ud55c \ubb38\uc81c\uc5d0\uc11c \ubc29\uc815\uc2dd\uc73c\ub85c \uad6c\ud558\uae30 \uc5b4\ub824\uc6b4 \uacbd\uc6b0\uac00 \ub9ce\ub2e4. \uadf8\ub7ec\ubbc0\ub85c \uc6b0\ub9ac\ub294 \uc544\ub798\uc758 \uacbd\uc0ac \ud558\uac15\ubc95\uc744 \uc0ac\uc6a9\ud560 \uac83\uc774\ub2e4. $$ w_{t+1} = w_{t} - \\alpha \\frac{\\partial MSA}{\\partial w_{t}} \\\\ b_{t+1} = b_{t} - \\alpha \\frac{\\partial MSA}{\\partial b_{t}} $$ \uacbd\uc0ac\ud558\uac15\ubc95\uc774\ub780 \ub85c\uc2a4 \ud391\uc158(\uc5ec\uae30\uc11c\ub294 MSA)\uc758 \ubbf8\ubd84\uac12\uc744 \ud30c\ub77c\ubbf8\ud130\uc5d0\uc11c \uc9c0\uc18d\uc801\uc73c\ub85c \uc801\uc6a9\ud574\uc11c \ud30c\ub77c\ubbf8\ud130\uac00 \uc218\ub834 \ud560\ub54c\uae4c\uc9c0 \ubc18\ubcf5\ud558\ub294 \ubc29\ubc95\uc744 \ub9d0\ud55c\ub2e4. \ub370\uc774\ud130\ub97c \ub9cc\ub4e4\uc5b4\ubcf4\uc790. 1\ucc28\uc6d0 \ub370\uc774\ud130\ub97c \ub9cc\ub4e4\uc790. \ub370\uc774\ud130\ub97c \ub9cc\ub4e4\ub54c x \uac12\uc740 range(20) = [0,1,..,19] \ub97c \uc0ac\uc6a9\ud558\uace0 y \uac12\uc740 $y = wx + b + \\eta $ \uc5ec\uae30\uc11c $\\eta$ \uc740 \uc815\uaddc\ubd84\ud3ec\uc758\uc5d0\uc11c mean = 0, std = 1 \uc744 \uc0ac\uc6a9\ud574 \ub79c\ub364\ud558\uac8c \ub354 \ud560 \uac83\uc774\ub2e4. code Automatic Differentiation \uacbd\uc0ac \ud558\uac15\ubc95\uc740 \ubbf8\ubd84\uc744 \ud544\uc694\ub85c \ud558\uace0 composition function \uc758 \uacbd\uc6b0 chain rule \uc0ac\uc6a9\ud574 \ubbf8\ubd84\uc744 \ud574\uc57c\ud55c\ub2e4. \ud150\uc11c \ud50c\ub85c\uc6b0\ub294 \uc2dc\uc2a4\ud15c\uc5d0\uc11c \uc790\ub3d9\uc73c\ub85c \ubbf8\ubd84\uc2dd\uc744 \uc81c\uacf5 \ud574\uc900\ub2e4. Gradients tf.gradients \ud568\uc218\ub97c \uc774\uc6a9\ud574\uc11c \uacbd\uc0ac \ud558\uac15\ubc95\uc744 \uc0ac\uc6a9\ud558\uc790. grads = tf.gradients(my_tensor, var_list) grads \uc548\uc5d0\ub294 len(var_list)\uc758 \uae38\uc774\uc640 \uac19\uc740 \ud150\uc11c\uac00 \ub4e4\uc5b4\uc788\ub2e4. \uc774 \ud150\uc11c \uac01\uac01\uc758 var_list \uc758 \ubcc0\uc218\ub97c my_tensor \ud3b8\ubbf8\ubd84\ud55c \uc2dd\uc774\ub2e4. \ub9cc\uc57d var_list \uc548\uc5d0 my_tensor \uc5d0 \uc758\uc874 \ud558\uc9c0 \uc54a\ub294 \ubcc0\uc218\uac00 \uc788\ub2e4\uba74 grads \uc758 \ud574\ub2f9 \uac12\uc740 None \uc774\ub2e4. Loss function # ytf \uc640 model_output \uc73c\ub85c MSA loss function \uc744 \ub9cc\ub4e4\uc5b4\ub77c. loss = tf.losses.mean_squared_error(ytf, model_output) # \ub85c\uc2a4 \ud391\uc158\uc5d0 \ub300\ud574\uc11c w, b \uc5d0 \ub300\ud55c \ud3b8\ubbf8\ubd84 \ud568\uc218\ub97c \ub9cc\ub4e4\uc5b4\ub77c. grads = tf.gradients(loss, [model.w, model.b]) update_w = tf.assign(model.w, model.w - 0.001 * grads[0]) update_b = tf.assign(model.b, model.b - 0.001 * grads[1]) update = tf.group(update_w, update_b) code Optimizer update \uad00\ub828 \uc791\uc5c5\ub3c4 tf.train.Optimizer \ub85c \ucd94\uc0c1\ud654 \ub418\uc5b4 \uc788\ub2e4. \uc544\ub798\uc640 \uac19\uc774 \uc0ac\uc6a9 \ud558\ub294\uac78 \uad8c\uc7a5\ud558\uba70 \uc790\ub9e4\ud488 AdamOptimizer, RMSPropOptimizer \ub3c4 \uc788\ub2e4. loss = tf.losses.mean_squared_error(ytf, model_output) update = tf.train.GradientDescentOptimizer(learning_rate=0.001).minimize(loss) code Control Logic tf.control_dependencies: \ub178\ub4dc \uc0ac\uc774\uc5d0 \uc758\uc874\uc131\uc744 \ucd94\uac00. tf.conf: true/false \ubd84\uae30 tf.case: multi-case \ubd84\uae30 tf.while_loop: while loop \uc774\ud574\ud558\uae30\ub294 \uc5b4\ub835\uc9c0\ub9cc RL\uc744 \uc704\ud574\uc11c \uaf2d \ud544\uc694\ud568. Control dependencies x = tf.get_variable('x', shape=(), initializer=tf.zeros_initializer()) assign_x = tf.assign(x, 10.0) # z = tf.assign(x, 10.0) + 1.0 z = x + 1.0 with tf.train.MonitoredSession() as sess: print(sess.run(z)) # \uacb0\uacfc \uac12\uc740 1.0 and assing_x \ub294 z \uc5d0 \uc758\uc874\uc131\uc774 \uc5c6\uc74c\uc73c\ub85c \uc2e4\ud589 \uc548\ub428 with tf.train.MonitoredSession() as sess: print(sess.run([assign_x, z])) # \ud150\uc11c \ud50c\ub85c\uc6b0\ub294 fetchs \ub9ac\uc2a4\ud2b8\uc5d0 \uc778\ub371\uc2a4 \uc21c\uc11c\ub300\ub85c \uc2e4\ud589\ud558\uc9c0 \uc54a\uc74c! # \uacb0\uacfc \uac12\uc740 (10.0, 1.0) \ub610\ub294 (10.0, 11.0) \uc774\ub428 assign_x \uc640 z \uac00 \ub808\uc774\uc2a4 \ucee8\ub514\uc158\uc774 \ub428. with tf.control_dependencies([assign_x]): z = x + 1.0 with tf.train.MonitoredSession() as sess: print(sess.run(z)) # z \ub97c assign_x \uc5d0 \uc758\uc874 \ud558\ub3c4\ub85d \uc124\uc815\ud588\uae30 \ub54c\ubb38\uc5d0 z \ub97c \uc2e4\ud589\ud558\uba74 assign_x \uac00 \uba3c\uc800 \uc2e4\ud589\ub428. 11.0 code Conditional evaluation. v1 = tf.get_variable('v1', shape=(), initializer=tf.zeros_initializer()); v2 = tf.get_variable('v2', shape=(), initializer=tf.zeros_initializer()); switch = tf.placeholder(tf.bool) cond = tf.cond(switch, lambda: tf.assign(v1, 1.0), # true lambda: tf.assign(v2, 2.0)) # false with tf.train.MonitoredSession() as sess: sess.run(cond, feed_dict={switch: False}) print(sess.run([v1, v2])) # [0.0, 2.0] v3 = tf.get_variable('v3', shape=(), initializer=tf.zeros_initializer()); v4 = tf.get_variable('v4', shape=(), initializer=tf.zeros_initializer()); switch = tf.placeholder(tf.bool) assign_v3 = tf.assign(v3, 1.0) assign_v4 = tf.assign(v4, 1.0) # \ucee8\ub514\uc158\uc744 \ub9cc\ub4e4\uae30 \uc704\ud574 \ud544\uc694\ud55c \uc758\uc874\uc131\uc740 \uba3c\uc800 \uc2e4\ud589\ub41c\ub2e4. # \uc989 assign_v4 \uc640 assign_v4 \ub294 cond \ub97c \ub9cc\ub4dc\ub294\ub300 \ud544\uc694\ud568\uc73c\ub85c # \ud574\ub2f9 op \ub97c \ub9cc\ub4dc\ub294 \uc704\uc758 \ub450\uac1c\uc758 \ud560\ub2f9\ubb38\uc774 \uc2e4\ud589\ub41c\ub2e4. cond = tf.cond(switch, lambda: assign_v3, lambda: assign_v4) with tf.train.MonitoredSession() as sess: sess.run(cond, feed_dict={switch: False}) print(sess.run([v3, v4])) # [1.0, 1.0] code While k = tf.constant(2) matrix = tf.ones([2, 2]) condition = lambda i, _: i < k body = lambda i, m: (i+1, tf.matmul(m, matrix)) final_i, power = tf.while_loop( cond=condition, body=body, loop_vars=(0, tf.diag([1., 1.])) ) # loop 1 # i = 0 => i = 1 # m * matrix => m # [[1, 0] [[1, 1] [[1, 1] # [0, 1]] * [1, 1]] => [1, 1]] # loop 2 # i = 1 => i = 2 # m * matrix => m # [[1, 1] [[1, 1] [[2, 2] # [1, 1]] * [1, 1]] => [2, 2]] # i < 2 break; with tf.train.MonitoredSession() as sess: print(sess.run([final_i, power])) # [2, [[2, 2], [2, 2]]] code Dynamic Unrolling \ub525\ub7ec\ub2dd\uacfc RL \uc5d0\uc11c \ud2b9\uc815 \uc0c1\ud0dc\uc5d0 \uac19\uc740 transformaion \uc744 \ud574\uc11c \ub204\uc801 \uc2dc\ud0a4\ub294 \ud589\uc704\ub294 \uc790\uc8fc \uc77c\uc5b4\ub09c\ub2e4. \uc608\ub97c\ub4e4\uc5b4 Time series prediction Sequence to sequence models Take decisions in partially observable domains \ud150\uc11c \ud50c\ub85c\uc6b0\uc5d0\uc11c ad-hoc \uc720\ud2f8\ub9ac\ud2f0 \ud568\uc218\ub97c \uc81c\uacf5\ud55c\ub2e4. \uc608\uc81c Fibnacci number \uc704\uc758 \ub204\uc801 \uc608\uc81c\ub85c \ud53c\ubcf4\ub098\uce58 \uc218\uc5f4\uc744 \ub4e4\uc5b4\ubcf4\uc790. \ud53c\ubcf4\ub098\uce58 \uc218\uc5f4\uc740 $0, 1, 1, 2, 3, 5.. $ \uac19\uc740 \uc218\uc5f4\uc744 \ub9d0\ud55c\ub2e4. \ucd08\uae30\uac12 (0, 1) \uc744 \uc8fc\uba74 \ub2e4\uc74c \uc218\ubd80\ud130\ub294 \uc774\uc804 \ub450 \uc218\uc758 \ud569\uc73c\ub85c \ub2e4\uc74c \uc218\ub97c \uad6c \ud560 \uc218 \uc788\ub2e4. \uc989 \uc774\uc804 \ub450\uac1c\uc758 \uc0c1\ud0dc\uac12\ub9cc \uae30\uc5b5\ud558\uba74 \ub418\ub294\uac83\uc774\ub2e4. $$ F_{0} = 0, F_{1} = 1, \\\\ F_{n} = F_{n-1} + F_{n-2}, \\\\ \\text{for } n > 1. $$ def fibonacci(state): output = state[0] + state[1] return output, (state[1], output) state = (0, 1) # (f_{0}, f_{1}) for item in range(10): output, state = fibonacci(state) #f_n, (f_{n-2}, f_{n-1}) print(output) # \uc54c\uace0\ub9ac\uc998\uc740 \uc704\uc640 \uac19\uace0 \ud150\uc11c \ud50c\ub85c\uc6b0 \uad6c\ud604\uc740 \uc544\ub798 \ucf54\ub4dc\ub97c \ucc38\uc870\ud558\uc790. code Advanced Features \ud150\uc11c \ud50c\ub85c\uc6b0\ub294 \uc704\uc5d0 \uc124\uba85 \ub9d0\uace0\ub3c4 \ub9ce\uc740 \ub2e4\ub978 \uae30\ub2a5\ub4e4\uc744 \uc81c\uacf5\ud55c\ub2e4. \ub7f0\ud0c0\uc784 \ub77c\uc774\ube14\ub7ec\ub294 \uc544\ub798\uc640 \uac19\uc740 \uae30\ub2a5\ub3c4 \uc81c\uacf5\ud55c\ub2e4. \uba40\ud2f0\ucf54\uc5b4 CPU \uc5d0\uc11c \uba40\ud2f0 \uc4f0\ub808\ub4dc \uc2e4\ud589\uc744 \ud560 \uc218 \uc788\ub2e4. GPU \uc5d0\uc11c \uacc4\uc0b0\uc744 \uc2dc\ud0ac \uc218\ub3c4 \uc788\ub2e4. \ubd84\uc0b0 \ud658\uacbd\uc5d0\uc11c \uc5ec\ub7ec \uba38\uc2e0\uc5d0 \uac78\uccd0 \uc2e4\ud589 \uc2dc\ud0ac\uc218\ub3c4 \uc788\ub2e4. Annotate \ub97c \uadf8\ub798\ud504\uc5d0 \uba85\uc2dc\ud574\uc8fc\uba74 \uc704\uc758 \uae30\ub2a5\ub4e4\uc744 \ud150\uc11c\ud50c\ub85c\uc6b0\uac00 \uc54c\uc544\uc11c \ucc98\ub9ac\ud574\uc900\ub2e4. with tf.device(\"/cpu:0\"): a = tf.assign(..) b = tf.assign(..) with tf.device(\"/gpu:0\"): c = tf.matfmul(a, b) with tf.Session() as sess: sess.run(c) \ud560\ub2f9\ud558\uc9c0 \uc54a\uc544\ub3c4 gpu \uac00 \uac00\ub2a5\ud558\uba74 gpu \uc5d0\uc11c \uc2e4\ud589 \ud55c\ub2e4. Reference Assignment \ucc38\uc870","title":"2. Introduction to TensorFlow"},{"location":"dl/2_dl_tensorflow/#2-introduction-to-tensorflow","text":"","title":"2. Introduction to TensorFlow"},{"location":"dl/2_dl_tensorflow/#what-is-tensorflow","text":"\ud150\uc11c\ud50c\ub85c\uc6b0\ub294 \uacc4\uc0b0\uc744 \uc704\ud55c \ub77c\uc774\ube14\ub7ec\ub9ac\uc774\ub2e4. \ud150\uc11c\ub780 \uba40\ud2f0\ub514\uba54\uc154\ub110 \uc5b4\ub808\uc774(\ub2e4\ucc28\uc6d0 \ud589\ub82c)\ub97c \uc758\ubbf8\ud55c\ub2e4. flow \ub294 \ud750\ub978\ub2e4\ub294 \ub290\ub08c\uc774\ub2e4. \ud150\uc11c\ud50c\ub85c\uc6b0\ub294 \uc774\ub984\uc5d0\uc11c \ubcf4\ub4ef\uc774 \ud150\uc11c\uac00 \ud750\ub974\ub294\uac78 \uc758\ubbf8\ud55c\ub2e4. TODO: \ud150\uc11c\ud50c\ub85c\uc6b0\ub97c \ubb3c\uc774 \ud750\ub974\ub294 \uae38\uc744 \ud30c\uace0 \uadf8 \uc704\uc5d0 \uc2e4\uc81c \ubb3c\uc744 \ud758\ub9ac\ub294 \ubaa8\uc2b5\uc73c\ub85c \ubb18\uc0ac\ud574\ubcf4\uc790. \ud150\uc11c\ub97c \ubb3c\uc774\ub77c\uace0 \uc0dd\uac01\ud574\ubcf4\uc790. \ubb3c\uc744 \uc6d0\ud558\ub294 \ubc29\ud5a5\uc73c\ub85c \ud750\ub974\uac8c \ud558\uae30 \uc704\ud574\uc11c\ub294 \uc77c\ub2e8 \uae38\uc744 \ud30c\uc57c\ud55c\ub2e4. \uadf8 \uae38 \uc704\uc5d0 \ubb3c\uc744 \ubd80\uc73c\uba74 \uc774\ubbf8 \ud30c\ub454 \uae38\uc744 \ub530\ub77c \ubb3c\uc774 \ud750\ub978\ub2e4. \ubb3c\uc774 \ud569\uccd0\uc9c0\uae30\ub3c4 \ud558\uace0 \uc11e\uc774\uae30\ub3c4 \ud558\uba74\uc11c \uc0c8\ub85c\uc6b4 \ubb3c\ub85c \ubcc0\ud574 \ub9c8\uc9c0\ub9c9\uc5d0 \ub2e4\ub2e4\ub978\ub2e4.","title":"What is Tensorflow?"},{"location":"dl/2_dl_tensorflow/#_1","text":"\ud150\uc11c\ud50c\ub85c\uc6b0\ub294 \uacc4\uc0b0\uc744 \ud55c\ub2e4. \uacc4\uc0b0\uc744 \ud558\uae30\uc704\ud574\uc11c\ub294 \ud2b9\uc815 \uacc4\uc0b0\uc744 \uc815\uc758\ud558\uace0 \uc2e4\ud589 \ud574\uc57c \ud55c\ub2e4. \ud150\uc11c\ud50c\ub85c\uc6b0\ub294 \uacc4\uc0b0\ub4e4\uc744 \ub2e8 \ubc29\ud5a5 \uadf8\ub798\ud504\ub85c \uc815\uc758\ud55c\ub2e4. \uadf8\ub9ac\uace0 \uc815\uc758 \ub41c \ub2e8 \ubc29\ud5a5 \uadf8\ub798\ud504\ub97c \uc2e4\ud589\ud574 \uacb0\uacfc\uac12\uc744 \uad6c\ud55c\ub2e4.","title":"\ubb34\uc5c7\uc73c\ub85c \uad6c\uc131\ub418\uc5b4 \uc788\ub294\uac00?"},{"location":"dl/2_dl_tensorflow/#2","text":"\uacc4\uc0b0 \uadf8\ub798\ud504\ub97c \uc815\uc758 \ud558\ub294 \ub77c\uc774\ube14\ub7ec\ub9ac. \uc815\uc758\ub41c \uadf8\ub798\ud504\ub97c \uc2e4\ud589 \uc2dc\ucf1c\uc8fc\ub294 \ub7f0\ud0c0\uc784 \ud658\uacbd(\uc5ec\ub7ec \ud558\ub4dc\uc6e8\uc5b4\uc5d0\uc11c \ub3d9\uc2dc\uc801\uc73c\ub85c \ub3cc\ub9b4\uc218 \uc788\ub2e4.)","title":"\ud150\uc11c\ud50c\ub85c\uc6b0\ub294 2\uac1c\uc758 \uad6c\uc131 \uc694\uc18c\ub97c \uac00\uc9c4\ub2e4."},{"location":"dl/2_dl_tensorflow/#_2","text":"\uacc4\uc0b0\uc744 \ub2e8\ubc29\ud5a5 \uadf8\ub798\ud504\ub85c \ucd94\uc0c1\ud654 \ud55c\uac83\uc744 \uc758\ubbf8\ud55c\ub2e4. \uadf8\ub798\ud504\ub294 2\uac00\uc9c0\ub85c \uad6c\uc131\ub418\uc5b4 \uc788\ub2e4. \ubc14\ub85c edge \uc640 node \uc774\ub2e4. edge \ub294 \ub2e4\ucc28\uc6d0 \ud589\ub82c(tensor)\uc5d0 \ub300\uc751\ud55c\ub2e4. node \ub294 \ud150\uc11c\ub97c \uc0dd\uc131 \ub610\ub294 \ud2b9\uc815 \uaddc\uce59\uc73c\ub85c \uc870\uc791\ud55c\ub2e4.(Ops)","title":"\uacc4\uc0b0 \uadf8\ub798\ud504\ub294 \ubb34\uc5c7\uc778\uac00?"},{"location":"dl/2_dl_tensorflow/#example-of-computational-graph","text":"\uc544\ub798\uc758 \uacc4\uc0b0 \uadf8\ub798\ud504 \uc815\uc758 \ucf54\ub4dc\ub294 \ub2e4\uc74c\uacfc \uac19\uc740 \ub2e8\ubc29\ud5a5 \uadf8\ub798\ud504\ub85c \ub9cc\ub4e4\uc5b4 \uc9c8\uc218 \uc788\ub2e4. (\ud150\uc11c\ub294 \ub7f0\ud0c0\uc784\uc5d0 \ud750\ub978\ub2e4.) red = 1 blue = 2 green = red * blue pink = red + blue purple = green / pink print(purple)","title":"Example of Computational Graph"},{"location":"dl/2_dl_tensorflow/#_3","text":"\uc758\uc874\uc131\uc744 \uace0\ub824\ud55c \uc2a4\ucf00\uc974\ub9c1\uc744 \ud560 \uc218 \uc788\ub2e4. \uc704\uc758 \uadf8\ub798\ud504\ub85c\uc5d0\uc11c $a*b$ \uc640 $a+b$ \ub294 \uc758\uc874\uc131\uc774 \uc5c6\uae30 \ub54c\ubb38\uc5d0 \ub3d9\uc2dc\uc5d0 \uc2a4\ucf00\uc974\ub9c1 \ud560 \uc218 \uc788\ub2e4. $a * b$ \uc758 \uacb0\uacfc\ub9cc \uc5bb\uace0 \uc2f6\uc744 \uacbd\uc6b0 $a*b$ \ub9cc \uc2e4\ud589 \ud560 \uc218 \uc788\ub2e4. \uc758\uc874\uc131\uc774 \uc5c6\ub294 \uadf8\ub798\ud504\ub97c \ub2e4\ub978 \uba38\uc2e0\uc5d0 \uc2a4\ucf00\uc974\ub9c1 \ud560 \uc218 \uc788\ub2e4.","title":"\ub2e8\ubc29\ud5a5 \uadf8\ub798\ud504\ub85c \uc5bb\uc744 \uc218 \uc788\ub294 \uac83\ub4e4."},{"location":"dl/2_dl_tensorflow/#operation","text":"","title":"\ud150\uc11c\ud50c\ub85c\uc6b0 operation"},{"location":"dl/2_dl_tensorflow/#_4","text":"\ud150\uc11c\ud50c\ub85c\uc6b0\ub294 \uadf8\ub798\ud504\ub97c \uc815\uc758 \ud558\ub294 \uacf3\uacfc \uc2e4\ud589\ub418\ub294 \uacf3\uc774 \ub2e4\ub974\ub2e4. \uc989 \uc5b8\uc5b4\uc5d0\uc11c \uc81c\uacf5\ud558\ub294 \uc77c\ubc18\uc801\uc778 \ubcc0\uc218, \ubd84\uae30\ubb38, for\ubb38\ub4f1\uc744 \uc0ac\uc6a9 \ud560 \uc218 \uc5c6\ub2e4. \uadf8\ub807\ub2e4\uba74 \uc704\uc758 \uae30\ub2a5\uc774 \ud544\uc694\ud55c \uc0c1\ud669\uc774 \uc624\uba74 \uc5b4\ub5bb\uac8c \ud560\uac83\uc778\uac00?","title":"\uc65c \ud544\uc694 \ud55c\uac00?"},{"location":"dl/2_dl_tensorflow/#_5","text":"\ud150\uc11c\ud50c\ub85c\uc6b0\uc758 \ub178\ub4dc\ub294 ops \ub77c\uace0 \uc704\uc5d0\uc11c \uc815\uc758\ud588\ub2e4. \ud574\ub2f9 \ub178\ub4dc \uc989 ops \uc0ac\uc6a9 \ud574\uc11c \uc704\uc758 \ud544\uc694\ub97c \ub9cc\uc871\uc2dc\ucf1c \uc8fc\uba74 \ub41c\ub2e4. Variable ops: \uc804\uccb4 \ub7f0\ud0c0\uc784 \ud658\uacbd\uc5d0\uc11c \uacf5\uc720 \uac00\ub2a5\ud558\uace0 \ubcc0\uacbd \ud560 \uc218 \uc788\ub294 \uc601\uc18d\uc801 \ubcc0\uc218 Conditional ops: \ub2e4\ub978 \ubd80\ubd84\uc5d0 \uc758\ud574 \ubd84\uae30\ub418\ub294 \uacc4\uc0b0 \ucc98\ub9ac. Loop ops: \ubc18\ubcf5 \uacc4\uc0b0 Control ops: \ub450\uac1c\uc758 ops \ub4e4\uc758 \uacc4\uc0b0 \uc21c\uc11c\ub97c \uac15\uc81c Queue ops: \ube44\ub3d9\uae30 \uacc4\uc0b0\uc744 \uc704\ud574 \uc0ac\uc6a9.","title":"\ud574\uacb0\ucc45"},{"location":"dl/2_dl_tensorflow/#_6","text":"\ubaa8\ub4e0 \ud150\uc11c\ud50c\ub85c\uc6b0\ub294 \ub450\uac1c\uc758 \ub2e8\uacc4\ub85c \uc774\ub8e8\uc5b4 \uc9c4\ub2e4. - \uadf8\ub798\ud504\ub97c \uc815\uc758\ud558\ub294 \ub2e8\uacc4(tf.Graph) - \ubb3c\uae38\uc744 \ud30c\ub294 \ub2e8\uacc4 - \uc815\uc758\ub41c \uadf8\ub798\ud504\ub97c \uc2e4\ud589\ud558\ub294 \ub2e8\uacc4 (tf.Session) - \ud30c\uc9c4 \ubb3c\uae38\uc744 \ub530\ub77c \ubb3c\uc744 \ud758\ub9ac\ub294 \ub2e8\uacc4","title":"\uc815\uc758\uc640 \uc2e4\ud589"},{"location":"dl/2_dl_tensorflow/#_7","text":"\ud150\uc11c\ud50c\ub85c\uc6b0\uc758 \ubc31\ub2e8\uc740 cpp \ub85c \ub9cc\ub4e4\uc5b4\uc838 \uc788\ub2e4. \ud558\uc9c0\ub9cc \ud150\uc11c\ud50c\ub85c\uc6b0\ub294 \ud3b8\uc758\ub97c \uc704\ud574 python, cpp \ub4f1 \uc5ec\ub7ec \uc5b8\uc5b4 \uc778\ud130\ud398\uc774\uc2a4\ub97c \uc81c\uacf5\ud55c\ub2e4. cpp \ud568\uc218\uc5d0 \uc0ac\uc6a9\ub420 \uac12\uc744 \ud30c\uc774\uc36c\uc73c\ub85c \uc81c\uacf5\ud574 \uc900\ub2e4\uace0 \uc0dd\uac01\ud558\uba74 \uae30\uc874 \ud30c\uc774\uc36c \ud504\ub85c\uadf8\ub798\ubc0d\uacfc \ud150\uc11c\ud50c\ub85c\uc6b0\uc758 \uc774\uc9c8\uac10\uc744 \uc870\uae08 \uc904\uc77c \uc218 \uc788\ub2e4.","title":"\ud150\uc11c \ud50c\ub85c\uc6b0 \uc5b8\uc5b4"},{"location":"dl/2_dl_tensorflow/#variable","text":"","title":"Variable"},{"location":"dl/2_dl_tensorflow/#definition","text":"\uc804\uccb4 \ub7f0\ud0c0\uc784 \ud658\uacbd\uc5d0\uc11c \uacf5\uc720 \uac00\ub2a5\ud558\uace0 \ubcc0\uacbd \ud560 \uc218 \uc788\ub294 \uc601\uc18d\uc801 \ubcc0\uc218 - \uc815\uc758 \ud560\ub54c name, type, shape, and initialization procedure \uc744 \ubcc0\uacbd \ud560 \uc218 \uc788\ub2e4. v = tf.get_variable( \"name\", dtype=tf.float32, shape[2, 2], initializer=tf.random_normal_initializer(stddev=0.5) )","title":"Definition"},{"location":"dl/2_dl_tensorflow/#use","text":"\ub2e4\ub978 \ud150\uc11c \ucc98\ub7fc \uc0ac\uc6a9\ud558\uba74 \ub41c\ub2e4. y = tf.matmul(v, tf.constant([[1,2], [3,4]]))","title":"Use"},{"location":"dl/2_dl_tensorflow/#assign","text":"\ubcc0\uc218\uc758 \uac12\uc744 \ubcc0\uacbd \ud558\ub824\uba74 \ud560\ub2f9\ud574\uc918\uc57c \ud558\uace0 \ud560\ub2f9\ub41c \uac12\uc740 \ub2e4\uc74c \uc5c5\ub370\uc774\ud2b8 \uae4c\uc9c0 \uac12\uc744 \uc720\uc9c0 \ud55c\ub2e4. increment_op = v.assign(v + 1) # syntax 1 increment_op = tf.assign(v, v + 1) #syntax2","title":"Assign"},{"location":"dl/2_dl_tensorflow/#initialization","text":"\ubcc0\uc218 \uac12\ub4e4\uc740 \ud2b9\uc815 session \uc548\uc5d0\uc11c\ub9cc \uc720\uc9c0 \ub418\uba70 \ubcc0\uc218\ub97c \uc0ac\uc6a9\ud558\uae30 \uc704\ud574\uc11c\ub294 \ucd5c\ucd08\uc5d0 1\ud68c \ucd08\uae30\ud654 \ud574\uc8fc\uc5b4\uc57c \ud55c\ub2e4. create graph() # including variables init = tf.global_variables_initializer() # \ud55c\ubc88\uc5d0 \ubaa8\ub4e0 \ubcc0\uc218 \ucd08\uae30\ud654 with tf.Session() as session: session.run(init)","title":"Initialization"},{"location":"dl/2_dl_tensorflow/#working-with-data","text":"\ub370\uc774\ud130\ub97c \uc77d\uc5b4 \uadf8\ub798\ud504\uc5d0\uac8c \uc8fc\uc5b4\uc57c \ud560 \uacbd\uc6b0\uac00 \uc788\ub2e4. \ub9cc\uc57d \ub370\uc774\ud130\uac00 \uc791\ub2e4\uba74 \uc6b0\ub9ac\ub294 \uadf8\ub798\ud504 \uc815\uc758\uc2dc\uc810\uc5d0 \ub370\uc774\ud130\ub97c (\uba54\ubaa8\ub9ac\uc5d0 \ub85c\ub529\ud574) \uc0c1\uc218\ub85c \uc815\uc758 \ud560 \uc218 \uc788\ub2e4. d = tf.constant(<some numpy arrary>) \ub370\uc774\ud130\uac00 \uba54\ubaa8\ub9ac\ubcf4\ub2e4 \ud06c\ub2e4\uba74 \uc5d0\ub7ec\uac00 \ubc1c\uc0dd \ub428\uc73c\ub85c \ucd94\ucc9c \ud558\uc9c0 \uc54a\ub294\ub2e4. \ub610\ud55c \uadf8\ub798\ud504 \uc815\uc758\ub97c \uc800\uc7a5 \ud560 \ub54c \ub370\uc774\ud130\ub3c4 \uc800\uc7a5 \ub428\uc73c\ub85c \uc704\uc758 \ubc29\uc2dd\uc744 \uc0ac\uc6a9\ud558\uc9c0 \ub9d0\uc790.","title":"Working with data"},{"location":"dl/2_dl_tensorflow/#placeholders-and-feeds","text":"\uadf8\ub807\ub2e4\uba74 \uadf8\ub798\ud504\ub97c \uc815\uc758 \ud560 \ub54c \uac00 \uc544\ub2cc \ub7f0\ud0c0\uc784\uc5d0 \ud544\uc694 \ud560 \ub54c \ub370\uc774\ud130\ub97c \uc8fc\uac8c \ud574\ubcf4\uc790. \uadf8\ub798\ud504\ub97c \ub9cc\ub4e4\uc5b4\uc57c \ud568\uc73c\ub85c \uc5b4\ub5a4 \ub370\uc774\ud130\uac00 \ub4e4\uc5b4\uc628\ub2e4\uace0 \uc815\uc758\ud55c \uac1d\uccb4(placeholder) \ub97c \uc0ac\uc6a9\ud558\uace0 \uc2e4\uc81c \ub7f0\ud0c0\uc784\uc5d0 feed_dict \uc744 \uc0ac\uc6a9\ud574\uc11c \ub370\uc774\ud130\ub97c \uc804\ub2ec\ud558\uc790. a = tf.placeholder(tf.float32, []) b = tf.constant(1.0) c = a + b with tf.Session() as session: print(session.run(c, feed_dict={a: 3.0})) print(session.run(c, feed_dict={a: 4.0})) \ud150\uc11c\ud50c\ub85c\uc6b0\ub294 \ud50c\ub808\uc774\uc2a4 \ud640\ub354\ub97c \uc0ac\uc6a9 \ud560 \uacbd\uc6b0 session.run \ud560 \ub54c numpy array \ub85c \uad6c\uc131\ub41c dictionary \ub370\uc774\ud130 \uad6c\uc870\uac00 \ub4e4\uc5b4\uc628\ub2e4\uace0 \uae30\ub300\ud55c\ub2e4. - \ub85c\ub4dc, \uc804\ucc98\ub9ac, \ubc30\uce58, \ud050\uc789\ub4f1 \ub9c8\uc74c\ub300\ub85c \ud558\uba74\ub41c\ub2e4.(\uc790\uc720\ub3c4\uac00 \ub192\ub2e4.) - \ub610\ud55c \ud30c\uc77c, \uc2a4\ud2b8\ub9bc\ub4f1 \ubc18\ubcf5\ub418\ub294 \uc791\uc5c5\uc740 tf.data \uc5d0\uc11c \uc774\ubbf8 \ub0b4\uc7a5\ub41c \ud568\uc218\ub85c \uc81c\uacf5\ud558\uace0 \uc788\ub2e4.","title":"Placeholders and Feeds"},{"location":"dl/2_dl_tensorflow/#_8","text":"\uac04\ub2e8\ud55c \uc120\ud615 \ud568\uc218\ub97c \ubc30\uc6b0\ub294 \uc608\uc81c\ub97c \uad6c\ud604\ud574 \ubcf4\uc790. \ud55c\uac1c\uc758 \ubcc0\uc218\ub9cc \uc788\ub294 \ud68c\uadc0 \ud568\uc218\ub97c \ubc30\uc6b4\ub2e4\uace0 \ud574\ubcf4\uc790. $f(x): R \\to R$ \uc6b0\ub9ac\ub294 \ud574\ub2f9 \ud568\uc218\uac00 \uc120\ud615\uc774\ub77c\uace0 \uac00\uc815\ud55c\ub2e4. $y = wx + b$ \uadf8\ub807\ub2e4\uba74 \uc6b0\ub9ac\uac00 \ucc3e\ub294 \uc2dd\uc740 \uc544\ub798\uc758 \uc2dd\uc744 \ub9cc\uc871\ud558\ub294 $\\hat w, \\hat b$ \ub97c \ucc3e\uc73c\uba74 \ub41c\ub2e4. $$ \\hat w, \\hat b = argmin_{w, b}\\left(\\frac{\\sum(y_{i} - wx_{i} + b)^{2}}{N}\\right) $$ \uc6b0\ub9ac\uac00 \uc0ac\uc6a9\ud558\ub294 \ub370\uc774\ud130\uc14b\ub3c4 \uc120\ud615\uc2dd \uc73c\ub85c \uc218\ub834 \ud55c\ub2e4\uace0 \uac00\uc815\ud55c\ub2e4. \ub2e4\ub978 \ub9d0\ub85c \uc6b0\ub9ac\ub294 mean squared error (MSE) \ub97c \ub9cc\uc871\ud558\ub294 $\\hat w, \\hat b$\ub97c \ucc3e\uc744 \uac83\uc774\ub2e4.","title":"\uc608\uc81c"},{"location":"dl/2_dl_tensorflow/#_9","text":"\uc704\uc758 \uc2dd\uc740 \ubc29\uc815\uc2dd\uc73c\ub85c \ubc14\ub85c \ud480\uac70\ub098 \uacbd\uc0ac \ud558\uac15\ubc95(gradient descent)\uc744 \uc0ac\uc6a9 \ud560 \uc218 \uc788\ub2e4. $$ \\begin{align} \\hat w = & \\frac{\\sum_{i}(x_{i} - \\bar x)(y_{i} - \\bar y)}{\\sum_{i}(x_{i} - \\bar x)^{2}} \\\\ \\hat b = & \\bar y - w \\bar x \\\\ \\bar x = & \\frac{\\sum_{i}x_{i}}{N} \\\\ \\bar y = & \\frac{\\sum_{i}y_{i}}{N} \\\\ \\end{align} $$ \uc77c\ubc18\uc801\uc73c\ub85c \ubcf5\uc7a1\ud55c \ubb38\uc81c\uc5d0\uc11c \ubc29\uc815\uc2dd\uc73c\ub85c \uad6c\ud558\uae30 \uc5b4\ub824\uc6b4 \uacbd\uc6b0\uac00 \ub9ce\ub2e4. \uadf8\ub7ec\ubbc0\ub85c \uc6b0\ub9ac\ub294 \uc544\ub798\uc758 \uacbd\uc0ac \ud558\uac15\ubc95\uc744 \uc0ac\uc6a9\ud560 \uac83\uc774\ub2e4. $$ w_{t+1} = w_{t} - \\alpha \\frac{\\partial MSA}{\\partial w_{t}} \\\\ b_{t+1} = b_{t} - \\alpha \\frac{\\partial MSA}{\\partial b_{t}} $$ \uacbd\uc0ac\ud558\uac15\ubc95\uc774\ub780 \ub85c\uc2a4 \ud391\uc158(\uc5ec\uae30\uc11c\ub294 MSA)\uc758 \ubbf8\ubd84\uac12\uc744 \ud30c\ub77c\ubbf8\ud130\uc5d0\uc11c \uc9c0\uc18d\uc801\uc73c\ub85c \uc801\uc6a9\ud574\uc11c \ud30c\ub77c\ubbf8\ud130\uac00 \uc218\ub834 \ud560\ub54c\uae4c\uc9c0 \ubc18\ubcf5\ud558\ub294 \ubc29\ubc95\uc744 \ub9d0\ud55c\ub2e4.","title":"\ud478\ub294 \ubc29\ubc95"},{"location":"dl/2_dl_tensorflow/#_10","text":"1\ucc28\uc6d0 \ub370\uc774\ud130\ub97c \ub9cc\ub4e4\uc790. \ub370\uc774\ud130\ub97c \ub9cc\ub4e4\ub54c x \uac12\uc740 range(20) = [0,1,..,19] \ub97c \uc0ac\uc6a9\ud558\uace0 y \uac12\uc740 $y = wx + b + \\eta $ \uc5ec\uae30\uc11c $\\eta$ \uc740 \uc815\uaddc\ubd84\ud3ec\uc758\uc5d0\uc11c mean = 0, std = 1 \uc744 \uc0ac\uc6a9\ud574 \ub79c\ub364\ud558\uac8c \ub354 \ud560 \uac83\uc774\ub2e4. code","title":"\ub370\uc774\ud130\ub97c \ub9cc\ub4e4\uc5b4\ubcf4\uc790."},{"location":"dl/2_dl_tensorflow/#automatic-differentiation","text":"\uacbd\uc0ac \ud558\uac15\ubc95\uc740 \ubbf8\ubd84\uc744 \ud544\uc694\ub85c \ud558\uace0 composition function \uc758 \uacbd\uc6b0 chain rule \uc0ac\uc6a9\ud574 \ubbf8\ubd84\uc744 \ud574\uc57c\ud55c\ub2e4. \ud150\uc11c \ud50c\ub85c\uc6b0\ub294 \uc2dc\uc2a4\ud15c\uc5d0\uc11c \uc790\ub3d9\uc73c\ub85c \ubbf8\ubd84\uc2dd\uc744 \uc81c\uacf5 \ud574\uc900\ub2e4.","title":"Automatic Differentiation"},{"location":"dl/2_dl_tensorflow/#gradients","text":"tf.gradients \ud568\uc218\ub97c \uc774\uc6a9\ud574\uc11c \uacbd\uc0ac \ud558\uac15\ubc95\uc744 \uc0ac\uc6a9\ud558\uc790. grads = tf.gradients(my_tensor, var_list) grads \uc548\uc5d0\ub294 len(var_list)\uc758 \uae38\uc774\uc640 \uac19\uc740 \ud150\uc11c\uac00 \ub4e4\uc5b4\uc788\ub2e4. \uc774 \ud150\uc11c \uac01\uac01\uc758 var_list \uc758 \ubcc0\uc218\ub97c my_tensor \ud3b8\ubbf8\ubd84\ud55c \uc2dd\uc774\ub2e4. \ub9cc\uc57d var_list \uc548\uc5d0 my_tensor \uc5d0 \uc758\uc874 \ud558\uc9c0 \uc54a\ub294 \ubcc0\uc218\uac00 \uc788\ub2e4\uba74 grads \uc758 \ud574\ub2f9 \uac12\uc740 None \uc774\ub2e4.","title":"Gradients"},{"location":"dl/2_dl_tensorflow/#loss-function","text":"# ytf \uc640 model_output \uc73c\ub85c MSA loss function \uc744 \ub9cc\ub4e4\uc5b4\ub77c. loss = tf.losses.mean_squared_error(ytf, model_output) # \ub85c\uc2a4 \ud391\uc158\uc5d0 \ub300\ud574\uc11c w, b \uc5d0 \ub300\ud55c \ud3b8\ubbf8\ubd84 \ud568\uc218\ub97c \ub9cc\ub4e4\uc5b4\ub77c. grads = tf.gradients(loss, [model.w, model.b]) update_w = tf.assign(model.w, model.w - 0.001 * grads[0]) update_b = tf.assign(model.b, model.b - 0.001 * grads[1]) update = tf.group(update_w, update_b) code","title":"Loss function"},{"location":"dl/2_dl_tensorflow/#optimizer","text":"update \uad00\ub828 \uc791\uc5c5\ub3c4 tf.train.Optimizer \ub85c \ucd94\uc0c1\ud654 \ub418\uc5b4 \uc788\ub2e4. \uc544\ub798\uc640 \uac19\uc774 \uc0ac\uc6a9 \ud558\ub294\uac78 \uad8c\uc7a5\ud558\uba70 \uc790\ub9e4\ud488 AdamOptimizer, RMSPropOptimizer \ub3c4 \uc788\ub2e4. loss = tf.losses.mean_squared_error(ytf, model_output) update = tf.train.GradientDescentOptimizer(learning_rate=0.001).minimize(loss) code","title":"Optimizer"},{"location":"dl/2_dl_tensorflow/#control-logic","text":"tf.control_dependencies: \ub178\ub4dc \uc0ac\uc774\uc5d0 \uc758\uc874\uc131\uc744 \ucd94\uac00. tf.conf: true/false \ubd84\uae30 tf.case: multi-case \ubd84\uae30 tf.while_loop: while loop \uc774\ud574\ud558\uae30\ub294 \uc5b4\ub835\uc9c0\ub9cc RL\uc744 \uc704\ud574\uc11c \uaf2d \ud544\uc694\ud568.","title":"Control Logic"},{"location":"dl/2_dl_tensorflow/#control-dependencies","text":"x = tf.get_variable('x', shape=(), initializer=tf.zeros_initializer()) assign_x = tf.assign(x, 10.0) # z = tf.assign(x, 10.0) + 1.0 z = x + 1.0 with tf.train.MonitoredSession() as sess: print(sess.run(z)) # \uacb0\uacfc \uac12\uc740 1.0 and assing_x \ub294 z \uc5d0 \uc758\uc874\uc131\uc774 \uc5c6\uc74c\uc73c\ub85c \uc2e4\ud589 \uc548\ub428 with tf.train.MonitoredSession() as sess: print(sess.run([assign_x, z])) # \ud150\uc11c \ud50c\ub85c\uc6b0\ub294 fetchs \ub9ac\uc2a4\ud2b8\uc5d0 \uc778\ub371\uc2a4 \uc21c\uc11c\ub300\ub85c \uc2e4\ud589\ud558\uc9c0 \uc54a\uc74c! # \uacb0\uacfc \uac12\uc740 (10.0, 1.0) \ub610\ub294 (10.0, 11.0) \uc774\ub428 assign_x \uc640 z \uac00 \ub808\uc774\uc2a4 \ucee8\ub514\uc158\uc774 \ub428. with tf.control_dependencies([assign_x]): z = x + 1.0 with tf.train.MonitoredSession() as sess: print(sess.run(z)) # z \ub97c assign_x \uc5d0 \uc758\uc874 \ud558\ub3c4\ub85d \uc124\uc815\ud588\uae30 \ub54c\ubb38\uc5d0 z \ub97c \uc2e4\ud589\ud558\uba74 assign_x \uac00 \uba3c\uc800 \uc2e4\ud589\ub428. 11.0 code","title":"Control dependencies"},{"location":"dl/2_dl_tensorflow/#conditional-evaluation","text":"v1 = tf.get_variable('v1', shape=(), initializer=tf.zeros_initializer()); v2 = tf.get_variable('v2', shape=(), initializer=tf.zeros_initializer()); switch = tf.placeholder(tf.bool) cond = tf.cond(switch, lambda: tf.assign(v1, 1.0), # true lambda: tf.assign(v2, 2.0)) # false with tf.train.MonitoredSession() as sess: sess.run(cond, feed_dict={switch: False}) print(sess.run([v1, v2])) # [0.0, 2.0] v3 = tf.get_variable('v3', shape=(), initializer=tf.zeros_initializer()); v4 = tf.get_variable('v4', shape=(), initializer=tf.zeros_initializer()); switch = tf.placeholder(tf.bool) assign_v3 = tf.assign(v3, 1.0) assign_v4 = tf.assign(v4, 1.0) # \ucee8\ub514\uc158\uc744 \ub9cc\ub4e4\uae30 \uc704\ud574 \ud544\uc694\ud55c \uc758\uc874\uc131\uc740 \uba3c\uc800 \uc2e4\ud589\ub41c\ub2e4. # \uc989 assign_v4 \uc640 assign_v4 \ub294 cond \ub97c \ub9cc\ub4dc\ub294\ub300 \ud544\uc694\ud568\uc73c\ub85c # \ud574\ub2f9 op \ub97c \ub9cc\ub4dc\ub294 \uc704\uc758 \ub450\uac1c\uc758 \ud560\ub2f9\ubb38\uc774 \uc2e4\ud589\ub41c\ub2e4. cond = tf.cond(switch, lambda: assign_v3, lambda: assign_v4) with tf.train.MonitoredSession() as sess: sess.run(cond, feed_dict={switch: False}) print(sess.run([v3, v4])) # [1.0, 1.0] code","title":"Conditional evaluation."},{"location":"dl/2_dl_tensorflow/#while","text":"k = tf.constant(2) matrix = tf.ones([2, 2]) condition = lambda i, _: i < k body = lambda i, m: (i+1, tf.matmul(m, matrix)) final_i, power = tf.while_loop( cond=condition, body=body, loop_vars=(0, tf.diag([1., 1.])) ) # loop 1 # i = 0 => i = 1 # m * matrix => m # [[1, 0] [[1, 1] [[1, 1] # [0, 1]] * [1, 1]] => [1, 1]] # loop 2 # i = 1 => i = 2 # m * matrix => m # [[1, 1] [[1, 1] [[2, 2] # [1, 1]] * [1, 1]] => [2, 2]] # i < 2 break; with tf.train.MonitoredSession() as sess: print(sess.run([final_i, power])) # [2, [[2, 2], [2, 2]]] code","title":"While"},{"location":"dl/2_dl_tensorflow/#dynamic-unrolling","text":"\ub525\ub7ec\ub2dd\uacfc RL \uc5d0\uc11c \ud2b9\uc815 \uc0c1\ud0dc\uc5d0 \uac19\uc740 transformaion \uc744 \ud574\uc11c \ub204\uc801 \uc2dc\ud0a4\ub294 \ud589\uc704\ub294 \uc790\uc8fc \uc77c\uc5b4\ub09c\ub2e4. \uc608\ub97c\ub4e4\uc5b4 Time series prediction Sequence to sequence models Take decisions in partially observable domains \ud150\uc11c \ud50c\ub85c\uc6b0\uc5d0\uc11c ad-hoc \uc720\ud2f8\ub9ac\ud2f0 \ud568\uc218\ub97c \uc81c\uacf5\ud55c\ub2e4.","title":"Dynamic Unrolling"},{"location":"dl/2_dl_tensorflow/#fibnacci-number","text":"\uc704\uc758 \ub204\uc801 \uc608\uc81c\ub85c \ud53c\ubcf4\ub098\uce58 \uc218\uc5f4\uc744 \ub4e4\uc5b4\ubcf4\uc790. \ud53c\ubcf4\ub098\uce58 \uc218\uc5f4\uc740 $0, 1, 1, 2, 3, 5.. $ \uac19\uc740 \uc218\uc5f4\uc744 \ub9d0\ud55c\ub2e4. \ucd08\uae30\uac12 (0, 1) \uc744 \uc8fc\uba74 \ub2e4\uc74c \uc218\ubd80\ud130\ub294 \uc774\uc804 \ub450 \uc218\uc758 \ud569\uc73c\ub85c \ub2e4\uc74c \uc218\ub97c \uad6c \ud560 \uc218 \uc788\ub2e4. \uc989 \uc774\uc804 \ub450\uac1c\uc758 \uc0c1\ud0dc\uac12\ub9cc \uae30\uc5b5\ud558\uba74 \ub418\ub294\uac83\uc774\ub2e4. $$ F_{0} = 0, F_{1} = 1, \\\\ F_{n} = F_{n-1} + F_{n-2}, \\\\ \\text{for } n > 1. $$ def fibonacci(state): output = state[0] + state[1] return output, (state[1], output) state = (0, 1) # (f_{0}, f_{1}) for item in range(10): output, state = fibonacci(state) #f_n, (f_{n-2}, f_{n-1}) print(output) # \uc54c\uace0\ub9ac\uc998\uc740 \uc704\uc640 \uac19\uace0 \ud150\uc11c \ud50c\ub85c\uc6b0 \uad6c\ud604\uc740 \uc544\ub798 \ucf54\ub4dc\ub97c \ucc38\uc870\ud558\uc790. code","title":"\uc608\uc81c Fibnacci number"},{"location":"dl/2_dl_tensorflow/#advanced-features","text":"\ud150\uc11c \ud50c\ub85c\uc6b0\ub294 \uc704\uc5d0 \uc124\uba85 \ub9d0\uace0\ub3c4 \ub9ce\uc740 \ub2e4\ub978 \uae30\ub2a5\ub4e4\uc744 \uc81c\uacf5\ud55c\ub2e4. \ub7f0\ud0c0\uc784 \ub77c\uc774\ube14\ub7ec\ub294 \uc544\ub798\uc640 \uac19\uc740 \uae30\ub2a5\ub3c4 \uc81c\uacf5\ud55c\ub2e4. \uba40\ud2f0\ucf54\uc5b4 CPU \uc5d0\uc11c \uba40\ud2f0 \uc4f0\ub808\ub4dc \uc2e4\ud589\uc744 \ud560 \uc218 \uc788\ub2e4. GPU \uc5d0\uc11c \uacc4\uc0b0\uc744 \uc2dc\ud0ac \uc218\ub3c4 \uc788\ub2e4. \ubd84\uc0b0 \ud658\uacbd\uc5d0\uc11c \uc5ec\ub7ec \uba38\uc2e0\uc5d0 \uac78\uccd0 \uc2e4\ud589 \uc2dc\ud0ac\uc218\ub3c4 \uc788\ub2e4. Annotate \ub97c \uadf8\ub798\ud504\uc5d0 \uba85\uc2dc\ud574\uc8fc\uba74 \uc704\uc758 \uae30\ub2a5\ub4e4\uc744 \ud150\uc11c\ud50c\ub85c\uc6b0\uac00 \uc54c\uc544\uc11c \ucc98\ub9ac\ud574\uc900\ub2e4. with tf.device(\"/cpu:0\"): a = tf.assign(..) b = tf.assign(..) with tf.device(\"/gpu:0\"): c = tf.matfmul(a, b) with tf.Session() as sess: sess.run(c) \ud560\ub2f9\ud558\uc9c0 \uc54a\uc544\ub3c4 gpu \uac00 \uac00\ub2a5\ud558\uba74 gpu \uc5d0\uc11c \uc2e4\ud589 \ud55c\ub2e4.","title":"Advanced Features"},{"location":"dl/2_dl_tensorflow/#reference","text":"Assignment \ucc38\uc870","title":"Reference"},{"location":"dl/3_dl_1_mnist/","text":"3.1 MNIST Goal \uc22b\uc790 \uc774\ubbf8\uc9c0\ub97c \uc8fc\uc5c8\uc744\ub54c \ud574\ub2f9 \uc22b\uc790\ub97c \ub9ac\ud134\ud558\ub294 \ud568\uc218\ub97c \ub9cc\ub4e4\uc5b4 \ubcf4\uc790. def predict(img): //\uc774\ubbf8\uc9c0\ub97c \uac00\uc9c0\uace0 \uc22b\uc790\ub97c \uacb0\uc815 return num # (0-9) Data set MNIST SubGoal \ud568\uc218\ub97c \ud6c8\ub828\ud55c\ub2e4. \ud6c8\ub828\ud558\ub294 \uadf8\ub798\ud504\ub97c \ubcf8\ub2e4. \uc608\uce21\ud55c\ub2e4. \ud3c9\uac00\ud55c\ub2e4. Term epoch: entire dataset is passed through NN only once. Model 1 x -> softmax(linear) -> y $x_{784} \\to h_{10} \\to y_{10}$ loss = sum(softmax_cross_entropy_with_logits) optimizer = GradientDescentOptimizer $$ \\begin{align} \\text{input } = & \\ x_{m,784} \\\\ h_{m,32} = & \\ \\text{softmax}(x_{m,32} W_{32,10} + b_{10}) \\\\ \\text{output } = & \\ y_{m, 10} \\end{align} $$ Model 2 x -> relu(linear) -> softmax(linear) -> y $x_{784} \\to h_{32}^{(1)} \\to h_{10}^{(2)} \\to y_{10}$ loss = sum(softmax_cross_entropy_with_logits) optimizer = GradientDescentOptimizer $$ \\begin{align} \\text{input } = & \\ x_{m,784} \\\\ h_{m,32}^{(1)} = & \\ \\text{relu}(x_{m,784} W_{784,32}^{(1)} + b_{32}^{(1)}) \\\\ h_{m,10}^{(2)} = & \\ \\text{softmax}(h_{m,32}^{(1)} W_{32,10}^{(2)} + b_{10}^{(2)}) \\\\ \\text{output } = & \\ y_{m, 10} \\end{align} $$ code Model 3 x -> relu(linear) -> relu(linear) -> softmax(linear) -> y $ x_{784} \\to h_{32}^{(1)} \\to h_{32}^{(2)} \\to h_{10}^{(3)} \\to y_{10}$ $$ \\begin{align} \\text{input } = & \\ x_{m,784} \\\\ h_{m,32}^{(1)} = & \\ \\text{relu}(x_{m,784} W_{784,32}^{(1)} + b_{32}^{(1)}) \\\\ h_{m,32}^{(2)} = & \\ \\text{relu}(x_{m,32} W_{32,32}^{(2)} + b_{32}^{(1)}) \\\\ h_{m,10}^{(3)} = & \\ \\text{softmax}(h_{m,32}^{(2)} W_{32,10}^{(3)} + b_{10}^{(3)}) \\\\ \\text{output } = & \\ y_{m, 10} \\end{align} $$","title":"3.1 MNIST"},{"location":"dl/3_dl_1_mnist/#31-mnist","text":"","title":"3.1 MNIST"},{"location":"dl/3_dl_1_mnist/#goal","text":"\uc22b\uc790 \uc774\ubbf8\uc9c0\ub97c \uc8fc\uc5c8\uc744\ub54c \ud574\ub2f9 \uc22b\uc790\ub97c \ub9ac\ud134\ud558\ub294 \ud568\uc218\ub97c \ub9cc\ub4e4\uc5b4 \ubcf4\uc790. def predict(img): //\uc774\ubbf8\uc9c0\ub97c \uac00\uc9c0\uace0 \uc22b\uc790\ub97c \uacb0\uc815 return num # (0-9)","title":"Goal"},{"location":"dl/3_dl_1_mnist/#data-set","text":"MNIST","title":"Data set"},{"location":"dl/3_dl_1_mnist/#subgoal","text":"\ud568\uc218\ub97c \ud6c8\ub828\ud55c\ub2e4. \ud6c8\ub828\ud558\ub294 \uadf8\ub798\ud504\ub97c \ubcf8\ub2e4. \uc608\uce21\ud55c\ub2e4. \ud3c9\uac00\ud55c\ub2e4.","title":"SubGoal"},{"location":"dl/3_dl_1_mnist/#term","text":"epoch: entire dataset is passed through NN only once.","title":"Term"},{"location":"dl/3_dl_1_mnist/#model-1","text":"x -> softmax(linear) -> y $x_{784} \\to h_{10} \\to y_{10}$ loss = sum(softmax_cross_entropy_with_logits) optimizer = GradientDescentOptimizer $$ \\begin{align} \\text{input } = & \\ x_{m,784} \\\\ h_{m,32} = & \\ \\text{softmax}(x_{m,32} W_{32,10} + b_{10}) \\\\ \\text{output } = & \\ y_{m, 10} \\end{align} $$","title":"Model 1"},{"location":"dl/3_dl_1_mnist/#model-2","text":"x -> relu(linear) -> softmax(linear) -> y $x_{784} \\to h_{32}^{(1)} \\to h_{10}^{(2)} \\to y_{10}$ loss = sum(softmax_cross_entropy_with_logits) optimizer = GradientDescentOptimizer $$ \\begin{align} \\text{input } = & \\ x_{m,784} \\\\ h_{m,32}^{(1)} = & \\ \\text{relu}(x_{m,784} W_{784,32}^{(1)} + b_{32}^{(1)}) \\\\ h_{m,10}^{(2)} = & \\ \\text{softmax}(h_{m,32}^{(1)} W_{32,10}^{(2)} + b_{10}^{(2)}) \\\\ \\text{output } = & \\ y_{m, 10} \\end{align} $$ code","title":"Model 2"},{"location":"dl/3_dl_1_mnist/#model-3","text":"x -> relu(linear) -> relu(linear) -> softmax(linear) -> y $ x_{784} \\to h_{32}^{(1)} \\to h_{32}^{(2)} \\to h_{10}^{(3)} \\to y_{10}$ $$ \\begin{align} \\text{input } = & \\ x_{m,784} \\\\ h_{m,32}^{(1)} = & \\ \\text{relu}(x_{m,784} W_{784,32}^{(1)} + b_{32}^{(1)}) \\\\ h_{m,32}^{(2)} = & \\ \\text{relu}(x_{m,32} W_{32,32}^{(2)} + b_{32}^{(1)}) \\\\ h_{m,10}^{(3)} = & \\ \\text{softmax}(h_{m,32}^{(2)} W_{32,10}^{(3)} + b_{10}^{(3)}) \\\\ \\text{output } = & \\ y_{m, 10} \\end{align} $$","title":"Model 3"},{"location":"dl/3_dl_neural_net/","text":"3. Neural Networks Foundations Overview. NN \uc740 \uc120\ud615 \ubcc0\ud658\ub4e4\uacfc + \ube44 \uc120\ud615 \ud568\uc218\ub4e4\uc758 \uc870\ud569 \uc774\ub2e4. - NN\uc758 \uc7a5\uc810\uacfc \uc720\uc5f0\ud568\uc740 \uc704\uc758 \uac04\ub2e8\ud55c \ubaa8\ub4c8\ub4e4\uc744 \ub300\uaddc\ubaa8\ub85c \uad6c\uc131\ud558\uc5ec \uc0ac\uc6a9 \ud568\uc5d0 \uc788\ub2e4. - \ud559\uc2b5\uc774\ub780? - loss function \uc744 \ub370\uc774\ud130\uc5d0 \ub9de\uac8c \ucd5c\uc801\ud654 \uc2dc\ud0a4\ub294\uac78 \uc758\ubbf8\ud55c\ub2e4. - \ubcf4\ud1b5 \ubbf8\ubd84\uc758 \uc5f0\uc1c4 \ubc95\uce59 \uadf8\ub9ac\uace0 SGD \ub97c \uc0ac\uc6a9\ud574 \ucd5c\uc801\ud654 \ud55c\ub2e4. \uc0ac\uc6a9\ucc98 \ucef4\ud4e8\ud130 \ube44\uc804 \uc74c\uc131\uc778\uc2dd, \uae30\uacc4\ubc88\uc5ed text to speech RL (DQN/A3C) \uc790\uc728\uc8fc\ud589\ucc28 \ub4f1. \uc6b0\ub9ac\uac00 \ub9cc\ub4e4\ub824\uace0 \ud558\ub294 nn \uc740 \uc704\uc758 \uc2dd\uc73c\ub85c \ud45c\ud604 \ud560 \uc218 \uc788\ub2e4. Road map Single layer networks Networks with one hidden layer Modern deep nets nn \uc744 \ucef4\ud4e8\ud130 \uadf8\ub798\ud504 \ud45c\ud604\uc73c\ub85c. Learing Chain rule Modualr backprop & automatic differentiation Module zoo: layers and losses \ud604\uc5c5\uc5d0\uc11c \uc0ac\uc6a9\ud558\ub294 \ud301 \uba85\uce6d\uad00\ub828 \uc8fc\uc758 neuron == unit \ube44\uc120\ud615 == activation function (\uc120\ud615 \ubcc0\ud658 + \ube44 \uc120\ud615) \uc744 \ud569\uccd0\uc11c layer \ub77c\uace0 \ubd80\ub978\ub2e4. \uc18c\ud504\ud2b8\uc6e8\uc5b4\uc5d0\uc11c\ub294 atomic ops \ub97c layer \ub77c\uace0 \ubd80\ub978\ub2e4. Single layer networks Linear layer Sigmoid activiation function layer Binary classification / logistic regression \ub9ac\ubdf0 Multi-way descisions: softmax layer Rectified(put currect) linear layers (relu) Linear layer \ub3d9\uc758\uc5b4\"fully connecnted\" \ub610\ub294 \"dense\" layers \uc778\uac04\uc758 \ub1cc\ub97c \uad6c\uc131\ud558\uace0 \uc788\ub294 \uc2e0\uacbd \uc138\ud3ec\ub97c \ubcf4\uba74 \uc218\uc0c1\ub3cc\uae30\ub97c \ud1b5\ud574 \uc5ec\ub7ec\uac1c\uc758 \uc778\ud48b\uc744 \ubc1b\uc544 \ucd95\uc0ad\ub9d0\ub2e8\uc744 \ud1b5\ud574 \uc5ec\ub7ec\uac1c\uc758 \uc544\uc6c3\ud48b\uc744 \uc0dd\uc131\ud55c\ub2e4. - \uc704\uc758 \ud604\uc0c1\uc744 \ubaa8\ub378\ub9c1 \ud574\ubcf4\uc790. input ouptput \uc815\uc758 2\uac1c\uc758 \uc778\ud48b\uc744 \ubc1b\uc544 \ud558\ub098\uc758 \uc544\uc6c3\ud48b\uc744 \uc0dd\uc131\ud55c\ub2e4. \uc6b0\ub9ac\ub294 $x_{1}$\uacfc $x_{2}$ \ub97c \ubc1b\uc544. $y_{1}$ \uc744 \ub9cc\ub4e4\ub824\uace0 \ud55c\ub2e4. \uc6b0\ub9ac\ub294 \uc544\ub798\uc640 \uac19\uc774 \uc815\uc758 \ud560 \uac83 \uc774\ub2e4. \uc544\uc6c3\ud48b \ud558\ub098\uc5d0 \ub300\ud574 \uc544\ub798\uc640 \uac19\uc774 \uc815\uc758 \ud558\uc790. $$ f: R^{n} \\to R \\\\ y = \\sum_{i}^{n}w_{i}x_{i} + b $$ \uadf8\ub807\ub2e4\uba74 \uc2e0\uacbd \uc138\ud3ec\ub294 \uc544\ub798\uc640 \uac19\uc774 \ud589\ub82c\uacfc \ubca1\ud130\uc758 \ub0b4\uc801\uc73c\ub85c \uc815\uc758 \ud560 \uc218 \uc788\ub2e4. $$ f: R^{n} \\to R^{m} \\\\ y = Wx + b $$ Sigmoid layer Activation function \uc911 \ud558\ub098. $f: R \\to R$ \ud568\uc218 \uc774\uba70 $-\\infty \\leq x \\leq +\\infty$ \ub97c input \uc73c\ub85c \ubc1b\uc544 $0 \\leq y \\leq 1$ \uc758 \uac12\uc744 \ub9ac\ud134\ud55c\ub2e4. $$\\sigma = \\frac{1}{1 + e^{-x}}$$ \uc120\ud615 \ubcc0\ud658\uc774 \uc544\ub2c8\uae30 \ub54c\ubb38\uc5d0 \ube44\uc120\ud615 \ud568\uc218\ub77c\uace0 \ud55c\ub2e4. \uc778\uacf5 \ub274\ub860 \uc774\uc81c \uc704\uc758 linear layer \uc640 activation layer(sigmoid) \ub97c \ud569\uce58\uba74 \uc778\uacf5 \ub274\ub860\uc774 \ub41c\ub2e4. - \uc9c0\uae08\uc740 \ud55c\uac1c\uc758 x vector \uc5d0 \ub300\ud574 feed forwarding \ud558\ub294 \ubd80\ubd84\ub9cc \uace0\ub824\ud558\uae30 \ub54c\ubb38\uc5d0 x, y \ub294 1\ucc28\uc6d0 \ubca1\ud130\uc774\ub2e4. $$ y = \\sigma \\left( \\sum_{i}w_{i}x_{i}+b\\right) \\\\ y = \\sigma (Wx + B) $$ input X \ub97c \ubc1b\uc544 output Y \ub85c \ubcc0\ud615(transformation)\ud558\ub294 \ud568\uc218(\uc778\uacf5 \ub274\ub860) \uc740 \uc544\ub798 \uadf8\ub9bc\uc5d0\uc11c $\\to$ \ub85c \ud45c\ud604\ub418\uc5c8\ub2e4. \uc544\ub798 \uadf8\ub9bc\uc740 1\ub2e8 \ub808\uc774\uc5b4\ub97c \ub3c4\uc2dd\ud654 \ud55c \uac83\uc774\ub2e4. \uc704\uc758 \ub274\ub860\uc744 \uad6c\ud604\ud558\uace0 W \uac12\uc744 \uad6c\ud558\uba74 \uc6b0\ub9ac\ub294 binary classification\uc744 \ud560 \uc218 \uc788\ub2e4. \uc544\ub798\ub294 $x_{1}, x_{2}$ \ub85c \uad6c\uc131\ub41c \uc810\ub4e4\uc744 \uc8fc\uace0 \ud6c8\ub828\uc744 \uc2dc\ud0a8\ub2e4. \uadf8\ub7ec\uba74 \uc774\ud6c4 \uc0c8\ub85c\uc6b4 $x_{1}, x_{2}$ \uc744 \uc8fc\uba74 \ub2f5\uc744 \uc608\uce21 \ud560 \uc218 \uc788\ub2e4. X = [(-1, -4),...,(4, 4)] //training data \uadf8\ub9bc\uc5d0\uc11c\ub294 X[i][0] \uc744 x \ucd95 \uac12, X[i][1] \uc744 y \ucd95 \uac12 \uc73c\ub85c \uc0ac\uc6a9\ud574\uc11c \ud45c\uae30 y = [(yellow),...,(blue)] // X \uc5d0 \ub300\uc751\ud558\ub294 label model = train(X, y) // w\ub97c \uad6c\ud568 \uc544\ub798\uc5d0\uc11c \uc124\uba85\ud568. model.predict((5, 5)) // \uad6c\ud574\uc9c4 w\uc5d0 \uc704\uc5d0 \uc815\uc758\ud55c \uc778\uacf5 \ub274\ub860\uc744 \uc0ac\uc6a9\ud574 \ub2f5\uc744 \uc608\uce21. blue Playground.tensorflow Softmax layer Multi-classs classificaion \uc5d0\uc11c \uc720\uc6a9\ud568. $$ y = \\text{softmax}(x), \\text{where: } y_{i} = \\frac{e^{x_{i}}}{\\sum_{j=1}^{K}e^{x_{j}}} \\tag{3.1} $$ argmax \ud568\uc218 input array \uc744 \uc8fc\uba74 input \uacfc \uac19\uc740 \ud06c\uae30\uc758 array \ub97c \ub9ac\ud134 y \uac12\uc740 x \uac12 \uc911 \uac00\uc7a5 \ud070 \uac12\ub9cc 1, \ub098\uba38\uc9c0\ub294 0 \uc73c\ub85c \ub3cc\ub824\uc90c \ubaa8\ub4e0 y \uac12\uc744 \ud569\ud558\uba74 1 y = argmax([1, 1, 8]) // y = [0, 0, 1] sum(y) // 1 softmax soft argmax \ud568\uc218\ub77c\uace0 \uc0dd\uac01\ud574\ub3c4 \ub428. input array \uc744 \uc8fc\uba74 input \uacfc \uac19\uc740 \ud06c\uae30\uc758 array \ub97c \ub9ac\ud134 y \uac12\uc740 x \uac12 \uc911 \uac00\uc7a5 \ud070 \uac12\uc740 1\uc5d0 \uac00\uae5d\uac8c , \ub098\uba38\uc9c0\ub294 0 \uc5d0 \uac00\uae5d\uac8c \ub3cc\ub824\uc90c \ubaa8\ub4e0 y \uac12\uc744 \ud569\ud558\uba74 1 \ud569\ud558\uba74 1\uc774 \ub418\uae30 \ub54c\ubb38\uc5d0 \ud655\ub960\ub85c \uc0dd\uac01 \ud560 \uc218 \uc788\uc74c y = softmax([1, 1, 8]) // \ub300\ub7b5 y = [0.001, 0.001, 0.998] // \uc2e4\uc81c y = [9.10221936e-04, 9.10221936e-04, 9.98179556e-01] sum(y) // 1 Softmax and cross-entropy / NLL loss \uc608\uce21 \uc6b0\ub9ac\ub294 Linear layer + softmax \uc744 \ud569\uce58\uba74multinomial logistic regression \ub610\ub294 multi-class classification \uc774 \uac00\ub2a5\ud574\uc9c4\ub2e4. $$ y_{i} = \\frac{e^{\\sum_{j}w_{ij}x_{j} + b_{i}}}{\\sum_{k=1}^{K}e^{\\sum_{j}w_{kj}x_{j} + b_{k}}} $$ \uc704\uc758 \uc2dd\uc744 \uc0ac\uc6a9\ud574 nn\uc744 \uad6c\uc131 \ud560 \uc218 \uc788\ub2e4. MNIST \ub370\uc774\ud130\uc5d0 \uc801\uc6a9\ud55c\ub2e4\uace0 \uc0dd\uac01\ud574\ubcf4\uc790. input: 0~9 \uae4c\uc9c0\uc758 \uc190\uae00\uc528 \uc0ac\uc9c4. output: 0~9 \uae4c\uc9c0\uc758 \uc190\uae00\uc528 \uc0ac\uc9c4\uc774 \ub098\ud0c0\ub0b4\ub294 \uc22b\uc790. //\uc608\uc81c\ub97c \uac04\ub2e8\ud558\uac8c \ud558\uae30 \uc704\ud574 0~2\ubc88\uae4c\uc9c0\uc758 \uc22b\uc790\ub85c \uad6c\uc131\ub41c \uc0ac\uc9c4\ub9cc \uc788\ub2e4\uace0 \ud574\ubcf4\uc790. X = [(raw values represent 2),...,(raw values represent 1)] //training data y = [(0,0,1),...,(0,1,0)] // X \uc5d0 \ub300\uc751\ud558\ub294 label model = train(X, y) // w\ub97c \uad6c\ud568 \uc544\ub798\uc5d0\uc11c \uc124\uba85\ud568. model.predict((raw values represent 0)) // (1, 0, 0) \uc744 \ud574\uc11d\ud558\uba74 0 \uc784\uc744 \uc54c \uc218 \uc788\uc74c. \ud559\uc2b5 loss function \uc73c\ub85c negative log likelihood(NLL) / cross-entropy of true labels \uc744 \uc0ac\uc6a9 \ud55c\ub2e4. $$ NLL(t, y) = Xent(t, y) = - \\sum_{t}^{classes:C} t_{i}\\text{log }y_{i} $$ Rectified-linear layer \ucd5c\uc18c 0, \uc544\ub2c8\uba74 $x_{i}$ $$ y = relu(x) \\text{, where:} y_{i} = \\text{maximum}(0, x_{i}) $$ Networks with one hidden layer \uc778\ud48b\uc744 \uc120\ud615\uc73c\ub85c \ubd84\ub9ac \ubd88\uac00\ub2a5 \ud560\ub54c \uc0ac\uc6a9. Hindden layer nets \uc740 \"universal function approximators\" \ub77c\uace0 \ub3c4 \ud568. hidden layer == linear + non-linearity == separte layers == modules Hidden Layers Single hidden layer (linear + non-linear) Hidden.h \uccab\ubc88\uc9f8 \uc120\ud615 \ubcc0\ud658 \uc2dd\uc758 \uc544\uc6c3\ud48b\uc774\ub2e4. \uc544\uc6c3\ud48b\uc774 \ub2e4\ub978 \ub808\uc774\uc5b4\uc758 \uc778\ud48b\uc774 \ub41c\ub2e4. \uc704\uc640 \uac19\uc774 \uad6c\uc131\ud558\uba74 \uc778\ud48b\uc744 \ub2e4\ub978 \ubc29\uc2dd\uc73c\ub85c \ud45c\ud604 \ud560 \uc218 \uc788\ub2e4. \uc6b0\ub9ac\uc758 \ubb38\uc81c\uac00 \uc120\ud615 \ubcc0\ud658\uc744 \ud1b5\ud574 \uc0dd\uc131\ub41c \uc911\uac04 \ud45c\ud604\ud615 \uc5d0\uc11c\ub294 \uc2ec\ud50c \ud574\uc9c0\uae38 \uae30\ub300 \ud560 \uc218 \uc788\ub2e4. \ubb38\uc81c\ub97c \uc8fc\uc5b4\uc9c4 \uc778\ud48b\uc5d0\uc11c \ubc14\ub85c \ud478\ub294\uac8c \uc544\ub2c8\ub77c \uc5f0\uc18d\uc801\uc778 \ubcc0\ud615\uc744 \ud1b5\ud574\uc11c \ubb38\uc81c\uac00 \uc26c\uc6cc\uc9c0\uae38 \uae30\ub300 \ud560 \uc218 \uc788\ub2e4. \uc608\ub97c \ub4e4\uc5b4 input \uc5d0\uc11c\ub294 \uc120\ud615 \ubd88\ub9ac\uac00 \ubd88\uac00\ub2a5\ud558\uc9c0\ub9cc \uc911\uac04 \ud45c\ud604\ud615\uc5d0\uc11c\ub294 \uc120\ud615 \ubd84\ub9ac\uac00 \uac00\ub2a5 \ud558\uac8c \ubcc0\ud658 Example \uc544\ub798\uc640 \uac19\uc740 \uc778\ud48b \ud45c\ud604\uc744 \uc120\ud615 \ubcc0\ud658\uc744 \ud1b5\ud574 \ud788\ub4e0 \ub808\uc774\uc5b4\uc5d0\uc11c \ub2e4\ub978 \ud45c\ud604\uc73c\ub85c \ubc14\uafc0\uc218 \uc788\ub2e4. \uc778\ud48b \ud45c\ud604\ud615 \uc5d0\uc11c\ub294 \uc120\ud615\uc73c\ub85c \uad6c\ubd84\uc774 \ubd88\uac00\ub2a5 \ud55c\ubc88\uc758 \uc120\ud615 \ubcc0\ud658 \ud6c4 \ud788\ub4e0\ub808\uc774\uc5b4\uc758 \uacb0\uacfc \uac12\uc5d0\uc11c\ub294 \uc120\ud615 \uad6c\ubd84\uc774 \uac00\ub2a5\ud55c \ud45c\ud604 \ud615\uc73c\ub85c \ubcc0\uacbd\ub428 \uc911\uac04 \ud45c\ud604\ud615\uc5d0 \uc120\ud615\uc2dd\uc744 \ub9cc\ub4e4\uc5b4 \ud074\ub798\uc2a4 \uad6c\ubd84 Point Input space Hidden space class A (1, 1) (1, 0) 0 B (-1, -1) (1, 0) 0 C (-1, 1) (0, 0) 1 D (1, -1) (1, 1) 1 Modern deep net \ud55c\uac1c\uc758 \ud788\ub4e0 \ub808\uc774\uc5b4\ub97c \uc0ac\uc6a9\ud574\uc11c \ud788\ub4e0\uc720\ub2db\uc774 \ub9ce\ub2e4\uba74 \uc6b0\ub9ac\ub294 universal function approximation \uc744 \ud560 \uc218 \uc788\ub2e4. \ub124\ud2b8\uc6cc\ud06c\uac00 \uae4a\uc5b4 \uc9c0\uba74 \ub354 \uac15\ub825\ud574\uc9c0\uace0 \ud6a8\uc728\uc801\uc774 \ub41c\ub2e4. \ubcf5\uc7a1\ud569 \ud568\uc218 \ub9f5\ud551\uc744 \uc5ec\ub7ec\uac1c\uc758 \uc791\uc740 \uc7ac\ud45c\ud604\ub41c \ub2e8\uacc4\ub85c \ubd84\ub9ac \ud560 \uc218 \uc788\ub2e4. edges -> junctions -> parts -> objects -> scences \ub124\ud2b8\uc6cc\ud06c\uc758 \uae4a\uc774\uac00 \ub07c\uce58\ub294 \uc88b\uc740 \uc601\ud5a5 why adding depth helps doc \uc5ec\ub7ec\uac1c\uc758 \uc778\ud48b\uc774 \uac19\uc740 \uc544\uc6c3\ud48b\uc5d0 \ub9f5\ud551\ub41c\ub2e4. \uadf8\ub807\ub2e4\uba74 \ud568\uc218\ub97c \uc7ac\ud65c\uc6a9 \ud560 \uc218 \uc788\uc744\uac83\uc774\ub2e4. \ub113\uc774\uac00 \uc544\ub2c8\ub77c \uae4a\uc774\ub97c \uae4a\uac8c \ud55c\ub2e4\uba74 \uadf8\ub7f0 \ud568\uc218\ub4e4\uc744 \ub9ce\uc774 \uc7ac\ud65c\uc6a9 \ud560 \uc218 \uc788\uc744 \uac83\uc774\ub2e4. Inception-v4 $$ f(|x|) = f(|-x|) \\\\ f(|x|,|y|) = f(|-x|,|y|) = f(|x|,|-y|) = f(|-x|,|-y|) $$ NN\uc744 \ud45c\ud604 \ud558\ub294 \uc5ec\ub7ec\uac00\uc9c0 \ubc29\uc2dd \uc544\ub798\uc758 \uc2dd\uc744 \uc5ec\ub7ec\uac00\uc9c0\ub85c \ud45c\ud604 \ud560 \uc218 \uc788\ub2e4. $$ \\begin{align} h^{(1)} & = \\sigma(W^{(1)}x) \\\\ h^{(2)} & = \\text{relu}(W^{(2)}x) \\\\ h^{(3)} & = \\sigma(W^{(3)}h^{(1)}) \\\\ y & = (W^{(4)}h^{(3)} + W^{(5)}h^{(2)}) \\end{align} $$ \uc704\uc758 \uadf8\ub798\ud504 \ubc29\uc2dd\uc73c\ub85c NN\uc744 \ud45c\ud604 \ud558\uac8c \ub418\uba74 \uac01\uac01\uc744 \ubaa8\ub4c8\ub85c \uc0dd\uac01\ud558\uace0 \ub808\uace0 \ucc98\ub7fc \ud544\uc694\ud55c\uacf3\uc5d0 \ub07c\uc5b4 \ub123\uc73c\uba74 \ub41c\ub2e4. OOP \ub85c \uc811\uadfc\ud574\uc11c \ucd94\uc0c1\ud654 \ud560 \uc218 \uc788\ub2e4. foward_pass() # predict backward_pass() # learning compute_gradients() # update parameter \uc0c8\ub85c\uc6b4 \ubaa8\ub4c8\uc744 \ucd94\uac00 \ud558\uae30 \uc27d\ub2e4. Learning \uc6b0\ub9ac\uc758 \ub370\uc774\ud130\uc640 \ubaa8\ub378 \ud30c\ub77c\ubbf8\ud130\uc5d0 \ub530\ub77c \ub85c\uc2a4 \ud391\uc158\uc744 \uc815\uc758\ud558\uace0 \ud574\ub2f9 \ub85c\uc2a4 \ud568\uc218\ub97c \ucd5c\uc801\ud654 \ubc29\ubc95\ub860\uc744 \uc0ac\uc6a9\ud558\uc5ec loss \ub97c \ucd5c\uc18c\ud654 \ud558\ub294\uac83. Linear algebra recap / notation Gradient vector Entries -> \ud2b9\uc815 scalar function \uc5d0 \ub300\ud55c vector arguments\ub4e4\uc758 \ud3b8\ubbf8\ubd84 \uac12\ub4e4. \ud55c\uac1c\uc758 y \uac12\uc5d0 \ub300\ud55c x \ubc31\ud130\uc758 \ud3b8\ubbf8\ubd84 \uac12\ub4e4 $$ y = f(\\mathbb{x}) \\\\ \\mathit{f} : \\mathbb{R}^{m} \\to \\mathbb{R} \\\\ \\frac{\\partial y}{\\partial \\mathbb{x}} = \\nabla^{(x)}y = \\left[ \\frac{\\partial y}{\\partial x_{1}},...,\\frac{\\partial y}{\\partial x_{m}} \\right] $$ Jacobian matrix Entries -> vector function \uc5d0 \ub300\ud55c vector arguments \uc758 \ud3b8\ubbf8\ubd84 \uac12\ub4e4. y \ubca1\ud130 \uac12\uc5d0 \ub300\ud55c x \ubc31\ud130\uc758 \ud3b8\ubbf8\ubd84 \uac12. Multi classificaion \uc77c \ub54c. $$ \\mathtt{y} = \\mathit{f}(\\mathbb{x}) \\\\ f = \\mathbb{R}^{m} \\to \\mathbb{R}^{n} \\\\ \\frac{\\partial \\mathbb{y}}{\\partial \\mathbb{x}} = \\pmb{J}^{(x)}\\mathbb{(y)} = \\begin{bmatrix} \\frac{\\partial y_{1}}{\\partial x_{1}} & \\cdots & \\frac{\\partial y_{1}}{\\partial x_{m}} \\\\ \\vdots & \\ddots & \\vdots \\\\ \\frac{\\partial y_{n}}{\\partial x_{1}} & \\cdots & \\frac{\\partial y_{n}}{\\partial x_{m}} \\\\ \\end{bmatrix} $$ \uacbd\uc0ac \ud558\uac15\ubc95\uc744 \uc0ac\uc6a9\ud55c \ucd5c\uc801\ud654 \ud55c\uac1c\uc758 \ub370\uc774\ud130 \uacbd\uc0ac \ud558\uac15\ubc95 online gradient descent $$ \\theta \\leftarrow \\theta - \\eta \\nabla^{(\\theta)} \\mathit{L} ( \\theta, \\mathbb{x}, y ) $$ \uc5ec\ub7ec\uac1c\uc758 \ub370\uc774\ud130\ub97c \uc0ac\uc6a9\ud55c \uacbd\uc0ac \ud558\uac15\ubc95 Full/mini batch gradient descent $$ \\theta \\leftarrow \\theta - \\eta \\nabla^{(\\theta)} \\mathit{L} \\left( \\theta, \\left\\{ \\mathbb{x}^{(i)}, y^{(i)} \\right\\}_{i=1}^{m} \\right) $$ Chain rule, backprop and automatic differentiation \uc5f0\uc1c4 \ubc95\uce59\uc744 \uc0ac\uc6a9\ud55c \uac04\ub2e8\ud55c \ubbf8\ubd84 x \uac00 \ubcc0\ud558\uba74 g\uac00 \uc870\uae08 \ubcc0\ud55c\ub2e4. g \uac00 \uc870\uae08 \ubcc0\ud558\uba74 f \uac00 \uc870\uae08 \ubcc0\ud55c\ub2e4. $$ y = f(g(x)); \\\\ \\frac{\\mathbf{d} y}{\\mathbf{d} x} = \\frac{\\mathbf{d} f}{\\mathbf{d} g} \\frac{\\mathbf{d} g}{\\mathbf{d} x} $$ Multivariate: \ud3b8\ubbf8\ubd84 y \uc758 \ubcc0\ud654\ub7c9\uc740 \uac01\uac01\uc758 \ud568\uc218\uc758 \ubcc0\ud654\ub7c9\uc744 \ub354\ud55c \uac83\uacfc \uac19\ub2e4. \uac01\uac01\uc758 \ud568\uc218\ub97c \ubbf8\ubd84 \ud560 \ub54c \ub2e4\ub978 \ud568\uc218\ub4e4\uc740 \uc0c1\uc218 \ucde8\uae09 \ud55c\ub2e4. $$ y = f(g^{(1)}(x),...,g^{(m)}(x)); \\\\ \\frac{\\partial y}{\\partial x} = \\sum_{i=1}^{i=m} \\frac{\\partial f}{\\partial g^{(i)}} \\frac{\\partial g^{(i)}}{\\partial x} $$ Computer graph \uac01\uac01\uc758 path\ub294 \ub530\ub77c\uac00\uba70 \ubbf8\ubd84\ud558\uace0, \uac00\ub2a5\ud55c \ubaa8\ub4e0 path \ub97c \ub354\ud55c\ub2e4. Traverse from Input $\\to$ Output == forward moard AD Traverse from Output $\\to$ Input == reverse mode AD == backprop \ud150\uc11c \ud50c\ub85c\uc6b0\uac00 \uc790\ub3d9\uc73c\ub85c \ubd84\uae30\ubb38, \ubc18\ubcf5\ubb38\ub4e4\uc744 \ub9de\uac8c \ubbf8\ubd84\ud574\uc900\ub2e4. \uc608\uc81c y \uac00 \uc774\ub7f0 \uc218\uc2dd\uc77c\ub54c $$ y = g( e(d(c(b(a(x))))), f(j(i(h(x)))) $$ \uadf8\ub798\ud504 \ud45c\ud604 \uc544\ub798\ub294 y \uc5d0\uc11c \ubd80\ud130 \uadf8\ub798\ud504\ub97c \ub530\ub77c \uc62c\ub77c \uc624\uba74 \uc644\uc131\ub418\ub294 backprop \uc2dd $$ \\frac{\\partial y}{\\partial x} = \\frac{\\partial h}{\\partial x} \\frac{\\partial i}{\\partial h} \\frac{\\partial j}{\\partial i} \\frac{\\partial f}{\\partial j} \\frac{\\partial g}{\\partial f} \\frac{\\partial y}{\\partial g} + \\frac{\\partial a}{\\partial x} \\frac{\\partial b}{\\partial a} \\frac{\\partial c}{\\partial b} \\frac{\\partial d}{\\partial c} \\frac{\\partial e}{\\partial d} \\frac{\\partial f}{\\partial e} \\frac{\\partial g}{\\partial f} \\frac{\\partial y}{\\partial g} $$ Forward mode AD(automatic differentiation) Traverse graph from each input to output. $ \\frac{\\partial a}{\\partial x}, \\frac{\\partial b}{\\partial x}, ..., \\frac{\\partial y}{\\partial x} $ \uac01\uac01\uc758 \ub178\ub4dc\ub4e4\uc744 input \uc73c\ub85c \ubbf8\ubd84\ud55c\uac12 \uac70\uc758 \uc548\uc500, x \uac12\uc774 \uacb0\uacfc\uc5d0 \uc5bc\ub9c8\ub098 \uc601\ud5a5\uc744 \uc8fc\ub294\uc9c0 \uc815\ub3c4. Backword mode AD Traverse graph from ouptut to input ouput \uc744 \uac01\uac01\uc758 \ub178\ub4dc\ub4e4\ub85c \ubbf8\ubd84\ud55c\uac12 $ \\frac{\\partial y}{\\partial g}, \\frac{\\partial y}{\\partial f}, ..., \\frac{\\partial y}{\\partial x} $ \ud559\uc2b5\uc5d0 \uc0ac\uc6a9. Modular backprop with vector input/outputs Forward-pass $ \\mathbb{y} = f (\\mathbb{x}) $ $$ \\text{Input : } \\mathbb{y} \\\\ \\text{Output : } \\mathbb{x} \\\\ \\mathbb{y} = f (\\mathbb{x}) $$ def forward_pass(x): # input \uc744 \uacc4\uc0b0\ud574\uc11c ouptput \ub9ac\ud134 return y Backward-pass $$ \\text{Input : } \\frac{ \\partial L }{ \\partial \\mathbb{y}} \\\\ \\text{Output : } \\frac{ \\partial L }{ \\partial \\mathbb{x} } \\\\ \\frac{ \\partial L }{ \\partial x_{i}} = \\sum_{j=1}^{J} \\frac{ \\partial L }{ \\partial y_{j}} \\frac{ \\partial y_{j} }{ \\partial x_{i}} \\\\ \\frac{ \\partial L }{ \\partial \\mathbb{x}} = \\frac{ \\partial L }{ \\partial \\mathbb{y}} ( J^{\\mathbb{(x)}} \\mathbb{(y)}) $$ def backward_pass(dL_dy): # \ub85c\uc2a4 \ud568\uc218\ub97c \uc544\uc6c3\ud48b \uac12\uc73c\ub85c \ubbf8\ubd84\ud55c \uac12\uc744 \ubc1b\uc544. # \ub85c\uc2a4 \ud568\uc218\ub97c \uc778\ud48b\uac12 \uc73c\ub85c \ubbf8\ubd84\ud55c \uac12\uc744 \ub9ac\ud134. return dL_dx Parameter gradients $$ \\text{Input : } \\frac{ \\partial L }{ \\partial \\mathbb{y}} \\\\ \\text{Output : } \\frac{ \\partial L }{ \\partial \\theta } \\\\ \\frac{ \\partial L }{ \\partial \\theta_{i}} = \\sum_{j=1}^{J} \\frac{ \\partial L }{ \\partial y_{j}} \\frac{ \\partial y_{j} }{ \\partial \\theta_{i}} \\\\ \\frac{ \\partial L }{ \\partial \\theta } = \\frac{ \\partial L }{ \\partial \\mathbb{y}} ( J^{(\\theta)} \\mathbb{(y)}) $$ def parameter_gradients(dL_dy): # \ub85c\uc2a4 \ud568\uc218\ub97c \uc544\uc6c3\ud48b \uac12\uc73c\ub85c \ubbf8\ubd84\ud55c \uac12\uc744 \ubc1b\uc544. # \ub85c\uc2a4 \ud568\uc218\ub97c \uc138\ud0c0\uac12 \uc73c\ub85c \ubbf8\ubd84\ud55c \uac12\uc744 \ub9ac\ud134. return dl_dtheta \ubaa8\ub4c8\ud654 \uac01\uac01\uc758 \ubaa8\ub4c8\ub4e4\uc774 \uc544\ub798\uc758 3\uac1c \uc778\ud130\ud398\uc774\uc2a4\ub97c \uad6c\ud604\ud558\uba74 \uc5f0\uacb0(chaining) \ud558\uc5ec \uacc4\uc0b0 \ud560 \uc218 \uc788\ub2e4. class module: interface forward_pass(x) interface backward_pass(dL_dy) interface parameter_gradients(dL_dy) x-ent: cross-entorpy \ud559\uc2b5\uc774\ub780 \uc544\ub798 3\uac1c\uc758 API\ub97c \ubc18\ubcf5 \ud638\ucd9c \ud558\uba74\ub41c\ub2e4. \uac01 \ubaa8\ub4c8\ub4e4\uc758 forward_pass \ub97c \uc5f0\uacb0\ud574\uc11c \uc791\ub3d9\uc2dc\ud0a4\uace0 \uac01 \ubaa8\ub4c8\ub4e4\uc758 backward_pass \ub97c \uc791\ub3d9 \uc2dc\ud0a4\uace0. \uac01 \ubaa8\ub4c8\ub4e4\uc758parameter_gradients \ub97c \uc791\ub3d9\uc2dc\ud0a4\uba74 \ud559\uc2b5\uc774 \ub41c\ub2e4. Linear module forward_pass $$ y = Wx + b \\\\ y_{n} = \\sum_{m} W_{nm} x_{m} + b_{n} $$ jacobian elements x \ubbf8\ubd84 b \ubbf8\ubd84 $\\theta$ \ubbf8\ubd84 $$ \\frac{ \\partial y_{i} }{ \\partial x_{j}} = W_{ij} \\\\ \\frac{ \\partial y_{i} }{ \\partial b_{j}} = \\delta_{ij} \\\\ \\frac{ \\partial y_{i} }{ \\partial W_{jk}} = x_{k} \\delta_{ij} \\\\ $$ backward_pass $$ \\frac{ \\partial L }{ \\partial \\mathbb{x}} = \\frac{ \\partial L }{ \\partial \\mathbb{y}} W \\\\ \\frac{ \\partial L }{ \\partial x_{j}} = \\sum_{i} \\frac{ \\partial L }{ \\partial y_{i}} \\frac{ \\partial y_{i} }{ \\partial x_{j}} = \\sum_{i} \\frac{ \\partial L }{ \\partial y_{i}} W_{ij} $$ param_gradients - $W$ $$ \\frac{ \\partial L }{ \\partial W} = \\left( \\frac{ \\partial L }{ \\partial \\mathbb{y}} \\right)^{T} \\mathbb{x}^{T} \\\\ \\frac{ \\partial L }{ \\partial W_{jk}} = \\sum_{i} \\frac{ \\partial L }{ \\partial y_{i}} \\frac{ \\partial y_{i} }{ \\partial W_{jk}} = \\sum_{i} \\frac{ \\partial L }{ \\partial y_{i}} x_{k} \\delta_{ij} = \\frac{ \\partial L }{ \\partial y_{j}} x_{k} $$ param_gradients - $\\mathbb{b}$ $$ \\frac{ \\partial L }{ \\partial \\mathbb{b}} = \\frac{ \\partial L }{ \\partial \\mathbb{y}} $$ Relu module forward_pass $$ y_{i} = \\text{max}(0, x_{i}) $$ backward_pass 0 \ubcf4\ub2e4 \ud06c\uba74 \uadf8\ub0e5 $y_{i}$ 0 \ubcf4\ub2e4 \uc791\uc73c\uba74 0 $$ \\frac{ \\partial L }{ \\partial x_{i}} = (y_{i} > 0) $$ Softmax module forward_pass $$ y_{n} = \\frac{e^{x_{n}}}{\\sum_{m}e^{x_{m}}} $$ jacobian elements $$ \\frac{ \\partial y_{i} }{ \\partial x_{j}} = \\frac{ \\partial }{ \\partial x_{j}} \\left( \\frac{e^{x_{i}}}{\\sum_{m}e^{x_{m}}} \\right) = \\frac{ \\delta_{ij} e^{x_{i}} }{ \\sum_{m}e^{x_{m}} } - \\frac{ e^{x_{i}} e^{x_{j}} }{ (\\sum_{m} e^{x_{m}})^{2} } = y_{i} (\\delta_{ij} - y_{j}) $$ backward_pass $$ \\frac{ \\partial L }{ \\partial \\mathbb{x}} = s - \\sum_{i} s_{i} \\text{; where} s_{i} = \\frac{ \\partial L }{ \\partial y_{i}} y_{i} $$ Cross-entropy loss module forward_pass y = L = Xent(p, x) $$ y = - \\sum_{i}^{\\text{classes:C}} p_{i}\\text{log }x_{i} $$ backward_pass \uc544\ub798\uc758 \uc2dd\uc5d0\uc11c $x_{i}$\uac00 \ub108\ubb34 \uc791\uc73c\uba74 \uc18c\uc218\uc810 \uad00\ub828 \uc774\uc288\uac00 \ubc1c\uc0dd \ub420 \uc218 \uc788\ub2e4. $$ \\frac{ \\partial L }{ \\partial x_{i}} = - \\frac{ p_{i}}{ x_{i}} $$ Cross-entropy + softmax loss module \uc704\uc758 \uc18c\uc218\uc810 \uc774\uc288 \ub54c\ubb38\uc5d0 \ubcf5\ud569 \ub85c\uc2a4 \ud568\uc218\ub97c \uc0ac\uc6a9\ud55c\ub2e4. forward_pass y = L = XentLogits(p, x) $$ y = - \\sum_{i}^{\\text{classes:C}} p_{i}\\text{log } \\left( \\frac{e^{x_{i}}}{\\sum_{m}e^{x_{m}}} \\right) $$ backward_pass $$ \\frac{ \\partial L }{ \\partial \\mathbb{x}} = \\mathbb{y} - \\mathbb{p} $$ Module Zoo Elementwise ops Add forward_pass: $ y = a + b $ backward_pass: $ \\frac{ \\partial L }{ \\partial a} = \\frac{ \\partial L }{ \\partial y} $ Multiply forward_pass: $ y = a \\odot b $ backward_pass: $ \\frac{ \\partial L }{ \\partial a} = b \\odot \\frac{ \\partial L }{ \\partial y} $ Groupwise ops Sum: forward_pass: $ y = \\sum x_{i} $ backward_pass: $ \\frac{ \\partial L }{ \\partial x} = \\frac{ \\partial L }{ \\partial y} 1^{T} $ Max: forward_pass: $ y = max_{i} \\{ x_{i} \\} $ backward_pass: $ \\frac{ \\partial L }{ \\partial x} = \\frac{ \\partial L }{ \\partial y} $ if i was maximal, 0 otherwise Switch/Conditional: \ud65c\uc131\ub41c branch \ub97c one-hot vector \uc778\ucf54\ub529 s \ubca1\ud130\ub85c \ud45c\ud604 forward_pass: $ y = \\mathbb{s} \\odot \\mathbb{x} $ backward_pass: $ \\frac{ \\partial L }{ \\partial \\mathbb{x}} = \\frac{ \\partial L }{ \\partial \\mathbb{y}} \\odot \\mathbb{s}^{T} $ Loss ops Squared Error (MSE) forward_pass: $ L = y = ||\\mathbb{t} - \\mathbb{x}||^{2} = \\sum_{j}(t_{j} - x_{j})^{2}$ backward_pass: $ \\frac{ \\partial L }{ \\partial \\mathbb{x}} = -2(\\mathbb{t} - \\mathbb{x})^{T} $ Activation functions tanh sigomoid \ub97c 0.0 \uc73c\ub85c \ub0b4\ub9ac\uace0 \uc870\uae08 y \ucd95\uc5d0 \uac00\uae5d\uac8c \uc138\uc6b4\uc815\ub3c4. Leaky relu input \uc774 \uc74c\uc218\uc77c\ub54c \uacbd\uc0ac\ub3c4\uac00 0 \uc774 \ub418\ub294\uac78 \ucc98\ub9ac \ud558\uae30 \uc704\ud574 Practical tips Overfitting & regularization Weight decay Dropout Data augmentation \uc88b\uc740 \ucd08\uae30\uac12 \uc124\uc815\uc744 \uc704\ud574 Scaling schemas Batch-norm Hyper-parameter optimization & architecture design d > 1 \uc77c \uacbd\uc6b0 \uadf8\ub9ac\ub4dc \ud0d0\uc0c9\ubcf4\ub2e4 \ub79c\ub364 \ud0d0\uc0c9\uc744 \ub354 \ucd94\ucc9c \ud55c\ub2e4. A few tips for diagnosing/debugging Check for dead units Be aware of vanishing/exploding gradients. Try to overfit on a very small subset of data or a very simple version of your task. Overfitting & regularization \ud2b8\ub808\uc778 \ub370\uc774\ud130\uc5d0\ub294 \uc88b\uc740 \uc810\uc218\ub97c \ubc1b\ub294\ub300 \ud14c\uc2a4\ud2b8 \ub370\uc774\ud130 \uc5d0\uc11c\ub294 \ub098\uc05c \uc810\uc218\ub97c \ubc1b\uc744 \uacbd\uc6b0. Early stopping Weight decay weight \uac00 \ub108\ubb34 \ucee4\uc9c0\uc9c0 \uc54a\uac8c \uc870\uc808 \ud558\ub294\uac83 sigmoid/than/softmax \uac19\uc740 \uacbd\uc6b0 linear region \uc5d0 \uac00\uae5d\uac8c \uba38\ubb3c\uac8c \ud558\ub294\uac83. \ubcc0\ud658\uc774 \uc120\ud615\uc5d0 \uac00\uae5d\uac8c \ub418\uac8c \uc720\ub3c4 \ud568\uc73c\ub85c \ud568\uc218\uc758 \ubcf5\uc7a1\ub3c4\uac00 \ub5a8\uc5b4\ud2b8\ub824 regularization \ud55c\ub2e4. relu \uc5d0\ub294 \ubcc4 \ud6a8\uacfc \uc5c6\uc74c Noise addition $\\to$ dropout \ud2b8\ub798\uc778 \ud558\ub294 \ub3c4\uc911\uc5d0 noise \ub97c \ub354\ud574\uc900\ub2e4. \ud53c\uccd0\uc758 \ud2b9\uc815 \uac12 \ub610\ub294 \uacb0\ud569 \uac12\ub4e4\uc5d0 \uc9c0\ub098\uce58\uac8c \uc758\uc874 \ud558\ub294\uac78 \ubc29\uc9c0 \uac04\ub2e8\ud55c \ubc29\uc2dd\uc758 \uc559\uc0c1\ube14 \ubc29\ubc95\uc774\ub77c\uace0 \ubcfc \uc218\ub3c4 \uc788\ub2e4. Dropout Training: \ub79c\ub364\ud558\uac8c \ud2b9\uc815 \ub808\uc774\uc5b4\uc758 \ubd80\ubd84\ub4e4\uc744 0\uc73c\ub85c \uc124\uc815. Testing: \ubaa8\ub4e0 \uc720\ub2db\uc744 \uc0ac\uc6a9\ud558\ub098, \uc77c\uc815 \ubd80\ubd84\uc744 0\uc73c\ub85c \ubcc0\ud558\uac8c \ud558\ub294 \uc815\ub3c4\ub97c \ubcc0\uacbd \ud558\uac70\ub098. \ub79c\ub364\ud558\uac8c 0 \uc73c\ub85c \uc138\ud305\ud560 \ubd80\ubd84\uc758 \uc815\ub3c4\ub97c \ubcc0\ud658 \uc2dc\ucf1c \uc5ec\ub7ec\ubc88 \uc2e4\ud589 \ud55c\ub2e4.(\uc559\uc0c1\ube14) Batch-norm \ub54c\ubb38\uc5d0 \uc694\uc998\uc740 \ub9ce\uc774 \uc0ac\uc6a9\ud558\uc9c0 \uc54a\uc74c. The importance of good initialization \ucd5c\ucd08 \ucd08\uae30\uac12\uc740 \uc791\uc544\uc57c \ud55c\ub2e4. \ud558\uc9c0\ub9cc \ubd84\ud3ec\uc5d0 \ub530\ub77c \uc5bc\ub9c8\ub098 \uc791\uc544\uc57c \ud558\ub294\uc9c0\ub294 \uce21\uc815\ud574\uc57c \ud55c\ub2e4. \uc5bc\ub9c8\ub098 \uc815\ubcf4\ub4e4\uc774 \uc798 \uc804\ub2ec\ub418\ub294\uc9c0 \uac00 \uc911\uc694\ud558\ub2e4. Too big -> exploid, Too small -> vanish \uc5ec\ub7ec \uc885\ub958\uc758 heuristic \uc788\ub2e4. Xavier initialization He initialization LSUV Batch-norm (loffe & Szegedy, 2015) \uc5c4\uccad \uc911\uc694\ud568! Scale and offset \uc774 \uc801\uc808\ud55c\uc9c0 \uc9c0\uc18d\uc801\uc73c\ub85c \ud655\uc778\ud558\uc790. \uac01\uac01\uc758 \ub808\uc774\uc5b4 \ubcc4\ub85c input \uc774 \uc5bc\ub9c8\ub098 \ube44\uc120\ud615 \uc801\uc778\uc9c0 \ud655\uc778\ud558\uace0 scale \uacfc offse \uc744 \ubcc0\uacbd\ud574 \uc801\uc808\ud558\uac8c \ub9cc\ub4e4\uc5b4 \uc8fc\uc790. \uc608\ub97c \ub4e4\uc5b4 \ub370\uc774\ud130\uc758 \ud1b5\uacc4\ub97c \uc0ac\uc6a9\ud574 \uc120\ud615 \ubcc0\ud658 \ub4a4\uc5d0 \ud3c9\uade0\uc744 0 \uc73c\ub85c \ud558\uace0 \ubd84\uc0b0\uc744 1\ub85c \ud558\ub294 \ub808\uc774\uc5b4\ub97c \ub124\ud2b8\uc6cc\ud06c\uc5d0\uc11c \ud544\uc694\ud55c \ubd80\ubd84\uc5d0 \ubaa8\ub450 \ub354\ud574\uc900\ub2e4. \ucd08\uae30\uac12 \uc124\uc815 \ubfd0\ub9cc \uc544\ub2c8\ub77c \ud2b8\ub798\uc774\ub2dd \uc911 \uc5d0\ub3c4 \uc911\uc694\ud558\ub2e4\uace0 \ubc1d\ud600\uc84c\ub2e4. batch-norm \uc791\uc5c5\uc744 \ud558\uba74 \uc790\ub3d9\uc73c\ub85c noise \uac00 \ub354\ud574\uc9c0\ub294 \uc148\uc774 \ub41c\ub2e4. Hyperparameter search \uc5b4\ub5bb\uac8c \uc88b\uc740 hyperparameter (learning rates, dropout-fractions, weight-decay, etc) \uac12\uc744 \ucc3e\uc744 \uac83\uc778\uac00. \ub9ce\uc740 \uc870\ud569\uc744 \ud2b9\uc815 \ub370\uc774\ud130\uc5d0 \uc2e4\ud5d8\ud574\uc11c \uac00\uc7a5 \uc88b\uc740 \uac78 \ubf51\ub294\uac8c \uae30\ubcf8 \uc804\ub7b5\uc774\ub2e4. \ud558\uc774\ud37c \ud30c\ub77c\ubbf8\ud130\uac00 \ub9ce\uc544\uc9c4\ub2e4\uba74 \ub2e4\ucc28\uc6d0\uc758 \uc800\uc8fc\ub85c \uc778\ud574 \ud0d0\uc0c9\ud574\uc57c\ud558\ub294 \uac12\ub4e4\uc758 \uc870\ud569\uc774 \uac70\ub300\ud574\uc9c4\ub2e4. \ub79c\ub364 \uc11c\uce58\uac00 \uadf8\ub9ac\ub4dc \uc11c\uce58\ubcf4\ub2e4 \uc88b\ub2e4. Meta-learning: \uc88b\uc740 \ud558\uc774\ud37c\ud30c\ub77c\ubbf8\ud130\ub97c \ucc3e\ub294 \uc54c\uace0\ub9ac\uc998\ub3c4 \ud55c\ucc3d \uac1c\ubc1c \uc911. Simple debugging and performance diagnostics \uc8fd\uc740 units \ub4e4\uc744 \uccb4\ud06c\ud574\ub77c. histogram/visualize gradient update over large minibatch Vanishing/exploding gradients \ub97c \uc8fc\uc758 \ud574\ub77c. histogram/visualize gradient update over large minibatch $10^{-3} * \\text{paramter scale}$ \uc77c\ub2e8 \uc544\uc8fc \uc791\uc740 \uc77c\ubd80 \ub370\uc774\ud130\uc13c \ub610\ub294 \uc2ec\ud50c\ud55c \ubc84\uc804\uc758 \ud14c\uc2a4\ud06c\uc5d0 overfit \uc2dc\ucf1c\ub77c. \uc791\uc740 \ub370\uc774\ud130\uc14b \ub610\ub294 \uc2ec\ud50c\ud55c \ubc84\uc804\uc5d0\uc11c \uc6b0\ub9ac\uc758 \ubaa8\ub378\uc744 training error \ub97c 0\uc73c\ub85c \ub9de\ucd94\uc5b4\uc57c \ud55c\ub2e4. Reference \ucc38\uc870 Assignment","title":"3. Neural Networks Foundations"},{"location":"dl/3_dl_neural_net/#3-neural-networks-foundations","text":"","title":"3. Neural Networks Foundations"},{"location":"dl/3_dl_neural_net/#overview","text":"NN \uc740 \uc120\ud615 \ubcc0\ud658\ub4e4\uacfc + \ube44 \uc120\ud615 \ud568\uc218\ub4e4\uc758 \uc870\ud569 \uc774\ub2e4. - NN\uc758 \uc7a5\uc810\uacfc \uc720\uc5f0\ud568\uc740 \uc704\uc758 \uac04\ub2e8\ud55c \ubaa8\ub4c8\ub4e4\uc744 \ub300\uaddc\ubaa8\ub85c \uad6c\uc131\ud558\uc5ec \uc0ac\uc6a9 \ud568\uc5d0 \uc788\ub2e4. - \ud559\uc2b5\uc774\ub780? - loss function \uc744 \ub370\uc774\ud130\uc5d0 \ub9de\uac8c \ucd5c\uc801\ud654 \uc2dc\ud0a4\ub294\uac78 \uc758\ubbf8\ud55c\ub2e4. - \ubcf4\ud1b5 \ubbf8\ubd84\uc758 \uc5f0\uc1c4 \ubc95\uce59 \uadf8\ub9ac\uace0 SGD \ub97c \uc0ac\uc6a9\ud574 \ucd5c\uc801\ud654 \ud55c\ub2e4.","title":"Overview."},{"location":"dl/3_dl_neural_net/#_1","text":"\ucef4\ud4e8\ud130 \ube44\uc804 \uc74c\uc131\uc778\uc2dd, \uae30\uacc4\ubc88\uc5ed text to speech RL (DQN/A3C) \uc790\uc728\uc8fc\ud589\ucc28 \ub4f1. \uc6b0\ub9ac\uac00 \ub9cc\ub4e4\ub824\uace0 \ud558\ub294 nn \uc740 \uc704\uc758 \uc2dd\uc73c\ub85c \ud45c\ud604 \ud560 \uc218 \uc788\ub2e4.","title":"\uc0ac\uc6a9\ucc98"},{"location":"dl/3_dl_neural_net/#road-map","text":"Single layer networks Networks with one hidden layer Modern deep nets nn \uc744 \ucef4\ud4e8\ud130 \uadf8\ub798\ud504 \ud45c\ud604\uc73c\ub85c. Learing Chain rule Modualr backprop & automatic differentiation Module zoo: layers and losses \ud604\uc5c5\uc5d0\uc11c \uc0ac\uc6a9\ud558\ub294 \ud301","title":"Road map"},{"location":"dl/3_dl_neural_net/#_2","text":"neuron == unit \ube44\uc120\ud615 == activation function (\uc120\ud615 \ubcc0\ud658 + \ube44 \uc120\ud615) \uc744 \ud569\uccd0\uc11c layer \ub77c\uace0 \ubd80\ub978\ub2e4. \uc18c\ud504\ud2b8\uc6e8\uc5b4\uc5d0\uc11c\ub294 atomic ops \ub97c layer \ub77c\uace0 \ubd80\ub978\ub2e4.","title":"\uba85\uce6d\uad00\ub828 \uc8fc\uc758"},{"location":"dl/3_dl_neural_net/#single-layer-networks","text":"Linear layer Sigmoid activiation function layer Binary classification / logistic regression \ub9ac\ubdf0 Multi-way descisions: softmax layer Rectified(put currect) linear layers (relu)","title":"Single layer networks"},{"location":"dl/3_dl_neural_net/#linear-layer","text":"\ub3d9\uc758\uc5b4\"fully connecnted\" \ub610\ub294 \"dense\" layers \uc778\uac04\uc758 \ub1cc\ub97c \uad6c\uc131\ud558\uace0 \uc788\ub294 \uc2e0\uacbd \uc138\ud3ec\ub97c \ubcf4\uba74 \uc218\uc0c1\ub3cc\uae30\ub97c \ud1b5\ud574 \uc5ec\ub7ec\uac1c\uc758 \uc778\ud48b\uc744 \ubc1b\uc544 \ucd95\uc0ad\ub9d0\ub2e8\uc744 \ud1b5\ud574 \uc5ec\ub7ec\uac1c\uc758 \uc544\uc6c3\ud48b\uc744 \uc0dd\uc131\ud55c\ub2e4. - \uc704\uc758 \ud604\uc0c1\uc744 \ubaa8\ub378\ub9c1 \ud574\ubcf4\uc790.","title":"Linear layer"},{"location":"dl/3_dl_neural_net/#input-ouptput","text":"2\uac1c\uc758 \uc778\ud48b\uc744 \ubc1b\uc544 \ud558\ub098\uc758 \uc544\uc6c3\ud48b\uc744 \uc0dd\uc131\ud55c\ub2e4. \uc6b0\ub9ac\ub294 $x_{1}$\uacfc $x_{2}$ \ub97c \ubc1b\uc544. $y_{1}$ \uc744 \ub9cc\ub4e4\ub824\uace0 \ud55c\ub2e4. \uc6b0\ub9ac\ub294 \uc544\ub798\uc640 \uac19\uc774 \uc815\uc758 \ud560 \uac83 \uc774\ub2e4. \uc544\uc6c3\ud48b \ud558\ub098\uc5d0 \ub300\ud574 \uc544\ub798\uc640 \uac19\uc774 \uc815\uc758 \ud558\uc790. $$ f: R^{n} \\to R \\\\ y = \\sum_{i}^{n}w_{i}x_{i} + b $$ \uadf8\ub807\ub2e4\uba74 \uc2e0\uacbd \uc138\ud3ec\ub294 \uc544\ub798\uc640 \uac19\uc774 \ud589\ub82c\uacfc \ubca1\ud130\uc758 \ub0b4\uc801\uc73c\ub85c \uc815\uc758 \ud560 \uc218 \uc788\ub2e4. $$ f: R^{n} \\to R^{m} \\\\ y = Wx + b $$","title":"input ouptput \uc815\uc758"},{"location":"dl/3_dl_neural_net/#sigmoid-layer","text":"Activation function \uc911 \ud558\ub098. $f: R \\to R$ \ud568\uc218 \uc774\uba70 $-\\infty \\leq x \\leq +\\infty$ \ub97c input \uc73c\ub85c \ubc1b\uc544 $0 \\leq y \\leq 1$ \uc758 \uac12\uc744 \ub9ac\ud134\ud55c\ub2e4. $$\\sigma = \\frac{1}{1 + e^{-x}}$$ \uc120\ud615 \ubcc0\ud658\uc774 \uc544\ub2c8\uae30 \ub54c\ubb38\uc5d0 \ube44\uc120\ud615 \ud568\uc218\ub77c\uace0 \ud55c\ub2e4.","title":"Sigmoid layer"},{"location":"dl/3_dl_neural_net/#_3","text":"\uc774\uc81c \uc704\uc758 linear layer \uc640 activation layer(sigmoid) \ub97c \ud569\uce58\uba74 \uc778\uacf5 \ub274\ub860\uc774 \ub41c\ub2e4. - \uc9c0\uae08\uc740 \ud55c\uac1c\uc758 x vector \uc5d0 \ub300\ud574 feed forwarding \ud558\ub294 \ubd80\ubd84\ub9cc \uace0\ub824\ud558\uae30 \ub54c\ubb38\uc5d0 x, y \ub294 1\ucc28\uc6d0 \ubca1\ud130\uc774\ub2e4. $$ y = \\sigma \\left( \\sum_{i}w_{i}x_{i}+b\\right) \\\\ y = \\sigma (Wx + B) $$ input X \ub97c \ubc1b\uc544 output Y \ub85c \ubcc0\ud615(transformation)\ud558\ub294 \ud568\uc218(\uc778\uacf5 \ub274\ub860) \uc740 \uc544\ub798 \uadf8\ub9bc\uc5d0\uc11c $\\to$ \ub85c \ud45c\ud604\ub418\uc5c8\ub2e4. \uc544\ub798 \uadf8\ub9bc\uc740 1\ub2e8 \ub808\uc774\uc5b4\ub97c \ub3c4\uc2dd\ud654 \ud55c \uac83\uc774\ub2e4. \uc704\uc758 \ub274\ub860\uc744 \uad6c\ud604\ud558\uace0 W \uac12\uc744 \uad6c\ud558\uba74 \uc6b0\ub9ac\ub294 binary classification\uc744 \ud560 \uc218 \uc788\ub2e4. \uc544\ub798\ub294 $x_{1}, x_{2}$ \ub85c \uad6c\uc131\ub41c \uc810\ub4e4\uc744 \uc8fc\uace0 \ud6c8\ub828\uc744 \uc2dc\ud0a8\ub2e4. \uadf8\ub7ec\uba74 \uc774\ud6c4 \uc0c8\ub85c\uc6b4 $x_{1}, x_{2}$ \uc744 \uc8fc\uba74 \ub2f5\uc744 \uc608\uce21 \ud560 \uc218 \uc788\ub2e4. X = [(-1, -4),...,(4, 4)] //training data \uadf8\ub9bc\uc5d0\uc11c\ub294 X[i][0] \uc744 x \ucd95 \uac12, X[i][1] \uc744 y \ucd95 \uac12 \uc73c\ub85c \uc0ac\uc6a9\ud574\uc11c \ud45c\uae30 y = [(yellow),...,(blue)] // X \uc5d0 \ub300\uc751\ud558\ub294 label model = train(X, y) // w\ub97c \uad6c\ud568 \uc544\ub798\uc5d0\uc11c \uc124\uba85\ud568. model.predict((5, 5)) // \uad6c\ud574\uc9c4 w\uc5d0 \uc704\uc5d0 \uc815\uc758\ud55c \uc778\uacf5 \ub274\ub860\uc744 \uc0ac\uc6a9\ud574 \ub2f5\uc744 \uc608\uce21. blue Playground.tensorflow","title":"\uc778\uacf5 \ub274\ub860"},{"location":"dl/3_dl_neural_net/#softmax-layer","text":"Multi-classs classificaion \uc5d0\uc11c \uc720\uc6a9\ud568. $$ y = \\text{softmax}(x), \\text{where: } y_{i} = \\frac{e^{x_{i}}}{\\sum_{j=1}^{K}e^{x_{j}}} \\tag{3.1} $$","title":"Softmax layer"},{"location":"dl/3_dl_neural_net/#argmax","text":"input array \uc744 \uc8fc\uba74 input \uacfc \uac19\uc740 \ud06c\uae30\uc758 array \ub97c \ub9ac\ud134 y \uac12\uc740 x \uac12 \uc911 \uac00\uc7a5 \ud070 \uac12\ub9cc 1, \ub098\uba38\uc9c0\ub294 0 \uc73c\ub85c \ub3cc\ub824\uc90c \ubaa8\ub4e0 y \uac12\uc744 \ud569\ud558\uba74 1 y = argmax([1, 1, 8]) // y = [0, 0, 1] sum(y) // 1","title":"argmax \ud568\uc218"},{"location":"dl/3_dl_neural_net/#softmax","text":"soft argmax \ud568\uc218\ub77c\uace0 \uc0dd\uac01\ud574\ub3c4 \ub428. input array \uc744 \uc8fc\uba74 input \uacfc \uac19\uc740 \ud06c\uae30\uc758 array \ub97c \ub9ac\ud134 y \uac12\uc740 x \uac12 \uc911 \uac00\uc7a5 \ud070 \uac12\uc740 1\uc5d0 \uac00\uae5d\uac8c , \ub098\uba38\uc9c0\ub294 0 \uc5d0 \uac00\uae5d\uac8c \ub3cc\ub824\uc90c \ubaa8\ub4e0 y \uac12\uc744 \ud569\ud558\uba74 1 \ud569\ud558\uba74 1\uc774 \ub418\uae30 \ub54c\ubb38\uc5d0 \ud655\ub960\ub85c \uc0dd\uac01 \ud560 \uc218 \uc788\uc74c y = softmax([1, 1, 8]) // \ub300\ub7b5 y = [0.001, 0.001, 0.998] // \uc2e4\uc81c y = [9.10221936e-04, 9.10221936e-04, 9.98179556e-01] sum(y) // 1","title":"softmax"},{"location":"dl/3_dl_neural_net/#softmax-and-cross-entropy-nll-loss","text":"","title":"Softmax and cross-entropy / NLL loss"},{"location":"dl/3_dl_neural_net/#_4","text":"\uc6b0\ub9ac\ub294 Linear layer + softmax \uc744 \ud569\uce58\uba74multinomial logistic regression \ub610\ub294 multi-class classification \uc774 \uac00\ub2a5\ud574\uc9c4\ub2e4. $$ y_{i} = \\frac{e^{\\sum_{j}w_{ij}x_{j} + b_{i}}}{\\sum_{k=1}^{K}e^{\\sum_{j}w_{kj}x_{j} + b_{k}}} $$ \uc704\uc758 \uc2dd\uc744 \uc0ac\uc6a9\ud574 nn\uc744 \uad6c\uc131 \ud560 \uc218 \uc788\ub2e4. MNIST \ub370\uc774\ud130\uc5d0 \uc801\uc6a9\ud55c\ub2e4\uace0 \uc0dd\uac01\ud574\ubcf4\uc790. input: 0~9 \uae4c\uc9c0\uc758 \uc190\uae00\uc528 \uc0ac\uc9c4. output: 0~9 \uae4c\uc9c0\uc758 \uc190\uae00\uc528 \uc0ac\uc9c4\uc774 \ub098\ud0c0\ub0b4\ub294 \uc22b\uc790. //\uc608\uc81c\ub97c \uac04\ub2e8\ud558\uac8c \ud558\uae30 \uc704\ud574 0~2\ubc88\uae4c\uc9c0\uc758 \uc22b\uc790\ub85c \uad6c\uc131\ub41c \uc0ac\uc9c4\ub9cc \uc788\ub2e4\uace0 \ud574\ubcf4\uc790. X = [(raw values represent 2),...,(raw values represent 1)] //training data y = [(0,0,1),...,(0,1,0)] // X \uc5d0 \ub300\uc751\ud558\ub294 label model = train(X, y) // w\ub97c \uad6c\ud568 \uc544\ub798\uc5d0\uc11c \uc124\uba85\ud568. model.predict((raw values represent 0)) // (1, 0, 0) \uc744 \ud574\uc11d\ud558\uba74 0 \uc784\uc744 \uc54c \uc218 \uc788\uc74c.","title":"\uc608\uce21"},{"location":"dl/3_dl_neural_net/#_5","text":"loss function \uc73c\ub85c negative log likelihood(NLL) / cross-entropy of true labels \uc744 \uc0ac\uc6a9 \ud55c\ub2e4. $$ NLL(t, y) = Xent(t, y) = - \\sum_{t}^{classes:C} t_{i}\\text{log }y_{i} $$","title":"\ud559\uc2b5"},{"location":"dl/3_dl_neural_net/#rectified-linear-layer","text":"\ucd5c\uc18c 0, \uc544\ub2c8\uba74 $x_{i}$ $$ y = relu(x) \\text{, where:} y_{i} = \\text{maximum}(0, x_{i}) $$","title":"Rectified-linear layer"},{"location":"dl/3_dl_neural_net/#networks-with-one-hidden-layer","text":"\uc778\ud48b\uc744 \uc120\ud615\uc73c\ub85c \ubd84\ub9ac \ubd88\uac00\ub2a5 \ud560\ub54c \uc0ac\uc6a9. Hindden layer nets \uc740 \"universal function approximators\" \ub77c\uace0 \ub3c4 \ud568. hidden layer == linear + non-linearity == separte layers == modules","title":"Networks with one hidden layer"},{"location":"dl/3_dl_neural_net/#hidden-layers","text":"Single hidden layer (linear + non-linear) Hidden.h \uccab\ubc88\uc9f8 \uc120\ud615 \ubcc0\ud658 \uc2dd\uc758 \uc544\uc6c3\ud48b\uc774\ub2e4. \uc544\uc6c3\ud48b\uc774 \ub2e4\ub978 \ub808\uc774\uc5b4\uc758 \uc778\ud48b\uc774 \ub41c\ub2e4. \uc704\uc640 \uac19\uc774 \uad6c\uc131\ud558\uba74 \uc778\ud48b\uc744 \ub2e4\ub978 \ubc29\uc2dd\uc73c\ub85c \ud45c\ud604 \ud560 \uc218 \uc788\ub2e4. \uc6b0\ub9ac\uc758 \ubb38\uc81c\uac00 \uc120\ud615 \ubcc0\ud658\uc744 \ud1b5\ud574 \uc0dd\uc131\ub41c \uc911\uac04 \ud45c\ud604\ud615 \uc5d0\uc11c\ub294 \uc2ec\ud50c \ud574\uc9c0\uae38 \uae30\ub300 \ud560 \uc218 \uc788\ub2e4. \ubb38\uc81c\ub97c \uc8fc\uc5b4\uc9c4 \uc778\ud48b\uc5d0\uc11c \ubc14\ub85c \ud478\ub294\uac8c \uc544\ub2c8\ub77c \uc5f0\uc18d\uc801\uc778 \ubcc0\ud615\uc744 \ud1b5\ud574\uc11c \ubb38\uc81c\uac00 \uc26c\uc6cc\uc9c0\uae38 \uae30\ub300 \ud560 \uc218 \uc788\ub2e4. \uc608\ub97c \ub4e4\uc5b4 input \uc5d0\uc11c\ub294 \uc120\ud615 \ubd88\ub9ac\uac00 \ubd88\uac00\ub2a5\ud558\uc9c0\ub9cc \uc911\uac04 \ud45c\ud604\ud615\uc5d0\uc11c\ub294 \uc120\ud615 \ubd84\ub9ac\uac00 \uac00\ub2a5 \ud558\uac8c \ubcc0\ud658","title":"Hidden Layers"},{"location":"dl/3_dl_neural_net/#example","text":"\uc544\ub798\uc640 \uac19\uc740 \uc778\ud48b \ud45c\ud604\uc744 \uc120\ud615 \ubcc0\ud658\uc744 \ud1b5\ud574 \ud788\ub4e0 \ub808\uc774\uc5b4\uc5d0\uc11c \ub2e4\ub978 \ud45c\ud604\uc73c\ub85c \ubc14\uafc0\uc218 \uc788\ub2e4. \uc778\ud48b \ud45c\ud604\ud615 \uc5d0\uc11c\ub294 \uc120\ud615\uc73c\ub85c \uad6c\ubd84\uc774 \ubd88\uac00\ub2a5 \ud55c\ubc88\uc758 \uc120\ud615 \ubcc0\ud658 \ud6c4 \ud788\ub4e0\ub808\uc774\uc5b4\uc758 \uacb0\uacfc \uac12\uc5d0\uc11c\ub294 \uc120\ud615 \uad6c\ubd84\uc774 \uac00\ub2a5\ud55c \ud45c\ud604 \ud615\uc73c\ub85c \ubcc0\uacbd\ub428 \uc911\uac04 \ud45c\ud604\ud615\uc5d0 \uc120\ud615\uc2dd\uc744 \ub9cc\ub4e4\uc5b4 \ud074\ub798\uc2a4 \uad6c\ubd84 Point Input space Hidden space class A (1, 1) (1, 0) 0 B (-1, -1) (1, 0) 0 C (-1, 1) (0, 0) 1 D (1, -1) (1, 1) 1","title":"Example"},{"location":"dl/3_dl_neural_net/#modern-deep-net","text":"\ud55c\uac1c\uc758 \ud788\ub4e0 \ub808\uc774\uc5b4\ub97c \uc0ac\uc6a9\ud574\uc11c \ud788\ub4e0\uc720\ub2db\uc774 \ub9ce\ub2e4\uba74 \uc6b0\ub9ac\ub294 universal function approximation \uc744 \ud560 \uc218 \uc788\ub2e4. \ub124\ud2b8\uc6cc\ud06c\uac00 \uae4a\uc5b4 \uc9c0\uba74 \ub354 \uac15\ub825\ud574\uc9c0\uace0 \ud6a8\uc728\uc801\uc774 \ub41c\ub2e4. \ubcf5\uc7a1\ud569 \ud568\uc218 \ub9f5\ud551\uc744 \uc5ec\ub7ec\uac1c\uc758 \uc791\uc740 \uc7ac\ud45c\ud604\ub41c \ub2e8\uacc4\ub85c \ubd84\ub9ac \ud560 \uc218 \uc788\ub2e4. edges -> junctions -> parts -> objects -> scences","title":"Modern deep net"},{"location":"dl/3_dl_neural_net/#_6","text":"why adding depth helps doc \uc5ec\ub7ec\uac1c\uc758 \uc778\ud48b\uc774 \uac19\uc740 \uc544\uc6c3\ud48b\uc5d0 \ub9f5\ud551\ub41c\ub2e4. \uadf8\ub807\ub2e4\uba74 \ud568\uc218\ub97c \uc7ac\ud65c\uc6a9 \ud560 \uc218 \uc788\uc744\uac83\uc774\ub2e4. \ub113\uc774\uac00 \uc544\ub2c8\ub77c \uae4a\uc774\ub97c \uae4a\uac8c \ud55c\ub2e4\uba74 \uadf8\ub7f0 \ud568\uc218\ub4e4\uc744 \ub9ce\uc774 \uc7ac\ud65c\uc6a9 \ud560 \uc218 \uc788\uc744 \uac83\uc774\ub2e4. Inception-v4 $$ f(|x|) = f(|-x|) \\\\ f(|x|,|y|) = f(|-x|,|y|) = f(|x|,|-y|) = f(|-x|,|-y|) $$","title":"\ub124\ud2b8\uc6cc\ud06c\uc758 \uae4a\uc774\uac00 \ub07c\uce58\ub294 \uc88b\uc740 \uc601\ud5a5"},{"location":"dl/3_dl_neural_net/#nn","text":"\uc544\ub798\uc758 \uc2dd\uc744 \uc5ec\ub7ec\uac00\uc9c0\ub85c \ud45c\ud604 \ud560 \uc218 \uc788\ub2e4. $$ \\begin{align} h^{(1)} & = \\sigma(W^{(1)}x) \\\\ h^{(2)} & = \\text{relu}(W^{(2)}x) \\\\ h^{(3)} & = \\sigma(W^{(3)}h^{(1)}) \\\\ y & = (W^{(4)}h^{(3)} + W^{(5)}h^{(2)}) \\end{align} $$ \uc704\uc758 \uadf8\ub798\ud504 \ubc29\uc2dd\uc73c\ub85c NN\uc744 \ud45c\ud604 \ud558\uac8c \ub418\uba74 \uac01\uac01\uc744 \ubaa8\ub4c8\ub85c \uc0dd\uac01\ud558\uace0 \ub808\uace0 \ucc98\ub7fc \ud544\uc694\ud55c\uacf3\uc5d0 \ub07c\uc5b4 \ub123\uc73c\uba74 \ub41c\ub2e4. OOP \ub85c \uc811\uadfc\ud574\uc11c \ucd94\uc0c1\ud654 \ud560 \uc218 \uc788\ub2e4. foward_pass() # predict backward_pass() # learning compute_gradients() # update parameter \uc0c8\ub85c\uc6b4 \ubaa8\ub4c8\uc744 \ucd94\uac00 \ud558\uae30 \uc27d\ub2e4.","title":"NN\uc744 \ud45c\ud604 \ud558\ub294 \uc5ec\ub7ec\uac00\uc9c0 \ubc29\uc2dd"},{"location":"dl/3_dl_neural_net/#learning","text":"\uc6b0\ub9ac\uc758 \ub370\uc774\ud130\uc640 \ubaa8\ub378 \ud30c\ub77c\ubbf8\ud130\uc5d0 \ub530\ub77c \ub85c\uc2a4 \ud391\uc158\uc744 \uc815\uc758\ud558\uace0 \ud574\ub2f9 \ub85c\uc2a4 \ud568\uc218\ub97c \ucd5c\uc801\ud654 \ubc29\ubc95\ub860\uc744 \uc0ac\uc6a9\ud558\uc5ec loss \ub97c \ucd5c\uc18c\ud654 \ud558\ub294\uac83.","title":"Learning"},{"location":"dl/3_dl_neural_net/#linear-algebra-recap-notation","text":"Gradient vector Entries -> \ud2b9\uc815 scalar function \uc5d0 \ub300\ud55c vector arguments\ub4e4\uc758 \ud3b8\ubbf8\ubd84 \uac12\ub4e4. \ud55c\uac1c\uc758 y \uac12\uc5d0 \ub300\ud55c x \ubc31\ud130\uc758 \ud3b8\ubbf8\ubd84 \uac12\ub4e4 $$ y = f(\\mathbb{x}) \\\\ \\mathit{f} : \\mathbb{R}^{m} \\to \\mathbb{R} \\\\ \\frac{\\partial y}{\\partial \\mathbb{x}} = \\nabla^{(x)}y = \\left[ \\frac{\\partial y}{\\partial x_{1}},...,\\frac{\\partial y}{\\partial x_{m}} \\right] $$ Jacobian matrix Entries -> vector function \uc5d0 \ub300\ud55c vector arguments \uc758 \ud3b8\ubbf8\ubd84 \uac12\ub4e4. y \ubca1\ud130 \uac12\uc5d0 \ub300\ud55c x \ubc31\ud130\uc758 \ud3b8\ubbf8\ubd84 \uac12. Multi classificaion \uc77c \ub54c. $$ \\mathtt{y} = \\mathit{f}(\\mathbb{x}) \\\\ f = \\mathbb{R}^{m} \\to \\mathbb{R}^{n} \\\\ \\frac{\\partial \\mathbb{y}}{\\partial \\mathbb{x}} = \\pmb{J}^{(x)}\\mathbb{(y)} = \\begin{bmatrix} \\frac{\\partial y_{1}}{\\partial x_{1}} & \\cdots & \\frac{\\partial y_{1}}{\\partial x_{m}} \\\\ \\vdots & \\ddots & \\vdots \\\\ \\frac{\\partial y_{n}}{\\partial x_{1}} & \\cdots & \\frac{\\partial y_{n}}{\\partial x_{m}} \\\\ \\end{bmatrix} $$","title":"Linear algebra recap / notation"},{"location":"dl/3_dl_neural_net/#_7","text":"\ud55c\uac1c\uc758 \ub370\uc774\ud130 \uacbd\uc0ac \ud558\uac15\ubc95 online gradient descent $$ \\theta \\leftarrow \\theta - \\eta \\nabla^{(\\theta)} \\mathit{L} ( \\theta, \\mathbb{x}, y ) $$ \uc5ec\ub7ec\uac1c\uc758 \ub370\uc774\ud130\ub97c \uc0ac\uc6a9\ud55c \uacbd\uc0ac \ud558\uac15\ubc95 Full/mini batch gradient descent $$ \\theta \\leftarrow \\theta - \\eta \\nabla^{(\\theta)} \\mathit{L} \\left( \\theta, \\left\\{ \\mathbb{x}^{(i)}, y^{(i)} \\right\\}_{i=1}^{m} \\right) $$","title":"\uacbd\uc0ac \ud558\uac15\ubc95\uc744 \uc0ac\uc6a9\ud55c \ucd5c\uc801\ud654"},{"location":"dl/3_dl_neural_net/#chain-rule-backprop-and-automatic-differentiation","text":"\uc5f0\uc1c4 \ubc95\uce59\uc744 \uc0ac\uc6a9\ud55c \uac04\ub2e8\ud55c \ubbf8\ubd84 x \uac00 \ubcc0\ud558\uba74 g\uac00 \uc870\uae08 \ubcc0\ud55c\ub2e4. g \uac00 \uc870\uae08 \ubcc0\ud558\uba74 f \uac00 \uc870\uae08 \ubcc0\ud55c\ub2e4. $$ y = f(g(x)); \\\\ \\frac{\\mathbf{d} y}{\\mathbf{d} x} = \\frac{\\mathbf{d} f}{\\mathbf{d} g} \\frac{\\mathbf{d} g}{\\mathbf{d} x} $$ Multivariate: \ud3b8\ubbf8\ubd84 y \uc758 \ubcc0\ud654\ub7c9\uc740 \uac01\uac01\uc758 \ud568\uc218\uc758 \ubcc0\ud654\ub7c9\uc744 \ub354\ud55c \uac83\uacfc \uac19\ub2e4. \uac01\uac01\uc758 \ud568\uc218\ub97c \ubbf8\ubd84 \ud560 \ub54c \ub2e4\ub978 \ud568\uc218\ub4e4\uc740 \uc0c1\uc218 \ucde8\uae09 \ud55c\ub2e4. $$ y = f(g^{(1)}(x),...,g^{(m)}(x)); \\\\ \\frac{\\partial y}{\\partial x} = \\sum_{i=1}^{i=m} \\frac{\\partial f}{\\partial g^{(i)}} \\frac{\\partial g^{(i)}}{\\partial x} $$ Computer graph \uac01\uac01\uc758 path\ub294 \ub530\ub77c\uac00\uba70 \ubbf8\ubd84\ud558\uace0, \uac00\ub2a5\ud55c \ubaa8\ub4e0 path \ub97c \ub354\ud55c\ub2e4. Traverse from Input $\\to$ Output == forward moard AD Traverse from Output $\\to$ Input == reverse mode AD == backprop \ud150\uc11c \ud50c\ub85c\uc6b0\uac00 \uc790\ub3d9\uc73c\ub85c \ubd84\uae30\ubb38, \ubc18\ubcf5\ubb38\ub4e4\uc744 \ub9de\uac8c \ubbf8\ubd84\ud574\uc900\ub2e4.","title":"Chain rule, backprop and automatic differentiation"},{"location":"dl/3_dl_neural_net/#_8","text":"y \uac00 \uc774\ub7f0 \uc218\uc2dd\uc77c\ub54c $$ y = g( e(d(c(b(a(x))))), f(j(i(h(x)))) $$ \uadf8\ub798\ud504 \ud45c\ud604 \uc544\ub798\ub294 y \uc5d0\uc11c \ubd80\ud130 \uadf8\ub798\ud504\ub97c \ub530\ub77c \uc62c\ub77c \uc624\uba74 \uc644\uc131\ub418\ub294 backprop \uc2dd $$ \\frac{\\partial y}{\\partial x} = \\frac{\\partial h}{\\partial x} \\frac{\\partial i}{\\partial h} \\frac{\\partial j}{\\partial i} \\frac{\\partial f}{\\partial j} \\frac{\\partial g}{\\partial f} \\frac{\\partial y}{\\partial g} + \\frac{\\partial a}{\\partial x} \\frac{\\partial b}{\\partial a} \\frac{\\partial c}{\\partial b} \\frac{\\partial d}{\\partial c} \\frac{\\partial e}{\\partial d} \\frac{\\partial f}{\\partial e} \\frac{\\partial g}{\\partial f} \\frac{\\partial y}{\\partial g} $$","title":"\uc608\uc81c"},{"location":"dl/3_dl_neural_net/#forward-mode-adautomatic-differentiation","text":"Traverse graph from each input to output. $ \\frac{\\partial a}{\\partial x}, \\frac{\\partial b}{\\partial x}, ..., \\frac{\\partial y}{\\partial x} $ \uac01\uac01\uc758 \ub178\ub4dc\ub4e4\uc744 input \uc73c\ub85c \ubbf8\ubd84\ud55c\uac12 \uac70\uc758 \uc548\uc500, x \uac12\uc774 \uacb0\uacfc\uc5d0 \uc5bc\ub9c8\ub098 \uc601\ud5a5\uc744 \uc8fc\ub294\uc9c0 \uc815\ub3c4.","title":"Forward mode AD(automatic differentiation)"},{"location":"dl/3_dl_neural_net/#backword-mode-ad","text":"Traverse graph from ouptut to input ouput \uc744 \uac01\uac01\uc758 \ub178\ub4dc\ub4e4\ub85c \ubbf8\ubd84\ud55c\uac12 $ \\frac{\\partial y}{\\partial g}, \\frac{\\partial y}{\\partial f}, ..., \\frac{\\partial y}{\\partial x} $ \ud559\uc2b5\uc5d0 \uc0ac\uc6a9.","title":"Backword mode AD"},{"location":"dl/3_dl_neural_net/#modular-backprop-with-vector-inputoutputs","text":"","title":"Modular backprop with vector input/outputs"},{"location":"dl/3_dl_neural_net/#forward-pass","text":"$ \\mathbb{y} = f (\\mathbb{x}) $ $$ \\text{Input : } \\mathbb{y} \\\\ \\text{Output : } \\mathbb{x} \\\\ \\mathbb{y} = f (\\mathbb{x}) $$ def forward_pass(x): # input \uc744 \uacc4\uc0b0\ud574\uc11c ouptput \ub9ac\ud134 return y","title":"Forward-pass"},{"location":"dl/3_dl_neural_net/#backward-pass","text":"$$ \\text{Input : } \\frac{ \\partial L }{ \\partial \\mathbb{y}} \\\\ \\text{Output : } \\frac{ \\partial L }{ \\partial \\mathbb{x} } \\\\ \\frac{ \\partial L }{ \\partial x_{i}} = \\sum_{j=1}^{J} \\frac{ \\partial L }{ \\partial y_{j}} \\frac{ \\partial y_{j} }{ \\partial x_{i}} \\\\ \\frac{ \\partial L }{ \\partial \\mathbb{x}} = \\frac{ \\partial L }{ \\partial \\mathbb{y}} ( J^{\\mathbb{(x)}} \\mathbb{(y)}) $$ def backward_pass(dL_dy): # \ub85c\uc2a4 \ud568\uc218\ub97c \uc544\uc6c3\ud48b \uac12\uc73c\ub85c \ubbf8\ubd84\ud55c \uac12\uc744 \ubc1b\uc544. # \ub85c\uc2a4 \ud568\uc218\ub97c \uc778\ud48b\uac12 \uc73c\ub85c \ubbf8\ubd84\ud55c \uac12\uc744 \ub9ac\ud134. return dL_dx","title":"Backward-pass"},{"location":"dl/3_dl_neural_net/#parameter-gradients","text":"$$ \\text{Input : } \\frac{ \\partial L }{ \\partial \\mathbb{y}} \\\\ \\text{Output : } \\frac{ \\partial L }{ \\partial \\theta } \\\\ \\frac{ \\partial L }{ \\partial \\theta_{i}} = \\sum_{j=1}^{J} \\frac{ \\partial L }{ \\partial y_{j}} \\frac{ \\partial y_{j} }{ \\partial \\theta_{i}} \\\\ \\frac{ \\partial L }{ \\partial \\theta } = \\frac{ \\partial L }{ \\partial \\mathbb{y}} ( J^{(\\theta)} \\mathbb{(y)}) $$ def parameter_gradients(dL_dy): # \ub85c\uc2a4 \ud568\uc218\ub97c \uc544\uc6c3\ud48b \uac12\uc73c\ub85c \ubbf8\ubd84\ud55c \uac12\uc744 \ubc1b\uc544. # \ub85c\uc2a4 \ud568\uc218\ub97c \uc138\ud0c0\uac12 \uc73c\ub85c \ubbf8\ubd84\ud55c \uac12\uc744 \ub9ac\ud134. return dl_dtheta","title":"Parameter gradients"},{"location":"dl/3_dl_neural_net/#_9","text":"\uac01\uac01\uc758 \ubaa8\ub4c8\ub4e4\uc774 \uc544\ub798\uc758 3\uac1c \uc778\ud130\ud398\uc774\uc2a4\ub97c \uad6c\ud604\ud558\uba74 \uc5f0\uacb0(chaining) \ud558\uc5ec \uacc4\uc0b0 \ud560 \uc218 \uc788\ub2e4. class module: interface forward_pass(x) interface backward_pass(dL_dy) interface parameter_gradients(dL_dy) x-ent: cross-entorpy \ud559\uc2b5\uc774\ub780 \uc544\ub798 3\uac1c\uc758 API\ub97c \ubc18\ubcf5 \ud638\ucd9c \ud558\uba74\ub41c\ub2e4. \uac01 \ubaa8\ub4c8\ub4e4\uc758 forward_pass \ub97c \uc5f0\uacb0\ud574\uc11c \uc791\ub3d9\uc2dc\ud0a4\uace0 \uac01 \ubaa8\ub4c8\ub4e4\uc758 backward_pass \ub97c \uc791\ub3d9 \uc2dc\ud0a4\uace0. \uac01 \ubaa8\ub4c8\ub4e4\uc758parameter_gradients \ub97c \uc791\ub3d9\uc2dc\ud0a4\uba74 \ud559\uc2b5\uc774 \ub41c\ub2e4.","title":"\ubaa8\ub4c8\ud654"},{"location":"dl/3_dl_neural_net/#linear-module","text":"forward_pass $$ y = Wx + b \\\\ y_{n} = \\sum_{m} W_{nm} x_{m} + b_{n} $$ jacobian elements x \ubbf8\ubd84 b \ubbf8\ubd84 $\\theta$ \ubbf8\ubd84 $$ \\frac{ \\partial y_{i} }{ \\partial x_{j}} = W_{ij} \\\\ \\frac{ \\partial y_{i} }{ \\partial b_{j}} = \\delta_{ij} \\\\ \\frac{ \\partial y_{i} }{ \\partial W_{jk}} = x_{k} \\delta_{ij} \\\\ $$ backward_pass $$ \\frac{ \\partial L }{ \\partial \\mathbb{x}} = \\frac{ \\partial L }{ \\partial \\mathbb{y}} W \\\\ \\frac{ \\partial L }{ \\partial x_{j}} = \\sum_{i} \\frac{ \\partial L }{ \\partial y_{i}} \\frac{ \\partial y_{i} }{ \\partial x_{j}} = \\sum_{i} \\frac{ \\partial L }{ \\partial y_{i}} W_{ij} $$ param_gradients - $W$ $$ \\frac{ \\partial L }{ \\partial W} = \\left( \\frac{ \\partial L }{ \\partial \\mathbb{y}} \\right)^{T} \\mathbb{x}^{T} \\\\ \\frac{ \\partial L }{ \\partial W_{jk}} = \\sum_{i} \\frac{ \\partial L }{ \\partial y_{i}} \\frac{ \\partial y_{i} }{ \\partial W_{jk}} = \\sum_{i} \\frac{ \\partial L }{ \\partial y_{i}} x_{k} \\delta_{ij} = \\frac{ \\partial L }{ \\partial y_{j}} x_{k} $$ param_gradients - $\\mathbb{b}$ $$ \\frac{ \\partial L }{ \\partial \\mathbb{b}} = \\frac{ \\partial L }{ \\partial \\mathbb{y}} $$","title":"Linear module"},{"location":"dl/3_dl_neural_net/#relu-module","text":"forward_pass $$ y_{i} = \\text{max}(0, x_{i}) $$ backward_pass 0 \ubcf4\ub2e4 \ud06c\uba74 \uadf8\ub0e5 $y_{i}$ 0 \ubcf4\ub2e4 \uc791\uc73c\uba74 0 $$ \\frac{ \\partial L }{ \\partial x_{i}} = (y_{i} > 0) $$","title":"Relu module"},{"location":"dl/3_dl_neural_net/#softmax-module","text":"forward_pass $$ y_{n} = \\frac{e^{x_{n}}}{\\sum_{m}e^{x_{m}}} $$ jacobian elements $$ \\frac{ \\partial y_{i} }{ \\partial x_{j}} = \\frac{ \\partial }{ \\partial x_{j}} \\left( \\frac{e^{x_{i}}}{\\sum_{m}e^{x_{m}}} \\right) = \\frac{ \\delta_{ij} e^{x_{i}} }{ \\sum_{m}e^{x_{m}} } - \\frac{ e^{x_{i}} e^{x_{j}} }{ (\\sum_{m} e^{x_{m}})^{2} } = y_{i} (\\delta_{ij} - y_{j}) $$ backward_pass $$ \\frac{ \\partial L }{ \\partial \\mathbb{x}} = s - \\sum_{i} s_{i} \\text{; where} s_{i} = \\frac{ \\partial L }{ \\partial y_{i}} y_{i} $$","title":"Softmax module"},{"location":"dl/3_dl_neural_net/#cross-entropy-loss-module","text":"forward_pass y = L = Xent(p, x) $$ y = - \\sum_{i}^{\\text{classes:C}} p_{i}\\text{log }x_{i} $$ backward_pass \uc544\ub798\uc758 \uc2dd\uc5d0\uc11c $x_{i}$\uac00 \ub108\ubb34 \uc791\uc73c\uba74 \uc18c\uc218\uc810 \uad00\ub828 \uc774\uc288\uac00 \ubc1c\uc0dd \ub420 \uc218 \uc788\ub2e4. $$ \\frac{ \\partial L }{ \\partial x_{i}} = - \\frac{ p_{i}}{ x_{i}} $$","title":"Cross-entropy loss module"},{"location":"dl/3_dl_neural_net/#cross-entropy-softmax-loss-module","text":"\uc704\uc758 \uc18c\uc218\uc810 \uc774\uc288 \ub54c\ubb38\uc5d0 \ubcf5\ud569 \ub85c\uc2a4 \ud568\uc218\ub97c \uc0ac\uc6a9\ud55c\ub2e4. forward_pass y = L = XentLogits(p, x) $$ y = - \\sum_{i}^{\\text{classes:C}} p_{i}\\text{log } \\left( \\frac{e^{x_{i}}}{\\sum_{m}e^{x_{m}}} \\right) $$ backward_pass $$ \\frac{ \\partial L }{ \\partial \\mathbb{x}} = \\mathbb{y} - \\mathbb{p} $$","title":"Cross-entropy + softmax loss module"},{"location":"dl/3_dl_neural_net/#module-zoo","text":"","title":"Module Zoo"},{"location":"dl/3_dl_neural_net/#elementwise-ops","text":"","title":"Elementwise ops"},{"location":"dl/3_dl_neural_net/#add","text":"forward_pass: $ y = a + b $ backward_pass: $ \\frac{ \\partial L }{ \\partial a} = \\frac{ \\partial L }{ \\partial y} $","title":"Add"},{"location":"dl/3_dl_neural_net/#multiply","text":"forward_pass: $ y = a \\odot b $ backward_pass: $ \\frac{ \\partial L }{ \\partial a} = b \\odot \\frac{ \\partial L }{ \\partial y} $","title":"Multiply"},{"location":"dl/3_dl_neural_net/#groupwise-ops","text":"","title":"Groupwise ops"},{"location":"dl/3_dl_neural_net/#sum","text":"forward_pass: $ y = \\sum x_{i} $ backward_pass: $ \\frac{ \\partial L }{ \\partial x} = \\frac{ \\partial L }{ \\partial y} 1^{T} $","title":"Sum:"},{"location":"dl/3_dl_neural_net/#max","text":"forward_pass: $ y = max_{i} \\{ x_{i} \\} $ backward_pass: $ \\frac{ \\partial L }{ \\partial x} = \\frac{ \\partial L }{ \\partial y} $ if i was maximal, 0 otherwise","title":"Max:"},{"location":"dl/3_dl_neural_net/#switchconditional","text":"\ud65c\uc131\ub41c branch \ub97c one-hot vector \uc778\ucf54\ub529 s \ubca1\ud130\ub85c \ud45c\ud604 forward_pass: $ y = \\mathbb{s} \\odot \\mathbb{x} $ backward_pass: $ \\frac{ \\partial L }{ \\partial \\mathbb{x}} = \\frac{ \\partial L }{ \\partial \\mathbb{y}} \\odot \\mathbb{s}^{T} $","title":"Switch/Conditional:"},{"location":"dl/3_dl_neural_net/#loss-ops","text":"","title":"Loss ops"},{"location":"dl/3_dl_neural_net/#squared-error-mse","text":"forward_pass: $ L = y = ||\\mathbb{t} - \\mathbb{x}||^{2} = \\sum_{j}(t_{j} - x_{j})^{2}$ backward_pass: $ \\frac{ \\partial L }{ \\partial \\mathbb{x}} = -2(\\mathbb{t} - \\mathbb{x})^{T} $","title":"Squared Error (MSE)"},{"location":"dl/3_dl_neural_net/#activation-functions","text":"","title":"Activation functions"},{"location":"dl/3_dl_neural_net/#tanh","text":"sigomoid \ub97c 0.0 \uc73c\ub85c \ub0b4\ub9ac\uace0 \uc870\uae08 y \ucd95\uc5d0 \uac00\uae5d\uac8c \uc138\uc6b4\uc815\ub3c4.","title":"tanh"},{"location":"dl/3_dl_neural_net/#leaky-relu","text":"input \uc774 \uc74c\uc218\uc77c\ub54c \uacbd\uc0ac\ub3c4\uac00 0 \uc774 \ub418\ub294\uac78 \ucc98\ub9ac \ud558\uae30 \uc704\ud574","title":"Leaky relu"},{"location":"dl/3_dl_neural_net/#practical-tips","text":"","title":"Practical tips"},{"location":"dl/3_dl_neural_net/#overfitting-regularization","text":"Weight decay Dropout Data augmentation","title":"Overfitting &amp; regularization"},{"location":"dl/3_dl_neural_net/#_10","text":"Scaling schemas Batch-norm","title":"\uc88b\uc740 \ucd08\uae30\uac12 \uc124\uc815\uc744 \uc704\ud574"},{"location":"dl/3_dl_neural_net/#hyper-parameter-optimization-architecture-design","text":"d > 1 \uc77c \uacbd\uc6b0 \uadf8\ub9ac\ub4dc \ud0d0\uc0c9\ubcf4\ub2e4 \ub79c\ub364 \ud0d0\uc0c9\uc744 \ub354 \ucd94\ucc9c \ud55c\ub2e4.","title":"Hyper-parameter optimization &amp; architecture design"},{"location":"dl/3_dl_neural_net/#a-few-tips-for-diagnosingdebugging","text":"Check for dead units Be aware of vanishing/exploding gradients. Try to overfit on a very small subset of data or a very simple version of your task.","title":"A few tips for diagnosing/debugging"},{"location":"dl/3_dl_neural_net/#overfitting-regularization_1","text":"\ud2b8\ub808\uc778 \ub370\uc774\ud130\uc5d0\ub294 \uc88b\uc740 \uc810\uc218\ub97c \ubc1b\ub294\ub300 \ud14c\uc2a4\ud2b8 \ub370\uc774\ud130 \uc5d0\uc11c\ub294 \ub098\uc05c \uc810\uc218\ub97c \ubc1b\uc744 \uacbd\uc6b0. Early stopping Weight decay weight \uac00 \ub108\ubb34 \ucee4\uc9c0\uc9c0 \uc54a\uac8c \uc870\uc808 \ud558\ub294\uac83 sigmoid/than/softmax \uac19\uc740 \uacbd\uc6b0 linear region \uc5d0 \uac00\uae5d\uac8c \uba38\ubb3c\uac8c \ud558\ub294\uac83. \ubcc0\ud658\uc774 \uc120\ud615\uc5d0 \uac00\uae5d\uac8c \ub418\uac8c \uc720\ub3c4 \ud568\uc73c\ub85c \ud568\uc218\uc758 \ubcf5\uc7a1\ub3c4\uac00 \ub5a8\uc5b4\ud2b8\ub824 regularization \ud55c\ub2e4. relu \uc5d0\ub294 \ubcc4 \ud6a8\uacfc \uc5c6\uc74c Noise addition $\\to$ dropout \ud2b8\ub798\uc778 \ud558\ub294 \ub3c4\uc911\uc5d0 noise \ub97c \ub354\ud574\uc900\ub2e4. \ud53c\uccd0\uc758 \ud2b9\uc815 \uac12 \ub610\ub294 \uacb0\ud569 \uac12\ub4e4\uc5d0 \uc9c0\ub098\uce58\uac8c \uc758\uc874 \ud558\ub294\uac78 \ubc29\uc9c0 \uac04\ub2e8\ud55c \ubc29\uc2dd\uc758 \uc559\uc0c1\ube14 \ubc29\ubc95\uc774\ub77c\uace0 \ubcfc \uc218\ub3c4 \uc788\ub2e4. Dropout Training: \ub79c\ub364\ud558\uac8c \ud2b9\uc815 \ub808\uc774\uc5b4\uc758 \ubd80\ubd84\ub4e4\uc744 0\uc73c\ub85c \uc124\uc815. Testing: \ubaa8\ub4e0 \uc720\ub2db\uc744 \uc0ac\uc6a9\ud558\ub098, \uc77c\uc815 \ubd80\ubd84\uc744 0\uc73c\ub85c \ubcc0\ud558\uac8c \ud558\ub294 \uc815\ub3c4\ub97c \ubcc0\uacbd \ud558\uac70\ub098. \ub79c\ub364\ud558\uac8c 0 \uc73c\ub85c \uc138\ud305\ud560 \ubd80\ubd84\uc758 \uc815\ub3c4\ub97c \ubcc0\ud658 \uc2dc\ucf1c \uc5ec\ub7ec\ubc88 \uc2e4\ud589 \ud55c\ub2e4.(\uc559\uc0c1\ube14) Batch-norm \ub54c\ubb38\uc5d0 \uc694\uc998\uc740 \ub9ce\uc774 \uc0ac\uc6a9\ud558\uc9c0 \uc54a\uc74c.","title":"Overfitting &amp; regularization"},{"location":"dl/3_dl_neural_net/#the-importance-of-good-initialization","text":"\ucd5c\ucd08 \ucd08\uae30\uac12\uc740 \uc791\uc544\uc57c \ud55c\ub2e4. \ud558\uc9c0\ub9cc \ubd84\ud3ec\uc5d0 \ub530\ub77c \uc5bc\ub9c8\ub098 \uc791\uc544\uc57c \ud558\ub294\uc9c0\ub294 \uce21\uc815\ud574\uc57c \ud55c\ub2e4. \uc5bc\ub9c8\ub098 \uc815\ubcf4\ub4e4\uc774 \uc798 \uc804\ub2ec\ub418\ub294\uc9c0 \uac00 \uc911\uc694\ud558\ub2e4. Too big -> exploid, Too small -> vanish \uc5ec\ub7ec \uc885\ub958\uc758 heuristic \uc788\ub2e4. Xavier initialization He initialization LSUV Batch-norm (loffe & Szegedy, 2015) \uc5c4\uccad \uc911\uc694\ud568! Scale and offset \uc774 \uc801\uc808\ud55c\uc9c0 \uc9c0\uc18d\uc801\uc73c\ub85c \ud655\uc778\ud558\uc790. \uac01\uac01\uc758 \ub808\uc774\uc5b4 \ubcc4\ub85c input \uc774 \uc5bc\ub9c8\ub098 \ube44\uc120\ud615 \uc801\uc778\uc9c0 \ud655\uc778\ud558\uace0 scale \uacfc offse \uc744 \ubcc0\uacbd\ud574 \uc801\uc808\ud558\uac8c \ub9cc\ub4e4\uc5b4 \uc8fc\uc790. \uc608\ub97c \ub4e4\uc5b4 \ub370\uc774\ud130\uc758 \ud1b5\uacc4\ub97c \uc0ac\uc6a9\ud574 \uc120\ud615 \ubcc0\ud658 \ub4a4\uc5d0 \ud3c9\uade0\uc744 0 \uc73c\ub85c \ud558\uace0 \ubd84\uc0b0\uc744 1\ub85c \ud558\ub294 \ub808\uc774\uc5b4\ub97c \ub124\ud2b8\uc6cc\ud06c\uc5d0\uc11c \ud544\uc694\ud55c \ubd80\ubd84\uc5d0 \ubaa8\ub450 \ub354\ud574\uc900\ub2e4. \ucd08\uae30\uac12 \uc124\uc815 \ubfd0\ub9cc \uc544\ub2c8\ub77c \ud2b8\ub798\uc774\ub2dd \uc911 \uc5d0\ub3c4 \uc911\uc694\ud558\ub2e4\uace0 \ubc1d\ud600\uc84c\ub2e4. batch-norm \uc791\uc5c5\uc744 \ud558\uba74 \uc790\ub3d9\uc73c\ub85c noise \uac00 \ub354\ud574\uc9c0\ub294 \uc148\uc774 \ub41c\ub2e4.","title":"The importance of good initialization"},{"location":"dl/3_dl_neural_net/#hyperparameter-search","text":"\uc5b4\ub5bb\uac8c \uc88b\uc740 hyperparameter (learning rates, dropout-fractions, weight-decay, etc) \uac12\uc744 \ucc3e\uc744 \uac83\uc778\uac00. \ub9ce\uc740 \uc870\ud569\uc744 \ud2b9\uc815 \ub370\uc774\ud130\uc5d0 \uc2e4\ud5d8\ud574\uc11c \uac00\uc7a5 \uc88b\uc740 \uac78 \ubf51\ub294\uac8c \uae30\ubcf8 \uc804\ub7b5\uc774\ub2e4. \ud558\uc774\ud37c \ud30c\ub77c\ubbf8\ud130\uac00 \ub9ce\uc544\uc9c4\ub2e4\uba74 \ub2e4\ucc28\uc6d0\uc758 \uc800\uc8fc\ub85c \uc778\ud574 \ud0d0\uc0c9\ud574\uc57c\ud558\ub294 \uac12\ub4e4\uc758 \uc870\ud569\uc774 \uac70\ub300\ud574\uc9c4\ub2e4. \ub79c\ub364 \uc11c\uce58\uac00 \uadf8\ub9ac\ub4dc \uc11c\uce58\ubcf4\ub2e4 \uc88b\ub2e4. Meta-learning: \uc88b\uc740 \ud558\uc774\ud37c\ud30c\ub77c\ubbf8\ud130\ub97c \ucc3e\ub294 \uc54c\uace0\ub9ac\uc998\ub3c4 \ud55c\ucc3d \uac1c\ubc1c \uc911.","title":"Hyperparameter search"},{"location":"dl/3_dl_neural_net/#simple-debugging-and-performance-diagnostics","text":"\uc8fd\uc740 units \ub4e4\uc744 \uccb4\ud06c\ud574\ub77c. histogram/visualize gradient update over large minibatch Vanishing/exploding gradients \ub97c \uc8fc\uc758 \ud574\ub77c. histogram/visualize gradient update over large minibatch $10^{-3} * \\text{paramter scale}$ \uc77c\ub2e8 \uc544\uc8fc \uc791\uc740 \uc77c\ubd80 \ub370\uc774\ud130\uc13c \ub610\ub294 \uc2ec\ud50c\ud55c \ubc84\uc804\uc758 \ud14c\uc2a4\ud06c\uc5d0 overfit \uc2dc\ucf1c\ub77c. \uc791\uc740 \ub370\uc774\ud130\uc14b \ub610\ub294 \uc2ec\ud50c\ud55c \ubc84\uc804\uc5d0\uc11c \uc6b0\ub9ac\uc758 \ubaa8\ub378\uc744 training error \ub97c 0\uc73c\ub85c \ub9de\ucd94\uc5b4\uc57c \ud55c\ub2e4.","title":"Simple debugging and performance diagnostics"},{"location":"dl/3_dl_neural_net/#reference","text":"\ucc38\uc870 Assignment","title":"Reference"},{"location":"dl/4_dl_beyond_image/","text":"4. Beyond Image Recognition, End-to-End Learning, Embeddings Overview \ub354\ubcf5\uc7a1\ud55c \ubaa8\ub378\uacfc \uc77c\uc744 \ud558\ub294 End to End \ud559\uc2b5\uc5d0 \ub300\ud55c \uc18c\uac1c \ubd84\ub958\ub97c \ub118\uc5b4\uc11c: \ud0d0\uc9c0, \uc870\uac01\ud654 End to End case study: \uacf5\uac04 \ubcc0\ud654 \ub124\ud2b8\uc6cc\ud06c \ub77c\ubca8 \uc5c6\uc774 \ubc30\uc6b0\uae30 embedding manifolds \uc870\ud569\ud558\uae30 - RL + sequence learing + auxiliary losses \ubbf8\ub85c \ucc3e\uae30\ub97c \ud480\uae30\uc704\ud574 End to End \ud559\uc2b5\uc774\ub780? input \uacfc output \ub9cc\uc744 \uba85\uc2dc\ud558\uace0 input \uc5d0\uc11c output \uc73c\ub85c\uc758 \ub9f5\ud551\uc744 \ucd5c\uc801\ud654 \ubb38\uc81c\ub85c \ubc14\uafb8\uc5b4 \ud559\uc2b5\ud558\ub294\uac83. \uc5ed\uc0ac 2010: \uc18c\ub9ac\ub97c \ubb38\uc790\ub85c: Audio $\\to$ Deep Net $\\to$ Text 2012: \uc0ac\uc9c4\uc744 \ub77c\ubca8\ub85c: Pixels $\\to$ Deep Net $\\to$ Labels 2014: \uae30\uacc4\ubc88\uc5ed: Text $\\to$ Deep Net $\\to$ Text 2018: \ub85c\ubd07: Sensors $\\to$ Deep Net $\\to$ Action Beyond ImageNet Classification Pretraining \ub9ce\uc740 \ub370\uc774\ud130\ub85c \ud070 \ubaa8\ub378\uc744 \ud559\uc2b5 \uc2dc\ud0a4\ub294\ub370\uc5d0\ub294 \ub9ce\uc740 \uc2dc\uac04\uc774 \ud544\uc694\ud558\ub2e4. ImageNet ConvNets \uac19\uc740 \uacbd\uc6b0\ub294 \ub9ce\uc740 GPU \ub85c \uba87\uc8fc\ub97c \ud559\uc2b5 \uc2dc\ucf1c\uc57c \ud55c\ub2e4. \uc774\ubbf8 \ub2e4\uc591\ud55c \ub370\uc774\ud130\ub85c \ubbf8\ub9ac \ud559\uc2b5\ub41c \ub124\ud2b8\uc6cc\ud06c\ub294 \ub2e4\ub978 \uc791\uc5c5\ub4e4\uc5d0\ub3c4 \uc720\uc6a9 \ud560 \uac83\uc774\ub2e4. \ube44\uc2b7\ud55c \ud074\ub798\uc2a4\ub4e4. \ube44\uc2b7\ud55c \ub3c4\uba54\uc778\ub4e4. \uc774\ubbf8 \ud559\uc2b5\ub41c \ubaa8\ub378\uc744 \uc0ac\uc6a9\ud574\ubcf4\uc790. \uc774\ubbf8 \ud559\uc2b5\ub41c \ubaa8\ub378\uc744 \uac00\uc838\uc628\ub2e4. \ub2e4\ub978 \ub124\ud2b8\uc6cc\ud06c\uc5d0 \uc5f0\uacb0\ud55c\ub2e4. \ub2e4\ub978 \ubd80\ubd84\uc744 \ud559\uc2b5 \uc2dc\ud0a8\ub2e4. \uc774\uc2dd\ub41c \ubbf8\ub9ac \ud559\uc2b5\ub41c \ub124\ud2b8\uc6cc\ud06c\uc758 \ud30c\ub77c\ubbf8\ud130\ub4e4\uc740 \uace0\uc815 \ud558\uac70\ub098 \ub290\ub9ac\uac8c \ubcc0\uacbd\ud55c\ub2e4. \uc774\ubbf8\uc9c0\ub137 \uc608\uc81c \ud6c8\ub828\ub41c \uc774\ubbf8\uc9c0\ub137 \ubd84\ub958 \ubaa8\ub378\uc744 \uac00\uc838\uc640\uc11c \ub9c8\uc9c0\ub9c9 \ub808\uc774\uc5b4\ub9cc \ubcc0\uacbd \ud55c\ub2e4. ouputs = \uc0c8\ub85c\uc6b4 \ub370\uc774\ud130\uc758 \ud074\ub798\uc2a4\ub4e4 \ub9c8\uc9c0\ub9c9 \ub808\uc774\uc5b4\ub97c \ud6c8\ub828 \uc2dc\ud0a8\ub2e4. \uc608\uc81c Imagenet \ub370\uc774\ud130 $\\to$ Covnet $\\to$ $\\mathbb{R}^{1000}$ \uc2e0\uaddc \ub370\uc774\ud130\uc14b $\\to$ Covnet(\uc704\uc5d0 \ubaa8\ub378) $\\to$ $\\mathbb{R}^{24}$ \ud074\ub798\uc2a4\uac00 24\uac1c \uc2e0\uaddc\ub370\uc774\ud130\uc758 \uc774\ubbf8\uc9c0\uac00 \uc801\uc744 \uc218\ub85d \uc798 \ub3d9\uc791\ud55c\ub2e4. a) \ud574\ub2f9 \uc774\ubbf8\uc9c0\uc5d0 \uc5b4\ub5a4 \ud074\ub798\uc2a4\ub4e4\uc774 \uc788\ub294\uc9c0 \ubaa8\ub450 \uc801\uc5b4\ub77c. b) \uc5b4\ub514\uc5d0 \uc5b4\ub5a4 \uc624\ube0c\uc81d\ud2b8\uac00 \uc788\uace0 \ud574\ub2f9 \uc624\ube0c\uc81d\ud2b8\uc758 \ubc94\uc704\ub4e4\uc744 \uc0ac\uac01\ud615\uc73c\ub85c \ud45c\uc2dc\ud574\ub77c. c) \uc624\ube0c\uc81d\ud2b8\ub97c \ud53d\uc140 \ub2e8\uc704\ub85c \ubd84\ub958 \ud574\ub77c. \uc591 d) \uc624\ube0c\uc81d\ud2b8\ub97c \uc778\uc2a4\ud134\uc2a4 \ub2e8\uc704\ub85c \ubd84\ub958\ud574\ub77c. \uc5911, \uc5912, ... Object Detection with convNet \uadf8\ub9bc b) \uc5b4\ub514\uc5d0 \uc5b4\ub5a4 \uc624\ube0c\uc81d\ud2b8\uac00 \uc788\uace0 \ud574\ub2f9 \uc624\ube0c\uc81d\ud2b8\uc758 \ubc94\uc704\ub4e4\uc744 \uc0ac\uac01\ud615\uc73c\ub85c \ud45c\uc2dc\ud574\ub77c. \uc2ac\ub77c\uc774\ub529 \uc708\ub3c4\uc6b0\ub97c \uc0ac\uc6a9\ud574 \ubaa8\ub4e0 \uc601\uc5ed\uc5d0 \uac1d\uccb4\uac00 \uc788\ub294\uc9c0 \ud655\uc778 \ud558\ub294\uac83. \ub108\ubb34 \ub290\ub9b4\uc218 \uc788\ub2e4. \ud558\uc9c0\ub9cc \ucd5c\uc801\ud654 \uac00\ub2a5 \uac19\uc740 \uac1d\uccb4\uac00 \uc5ec\ub7ec \ubc88 \ud0d0\uc9c0 \ub420 \uc218 \uc788\ub2e4. \uc0ac\uac01\ud2c0\uc744 \uc608\uce21 \ubc29\ubc95 \uc0ac\uac01\ud2c0\uc758 \uaf2d\uc9c0\uc810\uc744 \ud68c\uadc0 \ubb38\uc81c\ub85c \ud478\ub294\uac83 \uba87\uac1c\uc758 \uac1d\uccb4\uac00 \ud55c \uac1c\uc758 \uc774\ubbf8\uc9c0\uc5d0 \uc874\uc7ac \ud560 \uc9c0 \ubab0\ub77c\uc11c \ubb38\uc81c \uc0ac\uac01\ud2c0 \uc81c\uc548\ubc95 \ubaa8\ub4c8\uc744 \ub450\uac1c\ub85c \ubd84\ub9ac\ud574 \ucc98\ub9ac \uc0ac\uac01\ud2c0\uc758 \uc704\uce58\ub97c \uc81c\uc548\ud558\ub294 \ubaa8\ub4c8 \uc81c\uc548\ub41c \ubaa8\ub4c8\uc548\uc758 \uc774\ubbf8\uc9c0\ub97c \ubd84\ub958\ud558\ub294 \ubaa8\ub4c8 Faster R-CNN(region-CNN): Overview \uc81c\uc548\ub4e4\uc744 \uc0ac\uc6a9\ud574\uc11c \uac1d\uccb4 \ud0d0\uc0c9 \ubbf8\ub9ac \ud6c8\ub828\ub41c \uc774\ubbf8\uc9c0 \ub137\uc744 \uc0ac\uc6a9 \uc81c\uc548 \ub2e8\uacc4 \uc9c0\uc5ed \uc81c\uc548 \ud558\uc704 \ub9dd\ub97c \uc0ac\uc6a9\ud574\uc11c \uac1d\uccb4\uc758 \uc704\uce58\ub97c \uc81c\uc548 \ubc1b\uc74c \ucd5c\uc885 \ub2e8\uacc4 \uc81c\uc548\ub41c \uc0ac\uac01\ud2c0 \uc548\uc5d0 \uc5b4\ub5a4 \uac1d\uccb4\uac00 \uc788\ub294\uc9c0 \ud655\uc778 \uc774\ubbf8\uc9c0 \ud655\uc778 \ud6c4 \uc0ac\uac01\ud2c0 \uc790\uccb4\ub3c4 \uc870\uc815 \uac00\ub2a5 Region proposal network \uae30\ubcf8\uc801\uc73c\ub85c \ud070 \ubc94\uc704\uc758 \uc2ac\ub77c\uc774\ub529 \uc708\ub3c4\uc6b0\ub97c \uc0ac\uc6a9\ud55c\ub2e4. \ud574\ub2f9 \uc708\ub3c4\uc6b0\uc758 \uac00\uc6b4\ub300 \uc810\uc744 anchor \ub77c\uace0 \ud55c\ub2e4. \uc5ec\ub7ec \uac1c\uc758 (k = 9) \ubc15\uc2a4\ubaa8\uc591\uc744 \ud14c\uc2a4\ud2b8\ud55c\ub2e4. \uc774\ubbf8\uc9c0\uc758 \ud2b9\uc815 \uc708\ub3c4\uc6b0\ub97c \uc9d1\uc5b4 \ub123\uc73c\uba74 \ud574\ub2f9 \uc708\ub3c4\uc6b0\uc758 anchor \ub97c \uae30\uc900\uc73c\ub85c \uc5ec\ub7ec \uac1c\uc758 k \ubc15\uc2a4 \ubaa8\uc591\uc744 \ud14c\uc2a4\ud2b8 \ud55c\ud6c4 6*k \uc758 \uacb0\uacfc \ud589\ub82c\uc744 \ub9ac\ud134\ud55c\ub2e4. \uac01 $k_{i}$ \uc575\ucee4 \ubc15\uc2a4\uc5d0 \ub300\ud574\uc11c $2*k_{i}$ \ub294 \uc810\uc218\ub85c \ud574\ub2f9 k \uc575\ucee4 \ubc15\uc2a4\uc5d0 \uc624\ube0c\uc81d\ud2b8\uac00 \uc874\uc7ac\ud558\ub294 \ud655\ub960\ub85c \uc815\uc758\ud55c\ub2e4. $4*k_{i}$ \ub294 \uc575\ucee4\ub97c \uae30\uc900\uc73c\ub85c \ubc15\uc2a4 \uaf2d\uc9c0\uc810\ub4e4\uc758 \uc0c1\ub300 \uc88c\ud45c\ub97c \uc758\ubbf8\ud55c\ub2e4. \uc575\ucee4\ub97c \uae30\uc900\uc73c\ub85c \uc0c1\ub300 \uc88c\ud45c\ub97c \uc0ac\uc6a9\ud558\uae30 \ub54c\ubb38\uc5d0 \uc774\ubbf8\uc9c0 \ud06c\uae30\uc5d0 \uc0c1\uad00\uc5c6\uc774 \uc801\uc6a9 \ub420 \uc218 \uc788\ub2e4. \ud6c8\ub828\uc2dc \ubbf8\ub9ac \ud6c8\ub828\ub41c \uc774\ubbf8\uc9c0 \ub137\uc744 \uc815\ubc00\ud558\uac8c \ucd5c\uc801\ud654 \ud558\uae30 \uc704\ud574 \uc801\uc740 \ud559\uc2b5 \ube44\uc728\uc744 \uc0ac\uc6a9 \ud560 \uc218\ub3c4 \uc788\ub2e4. Semantic segmentation \uc544\ub798\uc758 \uc0c1\ub2e8 \uc774\ubbf8\uc9c0\ub97c \uc8fc\uba74 \ud558\ub2e8\uc758 \uc774\ubbf8\uc9c0\ub97c \ub9cc\ub4dc\ub294 ConvNet \uc744 \ub9cc\ub4e4\uc5b4\ubcf4\uc790. \uac01\uac01\uc758 \ud53d\uc140\uc744 \ud074\ub798\uc2a4\ubcc4\ub85c \ub77c\ubca8\uc744 \ubd99\uc778\ub2e4. \uc790\uc8fc \uc0ac\uc6a9 \ub418\ub294 \ubc29\ubc95 \ud574\ub2f9\ub3c4 S\uc5d0 \ud074\ub798\uc2a4 \ub9cc\ud07c\uc758 \ucc44\ub110\uc744 \ub9cc\ub4e0\ub2e4. $S_{i,j,c}$ - \ud53d\uc140 (i, j) \uc704\uce58\uac00 \ud074\ub798\uc2a4 c \uc77c \ud655\ub960 \uc0ac\uc6a9\ub41c \ube4c\ub529 \ube14\ub7ed\ub4e4\uc744 \ub9c8\uc9c0\ub9c9\uc5d0 \uc7ac\uc5f0\uacb0\ud574\uc11c \uc815\ubcf4\ub97c \uc804\uc774 \uc2dc\ud0a4\ub294 \ubc29\ubc95\ub3c4 \ub9ce\uc774 \uc0ac\uc6a9\ud55c\ub2e4. \uc608\uc81c \uc120\ud615 \ub808\uc774\uc5b4\uac00 \uc5c6\ub294 \uc644\uc804\ud55c ConvNets \ub9c8\uc9c0\ub9c9\uc758 transopose conv \ub808\uc774\uc5b4\uc5d0\uc11c \uc774\uc804\uc758 \ud480\ub9c1 \ub808\uc774\ub7ec\ub97c \uc0ac\uc6a9\ud55c\ub2e4. \ubbf8\ub9ac \ud6c8\ub828\ub41c \uc774\ubbf8\uc9c0\ub137 \ubd84\ub958\uae30\ub97c \uc0ac\uc6a9 \ub9c8\uc9c0\ub9c8 \ubc14\ub85c\uc804 \ub808\uc774\ub108\ub294 21\uac1c\uc758 \ucc44\ub110\uc744 \uac00\uc9c0\uace0 \uc788\ub2e4. 20\uac1c\uc758 \ud074\ub798\uc2a4 \uadf8\ub9ac\uace0 \ubc30\uacbd\ud654\uba74 \ub808\uc774\uc5b4\uac00 \uc911\ucca9 \ub418\uba74\uc11c \uc6b0\ub9ac\ub294 \uc704\uce58 \uad00\ub828\ub41c \uc815\ubcf4\ub97c \uc810\uc810 \uc694\uc57d\ud574\uc11c \ub9c8\uc9c0\ub9c9\uc5d0\ub294 21\uac1c\uc758 \ud074\ub798\uc2a4\uac00 \ud574\ub2f9 \uc774\ubbf8\uc9c0\uc5d0 \uc874\uc7ac \uac00\ub2a5\uc131\uc744 \ud655\ub960 \uc815\ubcf4\ub85c \ub0a8\uae34\ub2e4. 21\uac1c\uc758 \ub808\uc774\uc5b4\ub97c \uc6d0\ub798\uc758 \ud574\uc0c1\ub3c4\ub85c \ubcf5\uad6c \ud558\uae30 \uc704\ud574\uc11c \uc6b0\ub9ac\ub294 \ub9c8\uc9c0\ub9c9\uc5d0 transoposed conv \ub97c \uc0ac\uc6a9\ud574 \uc5ed\uc73c\ub85c \uc815\ubcf4\ub97c \ud0a4\uc6b4\ub2e4. \ud558\uc9c0\ub9cc \uc798 \ub3d9\uc791\ud558\uc9c0 \uc54a\ub294\ub2e4 \uc65c\ub0d0 \ud558\uba74 \uc774\ubbf8 \uacf5\uac04 \uc815\ubcf4\ub97c \uc783\uc5b4\ubc84\ub9b0 \uc0c1\ud0dc\uc774\uae30 \ub54c\ubb38\uc774\ub2e4. Reference \ucc38\uc870 \ucc38\uc870 \uc774\ubbf8\uc9c0","title":"4. Beyond Image Recognition, End-to-End Learning, Embeddings"},{"location":"dl/4_dl_beyond_image/#4-beyond-image-recognition-end-to-end-learning-embeddings","text":"","title":"4. Beyond Image Recognition, End-to-End Learning, Embeddings"},{"location":"dl/4_dl_beyond_image/#overview","text":"\ub354\ubcf5\uc7a1\ud55c \ubaa8\ub378\uacfc \uc77c\uc744 \ud558\ub294 End to End \ud559\uc2b5\uc5d0 \ub300\ud55c \uc18c\uac1c \ubd84\ub958\ub97c \ub118\uc5b4\uc11c: \ud0d0\uc9c0, \uc870\uac01\ud654 End to End case study: \uacf5\uac04 \ubcc0\ud654 \ub124\ud2b8\uc6cc\ud06c \ub77c\ubca8 \uc5c6\uc774 \ubc30\uc6b0\uae30 embedding manifolds \uc870\ud569\ud558\uae30 - RL + sequence learing + auxiliary losses \ubbf8\ub85c \ucc3e\uae30\ub97c \ud480\uae30\uc704\ud574","title":"Overview"},{"location":"dl/4_dl_beyond_image/#end-to-end","text":"input \uacfc output \ub9cc\uc744 \uba85\uc2dc\ud558\uace0 input \uc5d0\uc11c output \uc73c\ub85c\uc758 \ub9f5\ud551\uc744 \ucd5c\uc801\ud654 \ubb38\uc81c\ub85c \ubc14\uafb8\uc5b4 \ud559\uc2b5\ud558\ub294\uac83. \uc5ed\uc0ac 2010: \uc18c\ub9ac\ub97c \ubb38\uc790\ub85c: Audio $\\to$ Deep Net $\\to$ Text 2012: \uc0ac\uc9c4\uc744 \ub77c\ubca8\ub85c: Pixels $\\to$ Deep Net $\\to$ Labels 2014: \uae30\uacc4\ubc88\uc5ed: Text $\\to$ Deep Net $\\to$ Text 2018: \ub85c\ubd07: Sensors $\\to$ Deep Net $\\to$ Action","title":"End to End \ud559\uc2b5\uc774\ub780?"},{"location":"dl/4_dl_beyond_image/#beyond-imagenet-classification","text":"","title":"Beyond ImageNet Classification"},{"location":"dl/4_dl_beyond_image/#pretraining","text":"\ub9ce\uc740 \ub370\uc774\ud130\ub85c \ud070 \ubaa8\ub378\uc744 \ud559\uc2b5 \uc2dc\ud0a4\ub294\ub370\uc5d0\ub294 \ub9ce\uc740 \uc2dc\uac04\uc774 \ud544\uc694\ud558\ub2e4. ImageNet ConvNets \uac19\uc740 \uacbd\uc6b0\ub294 \ub9ce\uc740 GPU \ub85c \uba87\uc8fc\ub97c \ud559\uc2b5 \uc2dc\ucf1c\uc57c \ud55c\ub2e4. \uc774\ubbf8 \ub2e4\uc591\ud55c \ub370\uc774\ud130\ub85c \ubbf8\ub9ac \ud559\uc2b5\ub41c \ub124\ud2b8\uc6cc\ud06c\ub294 \ub2e4\ub978 \uc791\uc5c5\ub4e4\uc5d0\ub3c4 \uc720\uc6a9 \ud560 \uac83\uc774\ub2e4. \ube44\uc2b7\ud55c \ud074\ub798\uc2a4\ub4e4. \ube44\uc2b7\ud55c \ub3c4\uba54\uc778\ub4e4. \uc774\ubbf8 \ud559\uc2b5\ub41c \ubaa8\ub378\uc744 \uc0ac\uc6a9\ud574\ubcf4\uc790. \uc774\ubbf8 \ud559\uc2b5\ub41c \ubaa8\ub378\uc744 \uac00\uc838\uc628\ub2e4. \ub2e4\ub978 \ub124\ud2b8\uc6cc\ud06c\uc5d0 \uc5f0\uacb0\ud55c\ub2e4. \ub2e4\ub978 \ubd80\ubd84\uc744 \ud559\uc2b5 \uc2dc\ud0a8\ub2e4. \uc774\uc2dd\ub41c \ubbf8\ub9ac \ud559\uc2b5\ub41c \ub124\ud2b8\uc6cc\ud06c\uc758 \ud30c\ub77c\ubbf8\ud130\ub4e4\uc740 \uace0\uc815 \ud558\uac70\ub098 \ub290\ub9ac\uac8c \ubcc0\uacbd\ud55c\ub2e4.","title":"Pretraining"},{"location":"dl/4_dl_beyond_image/#_1","text":"\ud6c8\ub828\ub41c \uc774\ubbf8\uc9c0\ub137 \ubd84\ub958 \ubaa8\ub378\uc744 \uac00\uc838\uc640\uc11c \ub9c8\uc9c0\ub9c9 \ub808\uc774\uc5b4\ub9cc \ubcc0\uacbd \ud55c\ub2e4. ouputs = \uc0c8\ub85c\uc6b4 \ub370\uc774\ud130\uc758 \ud074\ub798\uc2a4\ub4e4 \ub9c8\uc9c0\ub9c9 \ub808\uc774\uc5b4\ub97c \ud6c8\ub828 \uc2dc\ud0a8\ub2e4. \uc608\uc81c Imagenet \ub370\uc774\ud130 $\\to$ Covnet $\\to$ $\\mathbb{R}^{1000}$ \uc2e0\uaddc \ub370\uc774\ud130\uc14b $\\to$ Covnet(\uc704\uc5d0 \ubaa8\ub378) $\\to$ $\\mathbb{R}^{24}$ \ud074\ub798\uc2a4\uac00 24\uac1c \uc2e0\uaddc\ub370\uc774\ud130\uc758 \uc774\ubbf8\uc9c0\uac00 \uc801\uc744 \uc218\ub85d \uc798 \ub3d9\uc791\ud55c\ub2e4. a) \ud574\ub2f9 \uc774\ubbf8\uc9c0\uc5d0 \uc5b4\ub5a4 \ud074\ub798\uc2a4\ub4e4\uc774 \uc788\ub294\uc9c0 \ubaa8\ub450 \uc801\uc5b4\ub77c. b) \uc5b4\ub514\uc5d0 \uc5b4\ub5a4 \uc624\ube0c\uc81d\ud2b8\uac00 \uc788\uace0 \ud574\ub2f9 \uc624\ube0c\uc81d\ud2b8\uc758 \ubc94\uc704\ub4e4\uc744 \uc0ac\uac01\ud615\uc73c\ub85c \ud45c\uc2dc\ud574\ub77c. c) \uc624\ube0c\uc81d\ud2b8\ub97c \ud53d\uc140 \ub2e8\uc704\ub85c \ubd84\ub958 \ud574\ub77c. \uc591 d) \uc624\ube0c\uc81d\ud2b8\ub97c \uc778\uc2a4\ud134\uc2a4 \ub2e8\uc704\ub85c \ubd84\ub958\ud574\ub77c. \uc5911, \uc5912, ...","title":"\uc774\ubbf8\uc9c0\ub137 \uc608\uc81c"},{"location":"dl/4_dl_beyond_image/#object-detection-with-convnet","text":"\uadf8\ub9bc b) \uc5b4\ub514\uc5d0 \uc5b4\ub5a4 \uc624\ube0c\uc81d\ud2b8\uac00 \uc788\uace0 \ud574\ub2f9 \uc624\ube0c\uc81d\ud2b8\uc758 \ubc94\uc704\ub4e4\uc744 \uc0ac\uac01\ud615\uc73c\ub85c \ud45c\uc2dc\ud574\ub77c. \uc2ac\ub77c\uc774\ub529 \uc708\ub3c4\uc6b0\ub97c \uc0ac\uc6a9\ud574 \ubaa8\ub4e0 \uc601\uc5ed\uc5d0 \uac1d\uccb4\uac00 \uc788\ub294\uc9c0 \ud655\uc778 \ud558\ub294\uac83. \ub108\ubb34 \ub290\ub9b4\uc218 \uc788\ub2e4. \ud558\uc9c0\ub9cc \ucd5c\uc801\ud654 \uac00\ub2a5 \uac19\uc740 \uac1d\uccb4\uac00 \uc5ec\ub7ec \ubc88 \ud0d0\uc9c0 \ub420 \uc218 \uc788\ub2e4. \uc0ac\uac01\ud2c0\uc744 \uc608\uce21 \ubc29\ubc95 \uc0ac\uac01\ud2c0\uc758 \uaf2d\uc9c0\uc810\uc744 \ud68c\uadc0 \ubb38\uc81c\ub85c \ud478\ub294\uac83 \uba87\uac1c\uc758 \uac1d\uccb4\uac00 \ud55c \uac1c\uc758 \uc774\ubbf8\uc9c0\uc5d0 \uc874\uc7ac \ud560 \uc9c0 \ubab0\ub77c\uc11c \ubb38\uc81c \uc0ac\uac01\ud2c0 \uc81c\uc548\ubc95 \ubaa8\ub4c8\uc744 \ub450\uac1c\ub85c \ubd84\ub9ac\ud574 \ucc98\ub9ac \uc0ac\uac01\ud2c0\uc758 \uc704\uce58\ub97c \uc81c\uc548\ud558\ub294 \ubaa8\ub4c8 \uc81c\uc548\ub41c \ubaa8\ub4c8\uc548\uc758 \uc774\ubbf8\uc9c0\ub97c \ubd84\ub958\ud558\ub294 \ubaa8\ub4c8","title":"Object Detection with convNet"},{"location":"dl/4_dl_beyond_image/#faster-r-cnnregion-cnn-overview","text":"\uc81c\uc548\ub4e4\uc744 \uc0ac\uc6a9\ud574\uc11c \uac1d\uccb4 \ud0d0\uc0c9 \ubbf8\ub9ac \ud6c8\ub828\ub41c \uc774\ubbf8\uc9c0 \ub137\uc744 \uc0ac\uc6a9 \uc81c\uc548 \ub2e8\uacc4 \uc9c0\uc5ed \uc81c\uc548 \ud558\uc704 \ub9dd\ub97c \uc0ac\uc6a9\ud574\uc11c \uac1d\uccb4\uc758 \uc704\uce58\ub97c \uc81c\uc548 \ubc1b\uc74c \ucd5c\uc885 \ub2e8\uacc4 \uc81c\uc548\ub41c \uc0ac\uac01\ud2c0 \uc548\uc5d0 \uc5b4\ub5a4 \uac1d\uccb4\uac00 \uc788\ub294\uc9c0 \ud655\uc778 \uc774\ubbf8\uc9c0 \ud655\uc778 \ud6c4 \uc0ac\uac01\ud2c0 \uc790\uccb4\ub3c4 \uc870\uc815 \uac00\ub2a5","title":"Faster R-CNN(region-CNN): Overview"},{"location":"dl/4_dl_beyond_image/#region-proposal-network","text":"\uae30\ubcf8\uc801\uc73c\ub85c \ud070 \ubc94\uc704\uc758 \uc2ac\ub77c\uc774\ub529 \uc708\ub3c4\uc6b0\ub97c \uc0ac\uc6a9\ud55c\ub2e4. \ud574\ub2f9 \uc708\ub3c4\uc6b0\uc758 \uac00\uc6b4\ub300 \uc810\uc744 anchor \ub77c\uace0 \ud55c\ub2e4. \uc5ec\ub7ec \uac1c\uc758 (k = 9) \ubc15\uc2a4\ubaa8\uc591\uc744 \ud14c\uc2a4\ud2b8\ud55c\ub2e4. \uc774\ubbf8\uc9c0\uc758 \ud2b9\uc815 \uc708\ub3c4\uc6b0\ub97c \uc9d1\uc5b4 \ub123\uc73c\uba74 \ud574\ub2f9 \uc708\ub3c4\uc6b0\uc758 anchor \ub97c \uae30\uc900\uc73c\ub85c \uc5ec\ub7ec \uac1c\uc758 k \ubc15\uc2a4 \ubaa8\uc591\uc744 \ud14c\uc2a4\ud2b8 \ud55c\ud6c4 6*k \uc758 \uacb0\uacfc \ud589\ub82c\uc744 \ub9ac\ud134\ud55c\ub2e4. \uac01 $k_{i}$ \uc575\ucee4 \ubc15\uc2a4\uc5d0 \ub300\ud574\uc11c $2*k_{i}$ \ub294 \uc810\uc218\ub85c \ud574\ub2f9 k \uc575\ucee4 \ubc15\uc2a4\uc5d0 \uc624\ube0c\uc81d\ud2b8\uac00 \uc874\uc7ac\ud558\ub294 \ud655\ub960\ub85c \uc815\uc758\ud55c\ub2e4. $4*k_{i}$ \ub294 \uc575\ucee4\ub97c \uae30\uc900\uc73c\ub85c \ubc15\uc2a4 \uaf2d\uc9c0\uc810\ub4e4\uc758 \uc0c1\ub300 \uc88c\ud45c\ub97c \uc758\ubbf8\ud55c\ub2e4. \uc575\ucee4\ub97c \uae30\uc900\uc73c\ub85c \uc0c1\ub300 \uc88c\ud45c\ub97c \uc0ac\uc6a9\ud558\uae30 \ub54c\ubb38\uc5d0 \uc774\ubbf8\uc9c0 \ud06c\uae30\uc5d0 \uc0c1\uad00\uc5c6\uc774 \uc801\uc6a9 \ub420 \uc218 \uc788\ub2e4.","title":"Region proposal network"},{"location":"dl/4_dl_beyond_image/#_2","text":"\ubbf8\ub9ac \ud6c8\ub828\ub41c \uc774\ubbf8\uc9c0 \ub137\uc744 \uc815\ubc00\ud558\uac8c \ucd5c\uc801\ud654 \ud558\uae30 \uc704\ud574 \uc801\uc740 \ud559\uc2b5 \ube44\uc728\uc744 \uc0ac\uc6a9 \ud560 \uc218\ub3c4 \uc788\ub2e4.","title":"\ud6c8\ub828\uc2dc"},{"location":"dl/4_dl_beyond_image/#semantic-segmentation","text":"\uc544\ub798\uc758 \uc0c1\ub2e8 \uc774\ubbf8\uc9c0\ub97c \uc8fc\uba74 \ud558\ub2e8\uc758 \uc774\ubbf8\uc9c0\ub97c \ub9cc\ub4dc\ub294 ConvNet \uc744 \ub9cc\ub4e4\uc5b4\ubcf4\uc790. \uac01\uac01\uc758 \ud53d\uc140\uc744 \ud074\ub798\uc2a4\ubcc4\ub85c \ub77c\ubca8\uc744 \ubd99\uc778\ub2e4. \uc790\uc8fc \uc0ac\uc6a9 \ub418\ub294 \ubc29\ubc95 \ud574\ub2f9\ub3c4 S\uc5d0 \ud074\ub798\uc2a4 \ub9cc\ud07c\uc758 \ucc44\ub110\uc744 \ub9cc\ub4e0\ub2e4. $S_{i,j,c}$ - \ud53d\uc140 (i, j) \uc704\uce58\uac00 \ud074\ub798\uc2a4 c \uc77c \ud655\ub960 \uc0ac\uc6a9\ub41c \ube4c\ub529 \ube14\ub7ed\ub4e4\uc744 \ub9c8\uc9c0\ub9c9\uc5d0 \uc7ac\uc5f0\uacb0\ud574\uc11c \uc815\ubcf4\ub97c \uc804\uc774 \uc2dc\ud0a4\ub294 \ubc29\ubc95\ub3c4 \ub9ce\uc774 \uc0ac\uc6a9\ud55c\ub2e4.","title":"Semantic segmentation"},{"location":"dl/4_dl_beyond_image/#_3","text":"\uc120\ud615 \ub808\uc774\uc5b4\uac00 \uc5c6\ub294 \uc644\uc804\ud55c ConvNets \ub9c8\uc9c0\ub9c9\uc758 transopose conv \ub808\uc774\uc5b4\uc5d0\uc11c \uc774\uc804\uc758 \ud480\ub9c1 \ub808\uc774\ub7ec\ub97c \uc0ac\uc6a9\ud55c\ub2e4. \ubbf8\ub9ac \ud6c8\ub828\ub41c \uc774\ubbf8\uc9c0\ub137 \ubd84\ub958\uae30\ub97c \uc0ac\uc6a9 \ub9c8\uc9c0\ub9c8 \ubc14\ub85c\uc804 \ub808\uc774\ub108\ub294 21\uac1c\uc758 \ucc44\ub110\uc744 \uac00\uc9c0\uace0 \uc788\ub2e4. 20\uac1c\uc758 \ud074\ub798\uc2a4 \uadf8\ub9ac\uace0 \ubc30\uacbd\ud654\uba74 \ub808\uc774\uc5b4\uac00 \uc911\ucca9 \ub418\uba74\uc11c \uc6b0\ub9ac\ub294 \uc704\uce58 \uad00\ub828\ub41c \uc815\ubcf4\ub97c \uc810\uc810 \uc694\uc57d\ud574\uc11c \ub9c8\uc9c0\ub9c9\uc5d0\ub294 21\uac1c\uc758 \ud074\ub798\uc2a4\uac00 \ud574\ub2f9 \uc774\ubbf8\uc9c0\uc5d0 \uc874\uc7ac \uac00\ub2a5\uc131\uc744 \ud655\ub960 \uc815\ubcf4\ub85c \ub0a8\uae34\ub2e4. 21\uac1c\uc758 \ub808\uc774\uc5b4\ub97c \uc6d0\ub798\uc758 \ud574\uc0c1\ub3c4\ub85c \ubcf5\uad6c \ud558\uae30 \uc704\ud574\uc11c \uc6b0\ub9ac\ub294 \ub9c8\uc9c0\ub9c9\uc5d0 transoposed conv \ub97c \uc0ac\uc6a9\ud574 \uc5ed\uc73c\ub85c \uc815\ubcf4\ub97c \ud0a4\uc6b4\ub2e4. \ud558\uc9c0\ub9cc \uc798 \ub3d9\uc791\ud558\uc9c0 \uc54a\ub294\ub2e4 \uc65c\ub0d0 \ud558\uba74 \uc774\ubbf8 \uacf5\uac04 \uc815\ubcf4\ub97c \uc783\uc5b4\ubc84\ub9b0 \uc0c1\ud0dc\uc774\uae30 \ub54c\ubb38\uc774\ub2e4.","title":"\uc608\uc81c"},{"location":"dl/4_dl_beyond_image/#reference","text":"\ucc38\uc870 \ucc38\uc870 \uc774\ubbf8\uc9c0","title":"Reference"},{"location":"etc/algorithm/en_2_getting_started/","text":"2.Getting Started Check list for learning algorithm Idea. Pseudocode. Argue that it is correctly works. Analyze its running time. Problem Input : A sequence of n elements $ A = < a_{1}, a_{2}, ... ,a_{n} > $. Output : The permutation(reordering) $ A = < a_{1}^{\\prime},a_{2}^{\\prime},...,a_{n}^{\\prime} > $ of the input sequence such that satisfies $ a_{1}^{\\prime} \\le a_{2}^{\\prime} \\le ... \\le a_{n}^{\\prime} $. Insertion sort Idea Idea: incremental approach. increment sorted array. insert current item into the sorted array A[1..j - 1] HowTo: Start from sorted length 1 array. Until conditions meet - i > 0 and A[i] > key Move i to one step back. Decrease i. Insert current item in A[i + 1] Pseudocode Pursue clean and concise INSERATION-SORT(A) 1 for j = 2 to A.length 2 key = A[j] 3 // Insert A[j] into the sorted sequence A[1..j - 1] 4 i = j - 1 5 while i > 0 and A[i] > key 6 A[i + 1] = A[i] 7 i = i - 1 8 A[i + 1] = key Tip Use \"i\" as a important loop variable name. Use simple condition first when there is logical concatenation. Use left as variable and right as almost constant value when compare two numbers. Make it simple as possible Argue that it is correctly works Guess I will use loop invariants. It keeps from start to terminate. I'll claim sub-array is always sorted. loop invariant: The sub-array A[1..j-1] consists of the elements originally in A[1..j-1], but in sorted order. It is similarity to the mathematical induction. We say an algorithm has true loop invariant on some properties. When the three properties hold, the loop invariant is true. Initialization: It is true prior to the first iteration of the loop. Maintenance: If it is true before an iteration of the loop,it remains true before the next iteration. Termination: When the loop terminates, the invariant gives us a useful property that helps show that the algorithm is correct. Initialization When j = 2, The subarray A[1..j-1] consists of just one element A[1], which is in fact the original element in A[1]. Moreover, the subarray is sorted(trivially, of course). Maintenance The body of for loop works by moving A[j-1], A[j-2], A[j-3], and so on by one position to the right until it finds the proper position for A j , at which point it inserts the value of a j . The subarray A[1..j] then consists of the elements originally in A[1..j],but it sorted order. Incrementing j for the next iteration of the for loop then preserve the loop invariant. Termination The condition causing the for loop to terminate is that j > A.length = n. Because each loop iteration increase j by 1, we must have j = n + 1 at that time. Substituting n + 1 for j in the wording of loop invariant, we have that the subarray A[1..n] consists of the element originally in A[1..n], but in sorted order. Pseudocode conventions We use the keyword to when a for loop increments its loop counter. We use the keyword downto when a for loop decrements its loop counter. When the loop counter changes by an amount greater then 1, the amount of change follows the optional keyword by. We shall not use global variables without explicit indication. The notation .. is used to indicate a range of values within an arrary. Thus, A[1..j] indicates the subarray of A consisting of the j elements A[1],A[2],...,A[j]. We organize compound date into objects, which are composed of attributes. We treat a variable represent arrary and object as a point to the date representing the arrary or object. For all attributes f of an object x, setting y = x causes y.f to equal x.f. Moreover, if we now set x.f = 3, then afterward not only dose x.f equal 3, but y.f equals 3 as well. In other words, x and y point to same object after the assignment y = x. We pass parameter to a procedure by value. When object passed, the pointer to the data representing object is copied. We allow multiple values to be returned by a single return statement. The boolean operators \"and\" and \"or\" are short circuiting. Exercise 2.1-1 Using Figure 2.2 as a model, illustrate the operation of INSERTION-SORT on the Arrary A = <31, 41, 59, 26, 41. 58> 2.1-2 Rewrite the Insertion-sort procedure to sort into nonincreasing instead of nondescreasing. INSERATION-SORT(A) For j = 2 to A.length key = A[j] i = j - 1 while i > 0 and A[i] < Key A[i + 1] = A[i] i = i - 1 A[i + 1] = key 2.1-3 Consider the searching problem : - Input : A sequence of n numbers $ A = < a_{1}, a_{2},...,a_{n} > $ and a value v. - Output : An index i such that v = A[i] or the special value NIL if v dose not appear in A. Write pseudocode for linear search, which scan trough the sequence, looking for v. Using a loop invariant, prove that your algorithm is correct. Make sure that your loop invariant fulfills the three necessary properties. pseudocode LINEAR-SEARCH(A, v) i = NIL For j = 1 to A.length if A[j] == v i = j code loop invariants i is NIL or 1 <= i <= A.length. If A[j] == v then i = j. Initialization : i is NIL. Before prior iteration. Maintenance : When j increase loop invariants hold before iteration and remain true before next iteration. Termination : When the loop terminate it give us a solution that is true. 2.1-4 Consider the problem of adding two n-bit binary integers, stored in two n-element arrays A and B. The sum of two integers should be stored in binary form in an (n+1)-element arrary C. State the problem formally and write pseudocode for adding two integers Input : A and B are n-bit binary integers, stored in two n-element arrary A and B. (A,B[i] = 0, 1) Output : C are n+1 bit binary integer, stored in (n+1) element arrary. ADD(A, B) carry = 0 For A.length downto 1 sum = A[i] + B[i] + carry C[i + 1] = sum % 2 carry = sum / 2 C[1] = carry code Analyzing Algorithms Predicting the resources that the algorithm required. We want to the performance measure of an algorithms to find best solution with machine-independent. Measuring Resources Computational time Memory Communication Bandwidth Model of implementation A generic one processor. random-access machine(RAM): instructions are executed one after another, with no concurrent operations. We assume our RAM is almost identical with real machine. (also computational time of instructions.) Analysis of insertion sort Running time of a program as a function of the size of its input. $$ f(\\text{size of input}) = \\text{Running time}$$ - input size: depends on the problem being studied. We shall indicate which input size measures is being used with each problem we study. - running time: the number of primitive steps or operations executed. It is convenient to define the notion of step so it is as machine-independent as possible. - We shall assume that each execution of the $i$th line takes time $c_{i}$, where $c_{i}$ is a constant. - We let $t_{j}$ denote the number of times the while loop test in line 5 is executed for that value of j. INSERATION-SORT(A) cost times 1 for j = 2 to A.length c1 n 2 key = A[j] c2 n-1 3 // ... 0 n-1 4 i = j - 1 c4 n-1 5 while i > 0 and A[i] > key c5 \\sum_{j=2}^{n} t_{j} 6 A[i + 1] = A[i] c6 \\sum_{j=2}^{n} (t_{j} - 1) 7 i = i - 1 c7 \\sum_{j=2}^{n} (t_{j} - 1) 8 A[i + 1] = key c8 n-1 The running time of algorithm is the sum of running time for each statement executed; $$ T(N) = c_{1}n + c_{2}(n-1) + c_{4}(n-1) + c_{5}\\sum_{j=2}^{n} t_{j} + c_{6}\\sum_{j=2}^{n} (t_{j} - 1) + c_{7}\\sum_{j=2}^{n} (t_{j} - 1) + c_{8}(n-1)$$ The best occurs if the array is already sorted. $$ \\begin{align} T(N) & = c_{1}n + c_{2}(n-1) + c_{4}(n-1) + c_{5}(n-1) + c_{8}(n-1) \\\\ & = (c_{1} + c_{2} + c_{4} + c_{5} + c_{8})n - (c_{2} + c_{4} + c_{5} + c_{8}) \\\\ & = an + b \\end{align} $$ It is thus a liner function of n. The worst occur if the array is in reversed order. We must compare each element A[j] with each element in the entire sorted subarray $A[1..j-1]$ and so $t_{j}$ for $ j = 2, 3, .., n$ $$ t_{1},..t_{j} = 2,..,n $$ Summation $$ \\begin{align} 1 + 2 + ... + n & = \\sum_{k=1}^{n} k \\\\ & = \\frac{1}{2}n(n+1) \\\\ \\end{align} $$ Apply to above equations start from 2 not from 1 $$ \\sum_{j=2}^{n}t_{j} = \\sum_{j=2}^{n}j = \\frac{n(n+1)}{2} - 1$$ 1 + 2 = 3, (1 - 1) + (2 - 1) = 1, because 1 - 1 = 0 we don't need to subtract 1. $$ \\sum_{j=2}^{n}(t_{j} - 1) = \\sum_{j=2}^{n}(j - 1) = \\frac{n(n-1)}{2}$$ $$ \\begin{align} T(N) & = c_{1}n + c_{2}(n-1) + c_{4}(n-1) + c_{5}\\Biggl( \\frac{n(n+1)}{2} - 1 \\Biggr) + c_{6}\\Biggl( \\frac{n(n-1)}{2} \\Biggr) + c_{7}\\Biggl( \\frac{n(n-1)}{2} \\Biggr)+ c_{8}(n-1) \\\\ & = \\biggl(\\frac{c_{5}}{2} + \\frac{c_{6}}{2} + \\frac{c_{7}}{2}\\biggr)n^{2} + \\biggl( c_{1} + c_{2} + c_{4} + \\frac{c_{5}}{2} - \\frac{c_{6}}{2} - \\frac{c_{7}}{2} + c_{8}\\biggr)n - (c_{2} + c_{4} + c_{5} + c_{8}) \\\\ & = an^{2} + bn + c \\end{align} $$ It is a quadratic function of n $an^{2} + bn + c$ Worst-case and average-case analysis Worst-case is the longest time for any input of size n. - It provide guarantee that the algorithm will never take any longer. - The worst case occurs fairly open - The \"average case\" is often roughly as bad as the worst case. Order of growth We use some simplifying abstractions to ease our analysis of the algorithm running time. - Ignore the actual costs of each statement.(e.g. $c_{i}$) - Ignore the abstract costs of $c_{i}$s (e.g. a, b, c in $an^{2} + bn + c$) - Rate of growth or order of growth is considering only the leading term of a formula (e.g. $an^{2}$) $$\\Theta(n^{2}) = \\text{theta of n-squred}$$ We usually consider one algorithm to be more efficient than another if its worst-case learning time has a lower order of growth. Exercises 2.2-1 Express the function $n^{3}/1000 - 100n^{2} - 100n + 3$ in terms of $\\Theta-notation.$ $$\\Theta(n^{3})$$ 2.2-2 Consider sorting n numbers stored in array A by first finding the smallest element of A and exchanging it with the element in A[i]. Then find the second smallest element of A, and exchange it with the element in A[2]. Continue in this manner for the first $n-1$ element of A. Generalize problem. Input : Sequence of n elements $A = < a_{1}, a_{2}, ... , a_{n} >$ Output : Permutation (ordered) $A = < a_{1}^{\\prime},a_{2}^{\\prime},...,a_{n}^{\\prime} >$ of the input sequence such that satisfies $ a_{1}^{\\prime} \\le a_{2}^{\\prime} \\le ... \\le a_{n}^{\\prime} $. Write pseudocode for this algorithm, which is known as selection sort. SELECTION-SORT(A) n = A.length For j = 1 to n - 1 smallest = j for i = j + 1 to n if A[i] < A[smallest] smallest = i exchange A[j] with A[smallest] # temp = A[j] # A[j] = A[smallest] # A[smallest] = temp code What loop invariant dose this algorithm maintain? Loop Invariant: The sub-array A[1..j] consists of the elements originally in A[1..j]. But in sorted order. Initialization: It is true prior to the first iteration of the loop. When j = 1, The subarray A[1..j] consists of just 1 element A[1], which is in fact originally element in A[1]. Moreover the subarray is sorted(trivially of course). maintenance: It is true before an iteration, it remains true before the next iteration. Before an iteration A[1..j - 1] is in sorted order. In iteration we insert minimum value to A[j], A[1..j] will remains sorted order. Incrementing j for the next iteration of the for loop then preserve the order. termination: When the loop terminate, the invariant give us a useful property that helps show that the algorithm is correct. The condition causing that the loop terminate is that j > A.length = n. Because each loop iteration increase j by 1, we must have j = n + 1 at that time. Substituting n + 1 for j in the wording of loop invariant, we have that the sub-array A[1..n] consists of elements originally in A[1..n], but in sorted order. Why dose it need to run for only the first n - 1 elements, rather than for all n elements? The subarray A[1..j-1] consists of the smallest elements 1-n elements, and therefore element A[n] must be the largest element. Give the best-case and worst case running times of selection sort in $\\Theta-$notation. SELECTION-SORT(A) | cost | time 1 n = A.length | c1 | 1 2 For j = 1 to n - 1 | c2 | n 3 smallest = j | c3 | n-1 4 for i = j + 1 to n | c4 | \\sum_{j=1}^{n} t_{j} 5 if A[i] < A[smallest] | c5 | \\sum_{j=1}^{n} (t_{j} - 1) 6 smallest = i | c6 | \\sum_{j=1}^{n} (t_{j} - 1) 7 exchange A[j] with A[smallest] | c7 | n-1 8 # temp = A[j] 9 # A[j] = A[smallest] 10 # A[smallest] = temp Best case & worst case is same $$ \\begin{align} T(n) & = c_{1} + c_{2}n + c_{3}(n-1) + c_{4}\\Biggl( \\sum_{j=1}^{n} t_{j} \\Biggr) + c_{5}\\Biggl( \\sum_{j=1}^{n} (t_{j} - 1) \\Biggr) + c_{6}\\Biggl( \\sum_{j=1}^{n} (t_{j} - 1) \\Biggr) + c_{7}(n-1) \\\\ & = c_{1} + c_{2}n + c_{3}(n-1) + c_{4}\\Biggl( \\frac{n(n+1)}{2} \\Biggr) + c_{5}\\Biggl( \\frac{n(n-1)}{2} \\Biggr) + c_{6}\\Biggl( \\frac{n(n-1)}{2} \\Biggr) + c_{7}(n-1) \\\\ & = (\\frac{c_{4}}{2} + \\frac{c_{5}}{2} + \\frac{c_{6}}{2})n^{2} + (c_{2} + c_{3} + \\frac{c_{4}}{2} - \\frac{c_{5}}{2} - \\frac{c_{6}}{2} + c_{7})n + (c_{1} - c_{3} - c_{7}) \\\\ & \\approx \\Theta(n^{2}) \\end{align} $$ 2.2-3 Consider linear search again (see Exercise 2.1-3). How many elements of the input sequence need to be checked on the average, assuming that the element begin searched for is equally likely to be any element in the array? LINEAR-SEARCH(A, v) i = NIL For j = 1 to A.length if A[j] == v i = j code simplify problem We have input sequence <1, 2>. We assume search for 1,2 as equally likely When we search 1, what is the probability it is at A[0]? $ \\frac{1}{2}$ When we search 1, what is the probability it is at A[1]? $ \\frac{1}{2}$ How many elements of the input sequence need to be checked on the average? $$ E(n) = 1 * 1/2 + 2 * 1/2 = 1/2 + 1 = 1.5$$ Generalize problem $$ \\begin{align} E(n) & = \\sum_{k=1}^{n} (k * 1/n) \\\\ & = \\frac{1}{n} \\sum_{k=1}^{n}k \\\\ & = \\frac{1}{n}\\frac{n(n+1)}{2} \\\\ & \\approx \\Theta(n) \\end{align} $$ How about in the worst case? n running times What are the average-case and worst-case running times of linear search in \u201a$\\Theta$-notation? Justify your answers. - When average-case running time is $\\Theta(n)$ (refer to Generalize problem). - When worst-case same, running time is n, it is $\\Theta(n)$ - Then both case running time in $\\Theta$-notation is $\\Theta(n)$. 2.2-4 How can we modify almost any algorithm to have a good best-case running time? Good best-case only possible some special case of input so it is impossible in general. 2.3 Designing algorithms 2.3.1 The divide-and-conquer approach To solve a given problem, they call themselves recursively one or more times to deal with closely related sub-problems. These algorithms follows a divide-and-conquer approach: they break down the problem into several subproblems recursively, and then combine these solution to create a solution to the original problem. The divide-and-conquer paradigm involves three steps at each level of recursion: General approach Divide #### the problem into smaller problems that are the smaller instance of the same problem. Conquer #### the subproblems by solving them. If its size small enough, however, just solve the subproblems in a straightforward manner. Combine the solution to the subproblems into the solution for a original problem Merge Sort approach The merge sort algorithm follows divide-and-conquer approach. Divide Divide the n-element sequence into two subsequence of n/2-elements each. Conquer Sort the subsequences using merge sort. Combine Merge the two sorted subsequences to produce the sorted answer Pseudo code Parameters A is array. p,q,r are indices into the array such that $p \\leq q \\lt r$ The procedure assumes that the subarray A[p..q] and A[q+1..r] are in sorted order. It merges them to form a single sorted subarray that replace the current subarray A[p..r]. Idea There is sequence which sorted in specific ranges. Break down into new two sorted temp sequences. Add infinite to end of two temp arrays. Merge and copy two sorted array into original array. // A = [1,4,2,3] // MERGE(A, 2, 3, 4) 1 MERGE(A, p, q, r) // in alphbet o,p,q,r,.. 2 lenL = q - p + 1 3 lenR = r - q 4 for i = 1 to lenL 5 L[i] = A[p + i - 1] 6 for j = 1 to lenR 7 R[j] = A[q + j] 8 L[lenL + 1] = infin 9 R[lenR + 1] = infin 10 i = 1 11 j = 1 12 for k = p to r 13 if L[i] <= R[j] 14 A[k] = L[i] 15 i = i + 1 16 else 17 A[k] = R[j] 18 j = j + 1 code Prove Loop invariant At the start of each iteration of the for loop of lines 12-18, the subarray A[p..k-1] contains the k-p smallest elements of $L[1..n_{1} + 1]$ and $R[1..n_{2} + 1]$, in sorted order. Moreover L[i] and L[j] are the smallest elements of their arrays that have not been copied back into A. Initialization Prior to the first iteration of the loop, we have k = p, so that the subarray A[p..k-1] is empty. This subarray contains k - p = 0 elements of L and R. Since j = i = 1, both L[i], R[j] are the smallest elements of their arrays that has not been coped back into A. Maintenance To see that each iteration maintains the loop invariant, let us suppose $L[i] \\leq R[j]$. Then $L[i]$ is the smallest element not yet copied back into A. Because $A[p..k - 1]$ contains the k - p smallest elements, after line 14 copies L[i] into A[k]. Incrementing k and i reestablishes the loop invariant for the next iteration. Termination At termination, k = r + 1. By the loop invariant, the subarray $A[p..k-1]$, which is $A[p..r]$, contains the $k - p = r - p + 1$ smallest elements // A = 5,3, 4,1 // // 1,3,4,5 // / \\ // 3,5 1,4 // / \\ / \\ // 3 5 1 4 //MERGE-SORT(A, 1, A.length) MERGE-SORT(A,p,r) if p < r q = lower((p + r)/2) MERGE-SORT(A, p, q) MERGE-SORT(A, q + 1, r) MERGE(A, p, q, r) 2.3. Analyzing divide-and-conquer algorithms Recurrence equation, recurrence Describe the overall running time on a problem of size n in terms of running time of smaller inputs. $$ T(n) = \\begin{cases} \\Theta(1), & \\text{if $n \\leq c$,} \\\\ aT(n/b) + D(n) + C(n), & \\text{otherwise.} \\end{cases} $$ Divide $D(n) = \\Theta(n)$ Conquer $2T(n/2)$ Combine $C(n)=\\Theta(n)$ $$ T(n) = \\begin{cases} c, & \\text{if $n = 1$,} \\\\ 2T(n/2) + cn, & \\text{$n \\gt 1$,} \\end{cases} $$ T(n) cn cn / \\ / \\ T(n/2) T(n/2) cn/2 cn/2 / \\ / \\ T(n/4) T(n/4) T(n/4) T(n/4) A cn --> cn | / \\ | cn/2 cn/2 --> cn lgn / \\ / \\ | .... | | | | ... | | V c c c c c --> cn \\______________________/ n Level of tree: lg n + 1 Total = (lg n + 1 ) * cn = lg n * cn + cn Worst case is $\\Theta(n \\log n)$ Exercises 2.3-1 Using Figure 2.4 as a model, illustrate the operation of merge sort on the array. A = <3, 41, 52, 26, 38, 57, 9, 49> 3,9,26,38,41,49,51,57 / \\ 3,26,41,51 9,38,49,57 / \\ / \\ 3,41 26,51 38,57 9,49 / \\ / \\ / \\ / \\ 3 41 52 26 38 57 9 49 2.3-2 Rewrite the MERGE procedure so that is dose not use sentinels, instead stopping once either array L or R has had all its elements copied back to A and then copying the remainder of other array back into A. MERGE() 2.3-3 Use mathematical induction to show that when n is an exact power of 2, the solution of the recurrence $$ T(n) = \\begin{cases} 2, & \\text{if $n = 2$,} \\\\ 2T(n/2) + n, & \\text{if $n = 2^{k}$, for $k > 1$} \\end{cases} $$ is $T(n) = n \\log n$ From https://mitpress.mit.edu/books/introduction-algorithms-third-edition","title":"2.Getting Started"},{"location":"etc/algorithm/en_2_getting_started/#2getting-started","text":"","title":"2.Getting Started"},{"location":"etc/algorithm/en_2_getting_started/#check-list-for-learning-algorithm","text":"Idea. Pseudocode. Argue that it is correctly works. Analyze its running time.","title":"Check list for learning algorithm"},{"location":"etc/algorithm/en_2_getting_started/#problem","text":"Input : A sequence of n elements $ A = < a_{1}, a_{2}, ... ,a_{n} > $. Output : The permutation(reordering) $ A = < a_{1}^{\\prime},a_{2}^{\\prime},...,a_{n}^{\\prime} > $ of the input sequence such that satisfies $ a_{1}^{\\prime} \\le a_{2}^{\\prime} \\le ... \\le a_{n}^{\\prime} $.","title":"Problem"},{"location":"etc/algorithm/en_2_getting_started/#insertion-sort","text":"","title":"Insertion sort"},{"location":"etc/algorithm/en_2_getting_started/#idea","text":"Idea: incremental approach. increment sorted array. insert current item into the sorted array A[1..j - 1] HowTo: Start from sorted length 1 array. Until conditions meet - i > 0 and A[i] > key Move i to one step back. Decrease i. Insert current item in A[i + 1]","title":"Idea"},{"location":"etc/algorithm/en_2_getting_started/#pseudocode","text":"Pursue clean and concise INSERATION-SORT(A) 1 for j = 2 to A.length 2 key = A[j] 3 // Insert A[j] into the sorted sequence A[1..j - 1] 4 i = j - 1 5 while i > 0 and A[i] > key 6 A[i + 1] = A[i] 7 i = i - 1 8 A[i + 1] = key","title":"Pseudocode"},{"location":"etc/algorithm/en_2_getting_started/#tip","text":"Use \"i\" as a important loop variable name. Use simple condition first when there is logical concatenation. Use left as variable and right as almost constant value when compare two numbers. Make it simple as possible","title":"Tip"},{"location":"etc/algorithm/en_2_getting_started/#argue-that-it-is-correctly-works","text":"","title":"Argue that it is correctly works"},{"location":"etc/algorithm/en_2_getting_started/#guess","text":"I will use loop invariants. It keeps from start to terminate. I'll claim sub-array is always sorted.","title":"Guess"},{"location":"etc/algorithm/en_2_getting_started/#loop-invariant","text":"The sub-array A[1..j-1] consists of the elements originally in A[1..j-1], but in sorted order. It is similarity to the mathematical induction. We say an algorithm has true loop invariant on some properties. When the three properties hold, the loop invariant is true. Initialization: It is true prior to the first iteration of the loop. Maintenance: If it is true before an iteration of the loop,it remains true before the next iteration. Termination: When the loop terminates, the invariant gives us a useful property that helps show that the algorithm is correct.","title":"loop invariant:"},{"location":"etc/algorithm/en_2_getting_started/#initialization","text":"When j = 2, The subarray A[1..j-1] consists of just one element A[1], which is in fact the original element in A[1]. Moreover, the subarray is sorted(trivially, of course).","title":"Initialization"},{"location":"etc/algorithm/en_2_getting_started/#maintenance","text":"The body of for loop works by moving A[j-1], A[j-2], A[j-3], and so on by one position to the right until it finds the proper position for A j , at which point it inserts the value of a j . The subarray A[1..j] then consists of the elements originally in A[1..j],but it sorted order. Incrementing j for the next iteration of the for loop then preserve the loop invariant.","title":"Maintenance"},{"location":"etc/algorithm/en_2_getting_started/#termination","text":"The condition causing the for loop to terminate is that j > A.length = n. Because each loop iteration increase j by 1, we must have j = n + 1 at that time. Substituting n + 1 for j in the wording of loop invariant, we have that the subarray A[1..n] consists of the element originally in A[1..n], but in sorted order.","title":"Termination"},{"location":"etc/algorithm/en_2_getting_started/#pseudocode-conventions","text":"We use the keyword to when a for loop increments its loop counter. We use the keyword downto when a for loop decrements its loop counter. When the loop counter changes by an amount greater then 1, the amount of change follows the optional keyword by. We shall not use global variables without explicit indication. The notation .. is used to indicate a range of values within an arrary. Thus, A[1..j] indicates the subarray of A consisting of the j elements A[1],A[2],...,A[j]. We organize compound date into objects, which are composed of attributes. We treat a variable represent arrary and object as a point to the date representing the arrary or object. For all attributes f of an object x, setting y = x causes y.f to equal x.f. Moreover, if we now set x.f = 3, then afterward not only dose x.f equal 3, but y.f equals 3 as well. In other words, x and y point to same object after the assignment y = x. We pass parameter to a procedure by value. When object passed, the pointer to the data representing object is copied. We allow multiple values to be returned by a single return statement. The boolean operators \"and\" and \"or\" are short circuiting.","title":"Pseudocode conventions"},{"location":"etc/algorithm/en_2_getting_started/#exercise","text":"","title":"Exercise"},{"location":"etc/algorithm/en_2_getting_started/#21-1","text":"Using Figure 2.2 as a model, illustrate the operation of INSERTION-SORT on the Arrary A = <31, 41, 59, 26, 41. 58>","title":"2.1-1"},{"location":"etc/algorithm/en_2_getting_started/#21-2","text":"Rewrite the Insertion-sort procedure to sort into nonincreasing instead of nondescreasing. INSERATION-SORT(A) For j = 2 to A.length key = A[j] i = j - 1 while i > 0 and A[i] < Key A[i + 1] = A[i] i = i - 1 A[i + 1] = key","title":"2.1-2"},{"location":"etc/algorithm/en_2_getting_started/#21-3","text":"Consider the searching problem : - Input : A sequence of n numbers $ A = < a_{1}, a_{2},...,a_{n} > $ and a value v. - Output : An index i such that v = A[i] or the special value NIL if v dose not appear in A. Write pseudocode for linear search, which scan trough the sequence, looking for v. Using a loop invariant, prove that your algorithm is correct. Make sure that your loop invariant fulfills the three necessary properties.","title":"2.1-3"},{"location":"etc/algorithm/en_2_getting_started/#pseudocode_1","text":"LINEAR-SEARCH(A, v) i = NIL For j = 1 to A.length if A[j] == v i = j code","title":"pseudocode"},{"location":"etc/algorithm/en_2_getting_started/#loop-invariants","text":"i is NIL or 1 <= i <= A.length. If A[j] == v then i = j. Initialization : i is NIL. Before prior iteration. Maintenance : When j increase loop invariants hold before iteration and remain true before next iteration. Termination : When the loop terminate it give us a solution that is true.","title":"loop invariants"},{"location":"etc/algorithm/en_2_getting_started/#21-4","text":"Consider the problem of adding two n-bit binary integers, stored in two n-element arrays A and B. The sum of two integers should be stored in binary form in an (n+1)-element arrary C. State the problem formally and write pseudocode for adding two integers Input : A and B are n-bit binary integers, stored in two n-element arrary A and B. (A,B[i] = 0, 1) Output : C are n+1 bit binary integer, stored in (n+1) element arrary. ADD(A, B) carry = 0 For A.length downto 1 sum = A[i] + B[i] + carry C[i + 1] = sum % 2 carry = sum / 2 C[1] = carry code","title":"2.1-4"},{"location":"etc/algorithm/en_2_getting_started/#analyzing-algorithms","text":"Predicting the resources that the algorithm required. We want to the performance measure of an algorithms to find best solution with machine-independent.","title":"Analyzing Algorithms"},{"location":"etc/algorithm/en_2_getting_started/#measuring-resources","text":"Computational time Memory Communication Bandwidth","title":"Measuring Resources"},{"location":"etc/algorithm/en_2_getting_started/#model-of-implementation","text":"A generic one processor. random-access machine(RAM): instructions are executed one after another, with no concurrent operations. We assume our RAM is almost identical with real machine. (also computational time of instructions.)","title":"Model of implementation"},{"location":"etc/algorithm/en_2_getting_started/#analysis-of-insertion-sort","text":"Running time of a program as a function of the size of its input. $$ f(\\text{size of input}) = \\text{Running time}$$ - input size: depends on the problem being studied. We shall indicate which input size measures is being used with each problem we study. - running time: the number of primitive steps or operations executed. It is convenient to define the notion of step so it is as machine-independent as possible. - We shall assume that each execution of the $i$th line takes time $c_{i}$, where $c_{i}$ is a constant. - We let $t_{j}$ denote the number of times the while loop test in line 5 is executed for that value of j. INSERATION-SORT(A) cost times 1 for j = 2 to A.length c1 n 2 key = A[j] c2 n-1 3 // ... 0 n-1 4 i = j - 1 c4 n-1 5 while i > 0 and A[i] > key c5 \\sum_{j=2}^{n} t_{j} 6 A[i + 1] = A[i] c6 \\sum_{j=2}^{n} (t_{j} - 1) 7 i = i - 1 c7 \\sum_{j=2}^{n} (t_{j} - 1) 8 A[i + 1] = key c8 n-1 The running time of algorithm is the sum of running time for each statement executed; $$ T(N) = c_{1}n + c_{2}(n-1) + c_{4}(n-1) + c_{5}\\sum_{j=2}^{n} t_{j} + c_{6}\\sum_{j=2}^{n} (t_{j} - 1) + c_{7}\\sum_{j=2}^{n} (t_{j} - 1) + c_{8}(n-1)$$ The best occurs if the array is already sorted. $$ \\begin{align} T(N) & = c_{1}n + c_{2}(n-1) + c_{4}(n-1) + c_{5}(n-1) + c_{8}(n-1) \\\\ & = (c_{1} + c_{2} + c_{4} + c_{5} + c_{8})n - (c_{2} + c_{4} + c_{5} + c_{8}) \\\\ & = an + b \\end{align} $$ It is thus a liner function of n. The worst occur if the array is in reversed order. We must compare each element A[j] with each element in the entire sorted subarray $A[1..j-1]$ and so $t_{j}$ for $ j = 2, 3, .., n$ $$ t_{1},..t_{j} = 2,..,n $$ Summation $$ \\begin{align} 1 + 2 + ... + n & = \\sum_{k=1}^{n} k \\\\ & = \\frac{1}{2}n(n+1) \\\\ \\end{align} $$","title":"Analysis of insertion sort"},{"location":"etc/algorithm/en_2_getting_started/#apply-to-above-equations","text":"start from 2 not from 1 $$ \\sum_{j=2}^{n}t_{j} = \\sum_{j=2}^{n}j = \\frac{n(n+1)}{2} - 1$$ 1 + 2 = 3, (1 - 1) + (2 - 1) = 1, because 1 - 1 = 0 we don't need to subtract 1. $$ \\sum_{j=2}^{n}(t_{j} - 1) = \\sum_{j=2}^{n}(j - 1) = \\frac{n(n-1)}{2}$$ $$ \\begin{align} T(N) & = c_{1}n + c_{2}(n-1) + c_{4}(n-1) + c_{5}\\Biggl( \\frac{n(n+1)}{2} - 1 \\Biggr) + c_{6}\\Biggl( \\frac{n(n-1)}{2} \\Biggr) + c_{7}\\Biggl( \\frac{n(n-1)}{2} \\Biggr)+ c_{8}(n-1) \\\\ & = \\biggl(\\frac{c_{5}}{2} + \\frac{c_{6}}{2} + \\frac{c_{7}}{2}\\biggr)n^{2} + \\biggl( c_{1} + c_{2} + c_{4} + \\frac{c_{5}}{2} - \\frac{c_{6}}{2} - \\frac{c_{7}}{2} + c_{8}\\biggr)n - (c_{2} + c_{4} + c_{5} + c_{8}) \\\\ & = an^{2} + bn + c \\end{align} $$ It is a quadratic function of n $an^{2} + bn + c$","title":"Apply to above equations"},{"location":"etc/algorithm/en_2_getting_started/#worst-case-and-average-case-analysis","text":"Worst-case is the longest time for any input of size n. - It provide guarantee that the algorithm will never take any longer. - The worst case occurs fairly open - The \"average case\" is often roughly as bad as the worst case.","title":"Worst-case and average-case analysis"},{"location":"etc/algorithm/en_2_getting_started/#order-of-growth","text":"We use some simplifying abstractions to ease our analysis of the algorithm running time. - Ignore the actual costs of each statement.(e.g. $c_{i}$) - Ignore the abstract costs of $c_{i}$s (e.g. a, b, c in $an^{2} + bn + c$) - Rate of growth or order of growth is considering only the leading term of a formula (e.g. $an^{2}$) $$\\Theta(n^{2}) = \\text{theta of n-squred}$$ We usually consider one algorithm to be more efficient than another if its worst-case learning time has a lower order of growth.","title":"Order of growth"},{"location":"etc/algorithm/en_2_getting_started/#exercises","text":"","title":"Exercises"},{"location":"etc/algorithm/en_2_getting_started/#22-1","text":"Express the function $n^{3}/1000 - 100n^{2} - 100n + 3$ in terms of $\\Theta-notation.$ $$\\Theta(n^{3})$$","title":"2.2-1"},{"location":"etc/algorithm/en_2_getting_started/#22-2","text":"Consider sorting n numbers stored in array A by first finding the smallest element of A and exchanging it with the element in A[i]. Then find the second smallest element of A, and exchange it with the element in A[2]. Continue in this manner for the first $n-1$ element of A.","title":"2.2-2"},{"location":"etc/algorithm/en_2_getting_started/#generalize-problem","text":"Input : Sequence of n elements $A = < a_{1}, a_{2}, ... , a_{n} >$ Output : Permutation (ordered) $A = < a_{1}^{\\prime},a_{2}^{\\prime},...,a_{n}^{\\prime} >$ of the input sequence such that satisfies $ a_{1}^{\\prime} \\le a_{2}^{\\prime} \\le ... \\le a_{n}^{\\prime} $.","title":"Generalize problem."},{"location":"etc/algorithm/en_2_getting_started/#write-pseudocode-for-this-algorithm-which-is-known-as-selection-sort","text":"SELECTION-SORT(A) n = A.length For j = 1 to n - 1 smallest = j for i = j + 1 to n if A[i] < A[smallest] smallest = i exchange A[j] with A[smallest] # temp = A[j] # A[j] = A[smallest] # A[smallest] = temp code","title":"Write pseudocode for this algorithm, which is known as selection sort."},{"location":"etc/algorithm/en_2_getting_started/#what-loop-invariant-dose-this-algorithm-maintain","text":"","title":"What loop invariant dose this algorithm maintain?"},{"location":"etc/algorithm/en_2_getting_started/#loop-invariant_1","text":"The sub-array A[1..j] consists of the elements originally in A[1..j]. But in sorted order.","title":"Loop Invariant:"},{"location":"etc/algorithm/en_2_getting_started/#initialization_1","text":"It is true prior to the first iteration of the loop. When j = 1, The subarray A[1..j] consists of just 1 element A[1], which is in fact originally element in A[1]. Moreover the subarray is sorted(trivially of course).","title":"Initialization:"},{"location":"etc/algorithm/en_2_getting_started/#maintenance_1","text":"It is true before an iteration, it remains true before the next iteration. Before an iteration A[1..j - 1] is in sorted order. In iteration we insert minimum value to A[j], A[1..j] will remains sorted order. Incrementing j for the next iteration of the for loop then preserve the order.","title":"maintenance:"},{"location":"etc/algorithm/en_2_getting_started/#termination_1","text":"When the loop terminate, the invariant give us a useful property that helps show that the algorithm is correct. The condition causing that the loop terminate is that j > A.length = n. Because each loop iteration increase j by 1, we must have j = n + 1 at that time. Substituting n + 1 for j in the wording of loop invariant, we have that the sub-array A[1..n] consists of elements originally in A[1..n], but in sorted order.","title":"termination:"},{"location":"etc/algorithm/en_2_getting_started/#why-dose-it-need-to-run-for-only-the-first-n-1-elements-rather-than-for-all-n-elements","text":"The subarray A[1..j-1] consists of the smallest elements 1-n elements, and therefore element A[n] must be the largest element.","title":"Why dose it need to run for only the first n - 1 elements, rather than for all n elements?"},{"location":"etc/algorithm/en_2_getting_started/#give-the-best-case-and-worst-case-running-times-of-selection-sort-in-theta-notation","text":"SELECTION-SORT(A) | cost | time 1 n = A.length | c1 | 1 2 For j = 1 to n - 1 | c2 | n 3 smallest = j | c3 | n-1 4 for i = j + 1 to n | c4 | \\sum_{j=1}^{n} t_{j} 5 if A[i] < A[smallest] | c5 | \\sum_{j=1}^{n} (t_{j} - 1) 6 smallest = i | c6 | \\sum_{j=1}^{n} (t_{j} - 1) 7 exchange A[j] with A[smallest] | c7 | n-1 8 # temp = A[j] 9 # A[j] = A[smallest] 10 # A[smallest] = temp","title":"Give the best-case and worst case running times of selection sort in $\\Theta-$notation."},{"location":"etc/algorithm/en_2_getting_started/#best-case-worst-case-is-same","text":"$$ \\begin{align} T(n) & = c_{1} + c_{2}n + c_{3}(n-1) + c_{4}\\Biggl( \\sum_{j=1}^{n} t_{j} \\Biggr) + c_{5}\\Biggl( \\sum_{j=1}^{n} (t_{j} - 1) \\Biggr) + c_{6}\\Biggl( \\sum_{j=1}^{n} (t_{j} - 1) \\Biggr) + c_{7}(n-1) \\\\ & = c_{1} + c_{2}n + c_{3}(n-1) + c_{4}\\Biggl( \\frac{n(n+1)}{2} \\Biggr) + c_{5}\\Biggl( \\frac{n(n-1)}{2} \\Biggr) + c_{6}\\Biggl( \\frac{n(n-1)}{2} \\Biggr) + c_{7}(n-1) \\\\ & = (\\frac{c_{4}}{2} + \\frac{c_{5}}{2} + \\frac{c_{6}}{2})n^{2} + (c_{2} + c_{3} + \\frac{c_{4}}{2} - \\frac{c_{5}}{2} - \\frac{c_{6}}{2} + c_{7})n + (c_{1} - c_{3} - c_{7}) \\\\ & \\approx \\Theta(n^{2}) \\end{align} $$","title":"Best case &amp; worst case is same"},{"location":"etc/algorithm/en_2_getting_started/#22-3","text":"Consider linear search again (see Exercise 2.1-3). How many elements of the input sequence need to be checked on the average, assuming that the element begin searched for is equally likely to be any element in the array? LINEAR-SEARCH(A, v) i = NIL For j = 1 to A.length if A[j] == v i = j code","title":"2.2-3"},{"location":"etc/algorithm/en_2_getting_started/#simplify-problem","text":"We have input sequence <1, 2>. We assume search for 1,2 as equally likely When we search 1, what is the probability it is at A[0]? $ \\frac{1}{2}$ When we search 1, what is the probability it is at A[1]? $ \\frac{1}{2}$ How many elements of the input sequence need to be checked on the average? $$ E(n) = 1 * 1/2 + 2 * 1/2 = 1/2 + 1 = 1.5$$","title":"simplify problem"},{"location":"etc/algorithm/en_2_getting_started/#generalize-problem_1","text":"$$ \\begin{align} E(n) & = \\sum_{k=1}^{n} (k * 1/n) \\\\ & = \\frac{1}{n} \\sum_{k=1}^{n}k \\\\ & = \\frac{1}{n}\\frac{n(n+1)}{2} \\\\ & \\approx \\Theta(n) \\end{align} $$","title":"Generalize problem"},{"location":"etc/algorithm/en_2_getting_started/#how-about-in-the-worst-case","text":"n","title":"How about in the worst case?"},{"location":"etc/algorithm/en_2_getting_started/#running-times","text":"What are the average-case and worst-case running times of linear search in \u201a$\\Theta$-notation? Justify your answers. - When average-case running time is $\\Theta(n)$ (refer to Generalize problem). - When worst-case same, running time is n, it is $\\Theta(n)$ - Then both case running time in $\\Theta$-notation is $\\Theta(n)$.","title":"running times"},{"location":"etc/algorithm/en_2_getting_started/#22-4","text":"How can we modify almost any algorithm to have a good best-case running time? Good best-case only possible some special case of input so it is impossible in general.","title":"2.2-4"},{"location":"etc/algorithm/en_2_getting_started/#23-designing-algorithms","text":"","title":"2.3 Designing algorithms"},{"location":"etc/algorithm/en_2_getting_started/#231-the-divide-and-conquer-approach","text":"To solve a given problem, they call themselves recursively one or more times to deal with closely related sub-problems. These algorithms follows a divide-and-conquer approach: they break down the problem into several subproblems recursively, and then combine these solution to create a solution to the original problem. The divide-and-conquer paradigm involves three steps at each level of recursion:","title":"2.3.1 The divide-and-conquer approach"},{"location":"etc/algorithm/en_2_getting_started/#general-approach","text":"","title":"General approach"},{"location":"etc/algorithm/en_2_getting_started/#divide","text":"the problem into smaller problems that are the smaller instance of the same problem.","title":"Divide ####"},{"location":"etc/algorithm/en_2_getting_started/#conquer","text":"the subproblems by solving them. If its size small enough, however, just solve the subproblems in a straightforward manner.","title":"Conquer ####"},{"location":"etc/algorithm/en_2_getting_started/#combine","text":"the solution to the subproblems into the solution for a original problem","title":"Combine"},{"location":"etc/algorithm/en_2_getting_started/#merge-sort-approach","text":"The merge sort algorithm follows divide-and-conquer approach.","title":"Merge Sort approach"},{"location":"etc/algorithm/en_2_getting_started/#divide_1","text":"Divide the n-element sequence into two subsequence of n/2-elements each.","title":"Divide"},{"location":"etc/algorithm/en_2_getting_started/#conquer_1","text":"Sort the subsequences using merge sort.","title":"Conquer"},{"location":"etc/algorithm/en_2_getting_started/#combine_1","text":"Merge the two sorted subsequences to produce the sorted answer","title":"Combine"},{"location":"etc/algorithm/en_2_getting_started/#pseudo-code","text":"","title":"Pseudo code"},{"location":"etc/algorithm/en_2_getting_started/#parameters","text":"A is array. p,q,r are indices into the array such that $p \\leq q \\lt r$ The procedure assumes that the subarray A[p..q] and A[q+1..r] are in sorted order. It merges them to form a single sorted subarray that replace the current subarray A[p..r].","title":"Parameters"},{"location":"etc/algorithm/en_2_getting_started/#idea_1","text":"There is sequence which sorted in specific ranges. Break down into new two sorted temp sequences. Add infinite to end of two temp arrays. Merge and copy two sorted array into original array. // A = [1,4,2,3] // MERGE(A, 2, 3, 4) 1 MERGE(A, p, q, r) // in alphbet o,p,q,r,.. 2 lenL = q - p + 1 3 lenR = r - q 4 for i = 1 to lenL 5 L[i] = A[p + i - 1] 6 for j = 1 to lenR 7 R[j] = A[q + j] 8 L[lenL + 1] = infin 9 R[lenR + 1] = infin 10 i = 1 11 j = 1 12 for k = p to r 13 if L[i] <= R[j] 14 A[k] = L[i] 15 i = i + 1 16 else 17 A[k] = R[j] 18 j = j + 1 code","title":"Idea"},{"location":"etc/algorithm/en_2_getting_started/#prove","text":"","title":"Prove"},{"location":"etc/algorithm/en_2_getting_started/#loop-invariant_2","text":"At the start of each iteration of the for loop of lines 12-18, the subarray A[p..k-1] contains the k-p smallest elements of $L[1..n_{1} + 1]$ and $R[1..n_{2} + 1]$, in sorted order. Moreover L[i] and L[j] are the smallest elements of their arrays that have not been copied back into A.","title":"Loop invariant"},{"location":"etc/algorithm/en_2_getting_started/#initialization_2","text":"Prior to the first iteration of the loop, we have k = p, so that the subarray A[p..k-1] is empty. This subarray contains k - p = 0 elements of L and R. Since j = i = 1, both L[i], R[j] are the smallest elements of their arrays that has not been coped back into A.","title":"Initialization"},{"location":"etc/algorithm/en_2_getting_started/#maintenance_2","text":"To see that each iteration maintains the loop invariant, let us suppose $L[i] \\leq R[j]$. Then $L[i]$ is the smallest element not yet copied back into A. Because $A[p..k - 1]$ contains the k - p smallest elements, after line 14 copies L[i] into A[k]. Incrementing k and i reestablishes the loop invariant for the next iteration.","title":"Maintenance"},{"location":"etc/algorithm/en_2_getting_started/#termination_2","text":"At termination, k = r + 1. By the loop invariant, the subarray $A[p..k-1]$, which is $A[p..r]$, contains the $k - p = r - p + 1$ smallest elements // A = 5,3, 4,1 // // 1,3,4,5 // / \\ // 3,5 1,4 // / \\ / \\ // 3 5 1 4 //MERGE-SORT(A, 1, A.length) MERGE-SORT(A,p,r) if p < r q = lower((p + r)/2) MERGE-SORT(A, p, q) MERGE-SORT(A, q + 1, r) MERGE(A, p, q, r)","title":"Termination"},{"location":"etc/algorithm/en_2_getting_started/#23-analyzing-divide-and-conquer-algorithms","text":"","title":"2.3. Analyzing divide-and-conquer algorithms"},{"location":"etc/algorithm/en_2_getting_started/#recurrence-equation-recurrence","text":"Describe the overall running time on a problem of size n in terms of running time of smaller inputs. $$ T(n) = \\begin{cases} \\Theta(1), & \\text{if $n \\leq c$,} \\\\ aT(n/b) + D(n) + C(n), & \\text{otherwise.} \\end{cases} $$","title":"Recurrence equation, recurrence"},{"location":"etc/algorithm/en_2_getting_started/#divide_2","text":"$D(n) = \\Theta(n)$","title":"Divide"},{"location":"etc/algorithm/en_2_getting_started/#conquer_2","text":"$2T(n/2)$","title":"Conquer"},{"location":"etc/algorithm/en_2_getting_started/#combine_2","text":"$C(n)=\\Theta(n)$ $$ T(n) = \\begin{cases} c, & \\text{if $n = 1$,} \\\\ 2T(n/2) + cn, & \\text{$n \\gt 1$,} \\end{cases} $$ T(n) cn cn / \\ / \\ T(n/2) T(n/2) cn/2 cn/2 / \\ / \\ T(n/4) T(n/4) T(n/4) T(n/4) A cn --> cn | / \\ | cn/2 cn/2 --> cn lgn / \\ / \\ | .... | | | | ... | | V c c c c c --> cn \\______________________/ n Level of tree: lg n + 1 Total = (lg n + 1 ) * cn = lg n * cn + cn Worst case is $\\Theta(n \\log n)$","title":"Combine"},{"location":"etc/algorithm/en_2_getting_started/#exercises_1","text":"","title":"Exercises"},{"location":"etc/algorithm/en_2_getting_started/#23-1","text":"Using Figure 2.4 as a model, illustrate the operation of merge sort on the array. A = <3, 41, 52, 26, 38, 57, 9, 49> 3,9,26,38,41,49,51,57 / \\ 3,26,41,51 9,38,49,57 / \\ / \\ 3,41 26,51 38,57 9,49 / \\ / \\ / \\ / \\ 3 41 52 26 38 57 9 49","title":"2.3-1"},{"location":"etc/algorithm/en_2_getting_started/#23-2","text":"Rewrite the MERGE procedure so that is dose not use sentinels, instead stopping once either array L or R has had all its elements copied back to A and then copying the remainder of other array back into A. MERGE()","title":"2.3-2"},{"location":"etc/algorithm/en_2_getting_started/#23-3","text":"Use mathematical induction to show that when n is an exact power of 2, the solution of the recurrence $$ T(n) = \\begin{cases} 2, & \\text{if $n = 2$,} \\\\ 2T(n/2) + n, & \\text{if $n = 2^{k}$, for $k > 1$} \\end{cases} $$ is $T(n) = n \\log n$","title":"2.3-3"},{"location":"etc/algorithm/en_2_getting_started/#from","text":"https://mitpress.mit.edu/books/introduction-algorithms-third-edition","title":"From"},{"location":"etc/android/googleplay/googleplay_billing/","text":"Google Play Billing Let you sell the digital content from inside an Android app. Building Blocks Google Play : An online store where users can download digital products. Google Play Console The interface app developers use to publish apps on Google Play. Google API Console The console for managing backend APIs, such as Google Play Developer API. Android device Any device used to run Android apps. Android app An application intended to run on Android device. Secure backend server A developer provided server used to implement purchase verification or subscription features. The Play Store app The app responsible for managing all operations related to the Google Play Billing. Google Play Billing Library An API that developers use to implement Google Play Billing within an app. Google Play Developer API A REST API used to programmatically perform a number of publishing and app-management tasks. Subscription and In-App purchase API. Publishing API. Real-time developer notifications Server push notifications that let you monitor state changes. In-app product types One-time products The Google Play Console calls them managed products. The Google Play Billing library calls them INAPP. Subscriptions Purchase tokens and order IDs Google Play billing tracks products and transactions using purchase tokens and order IDs. - A purchase token is a string that represents a buyer's entitlement to a product on Google Play. - An order ID is a string that represents a financial transactions on Google Play. For one-time products, every purchase creates a new token and a new order ID. For subscriptions, an initial purchase creates a purchase token and an order ID. For each continuous billing period, the purchase token stays the same and a new order ID is issued. In-app product configuration options configuration options: Title - A short description of the in-app product, such as \"loot box.\" Description - A longer description of the in-app product. Product ID - A unique, human readable ID for your product. also called SKUs (Stock keeping unit) Price / Default Price - The amount user will pay for the app-product. The default price for one=time products reflects the amount the user will be charged for the product. The default price for subscription is the price will be charged after they enter a regular billing cycle. A single app can have multiple in-app products available for purchase, each with different Product ID and price. Unique one-time product configuration options. Promo codes are codes that a user uses to get a one-time product free of charge. Unique subscription product configuration options. Billing period : The frequency at which a user is charged while their subscription is active. weekly, \"1, 3, 6 months\", annual Free trial period : An amount of time during which a user may access a subscription without being billed. Introductory price : The price of the subscription over a certain number of initial, \"introductory\" billing period. Grace period : The amount of time a user's subscription will remain active, giving the user additional time to fix their payment issue. Account hold : The state of a subscription can enter when a user does not update their form of payment during the grace period.","title":"Google Play Billing"},{"location":"etc/android/googleplay/googleplay_billing/#google-play-billing","text":"Let you sell the digital content from inside an Android app.","title":"Google Play Billing"},{"location":"etc/android/googleplay/googleplay_billing/#building-blocks","text":"Google Play : An online store where users can download digital products. Google Play Console The interface app developers use to publish apps on Google Play. Google API Console The console for managing backend APIs, such as Google Play Developer API. Android device Any device used to run Android apps. Android app An application intended to run on Android device. Secure backend server A developer provided server used to implement purchase verification or subscription features. The Play Store app The app responsible for managing all operations related to the Google Play Billing. Google Play Billing Library An API that developers use to implement Google Play Billing within an app. Google Play Developer API A REST API used to programmatically perform a number of publishing and app-management tasks. Subscription and In-App purchase API. Publishing API. Real-time developer notifications Server push notifications that let you monitor state changes.","title":"Building Blocks"},{"location":"etc/android/googleplay/googleplay_billing/#in-app-product-types","text":"One-time products The Google Play Console calls them managed products. The Google Play Billing library calls them INAPP. Subscriptions","title":"In-app product types"},{"location":"etc/android/googleplay/googleplay_billing/#purchase-tokens-and-order-ids","text":"Google Play billing tracks products and transactions using purchase tokens and order IDs. - A purchase token is a string that represents a buyer's entitlement to a product on Google Play. - An order ID is a string that represents a financial transactions on Google Play. For one-time products, every purchase creates a new token and a new order ID. For subscriptions, an initial purchase creates a purchase token and an order ID. For each continuous billing period, the purchase token stays the same and a new order ID is issued.","title":"Purchase tokens and order IDs"},{"location":"etc/android/googleplay/googleplay_billing/#in-app-product-configuration-options","text":"configuration options: Title - A short description of the in-app product, such as \"loot box.\" Description - A longer description of the in-app product. Product ID - A unique, human readable ID for your product. also called SKUs (Stock keeping unit) Price / Default Price - The amount user will pay for the app-product. The default price for one=time products reflects the amount the user will be charged for the product. The default price for subscription is the price will be charged after they enter a regular billing cycle. A single app can have multiple in-app products available for purchase, each with different Product ID and price.","title":"In-app product configuration options"},{"location":"etc/android/googleplay/googleplay_billing/#unique-one-time-product-configuration-options","text":"Promo codes are codes that a user uses to get a one-time product free of charge.","title":"Unique one-time product configuration options."},{"location":"etc/android/googleplay/googleplay_billing/#unique-subscription-product-configuration-options","text":"Billing period : The frequency at which a user is charged while their subscription is active. weekly, \"1, 3, 6 months\", annual Free trial period : An amount of time during which a user may access a subscription without being billed. Introductory price : The price of the subscription over a certain number of initial, \"introductory\" billing period. Grace period : The amount of time a user's subscription will remain active, giving the user additional time to fix their payment issue. Account hold : The state of a subscription can enter when a user does not update their form of payment during the grace period.","title":"Unique subscription product configuration options."},{"location":"etc/android/googleplay/googleplay_billing_library/","text":"Google Play Billing Library About the code snippets TrivialDrive v2 - How to list the available products. - Start a purchase flow. - Record product consumption Steps to add Google Play Billing to an app Update your app's dependencies. Connect to Google Play. Query for in-app product details. Enable the purchase of an in-app product. Query for purchased items. Add one-time product-specific or subscription-specific code. Update your app dependencies dependencies { ... api 'com.android.billingclient:billing:1.2' } Connect to Google Play Connect to Google play using BillingClient. mBillingClient = BillingClient.newBuilder(mActivity).setListener(this).build(); mBillingClient.startConnection(new BillingClientStateListener() { @Override public void onBillingSetupFinished(@BillingResponse int billingResponseCode) { if (billingResponseCode == BillingResponse.OK) { // The billing client is ready. You can query purchases here. } } @Override public void onBillingServiceDisconnected() { // Try to restart the connection on the next request to // Google Play by calling the startConnection() method. } }); Query for in-app product details SkiType.INAPP for one-time products. SkiType.SUBS for subscription. Query products. List<String> skuList = new ArrayList<> (); skuList.add(\"premium_upgrade\"); skuList.add(\"gas\"); SkuDetailsParams.Builder params = SkuDetailsParams.newBuilder(); params.setSkusList(skuList).setType(SkuType.INAPP); mBillingClient.querySkuDetailsAsync(params.build(), new SkuDetailsResponseListener() { @Override public void onSkuDetailsResponse(int responseCode, List<SkuDetails> skuDetailsList) // Process the result. } }); non-consumable : A one-time product that can be used indefinitely is called a non-consumable. consumable : A one-time product with non-infinite use is called consumable. Show product details. for (SkuDetails skuDetails : skuDetailsList) { String sku = skuDetails.getSku(); String price = skuDetails.getPrice(); } Enable the purchase of an in-app product Start billing process BillingFlowParams flowParams = BillingFlowParams.newBuilder() .setSku(skuId) .setType(SkuType.INAPP) // SkuType.SUB for subscription .build(); int responseCode = mBillingClient.launchBillingFlow(flowParams); It will call onPurchasesUpdated to give us a result. @Override void onPurchasesUpdated(@BillingResponse int responseCode, List<Purchase> purchases) { if (responseCode == BillingResponse.OK && purchases != null) { for (Purchase purchase : purchases) { handlePurchase(purchase); } } else if (responseCode == BillingResponse.USER_CANCELED) { // Handle an error caused by a user cancelling the purchase flow. } else { // Handle any other error codes. } } Successful purchases also generate a purchase token, which is unique identifier representing the user and the product ID for in-app product they purchased. The purchase token for subscription stays the same for each billing period. Verify a purchase Verify a purchase on a server Ensure that the device-server handshake is secure. Verify order Id is a unique value that you have not previously processed. Verify that your app's key has signed the INAPP_PURCHASE_DATA that you process. sequenceDiagram Client ->>+ Google : purchase(appid, skuid) Google -->>- Client : purchaseToken, orderId Client ->>+ YourServer : verify(purchaseToken, orderId, account) YourServer ->>+ Google : Get purchase(appid, purchaseToken) Google -->>- YourServer : Purchase Detail YourServer -->>- Client : verifyed Best Practices Use a real-time service to deliver your content. User a remote server to deliver your content. Encrypt the content. Whenever a user accesses the content, you should verify the user entitlement. From Android Doc","title":"Google Play Billing Library"},{"location":"etc/android/googleplay/googleplay_billing_library/#google-play-billing-library","text":"","title":"Google Play Billing Library"},{"location":"etc/android/googleplay/googleplay_billing_library/#about-the-code-snippets","text":"TrivialDrive v2 - How to list the available products. - Start a purchase flow. - Record product consumption","title":"About the code snippets"},{"location":"etc/android/googleplay/googleplay_billing_library/#steps-to-add-google-play-billing-to-an-app","text":"Update your app's dependencies. Connect to Google Play. Query for in-app product details. Enable the purchase of an in-app product. Query for purchased items. Add one-time product-specific or subscription-specific code.","title":"Steps to add Google Play Billing to an app"},{"location":"etc/android/googleplay/googleplay_billing_library/#update-your-app-dependencies","text":"dependencies { ... api 'com.android.billingclient:billing:1.2' }","title":"Update your app dependencies"},{"location":"etc/android/googleplay/googleplay_billing_library/#connect-to-google-play","text":"Connect to Google play using BillingClient. mBillingClient = BillingClient.newBuilder(mActivity).setListener(this).build(); mBillingClient.startConnection(new BillingClientStateListener() { @Override public void onBillingSetupFinished(@BillingResponse int billingResponseCode) { if (billingResponseCode == BillingResponse.OK) { // The billing client is ready. You can query purchases here. } } @Override public void onBillingServiceDisconnected() { // Try to restart the connection on the next request to // Google Play by calling the startConnection() method. } });","title":"Connect to Google Play"},{"location":"etc/android/googleplay/googleplay_billing_library/#query-for-in-app-product-details","text":"SkiType.INAPP for one-time products. SkiType.SUBS for subscription. Query products. List<String> skuList = new ArrayList<> (); skuList.add(\"premium_upgrade\"); skuList.add(\"gas\"); SkuDetailsParams.Builder params = SkuDetailsParams.newBuilder(); params.setSkusList(skuList).setType(SkuType.INAPP); mBillingClient.querySkuDetailsAsync(params.build(), new SkuDetailsResponseListener() { @Override public void onSkuDetailsResponse(int responseCode, List<SkuDetails> skuDetailsList) // Process the result. } }); non-consumable : A one-time product that can be used indefinitely is called a non-consumable. consumable : A one-time product with non-infinite use is called consumable. Show product details. for (SkuDetails skuDetails : skuDetailsList) { String sku = skuDetails.getSku(); String price = skuDetails.getPrice(); }","title":"Query for in-app product details"},{"location":"etc/android/googleplay/googleplay_billing_library/#enable-the-purchase-of-an-in-app-product","text":"Start billing process BillingFlowParams flowParams = BillingFlowParams.newBuilder() .setSku(skuId) .setType(SkuType.INAPP) // SkuType.SUB for subscription .build(); int responseCode = mBillingClient.launchBillingFlow(flowParams); It will call onPurchasesUpdated to give us a result. @Override void onPurchasesUpdated(@BillingResponse int responseCode, List<Purchase> purchases) { if (responseCode == BillingResponse.OK && purchases != null) { for (Purchase purchase : purchases) { handlePurchase(purchase); } } else if (responseCode == BillingResponse.USER_CANCELED) { // Handle an error caused by a user cancelling the purchase flow. } else { // Handle any other error codes. } } Successful purchases also generate a purchase token, which is unique identifier representing the user and the product ID for in-app product they purchased. The purchase token for subscription stays the same for each billing period.","title":"Enable the purchase of an in-app product"},{"location":"etc/android/googleplay/googleplay_billing_library/#verify-a-purchase","text":"","title":"Verify a purchase"},{"location":"etc/android/googleplay/googleplay_billing_library/#verify-a-purchase-on-a-server","text":"Ensure that the device-server handshake is secure. Verify order Id is a unique value that you have not previously processed. Verify that your app's key has signed the INAPP_PURCHASE_DATA that you process. sequenceDiagram Client ->>+ Google : purchase(appid, skuid) Google -->>- Client : purchaseToken, orderId Client ->>+ YourServer : verify(purchaseToken, orderId, account) YourServer ->>+ Google : Get purchase(appid, purchaseToken) Google -->>- YourServer : Purchase Detail YourServer -->>- Client : verifyed","title":"Verify a purchase on a server"},{"location":"etc/android/googleplay/googleplay_billing_library/#best-practices","text":"Use a real-time service to deliver your content. User a remote server to deliver your content. Encrypt the content. Whenever a user accesses the content, you should verify the user entitlement.","title":"Best Practices"},{"location":"etc/android/googleplay/googleplay_billing_library/#from","text":"Android Doc","title":"From"},{"location":"etc/android/googleplay/overview/","text":"Overview Sequence flow of Google Play Google Play Store sequenceDiagram Client ->>+ Google : Connection Google -->>- Client : void Client ->>+ Google : querySkuDetails(params) Google -->>- Client : skuDetails Client ->>+ Google : purchase(appid, skuid) Google -->>- Client : purchaseToken, orderId Client ->>+ YourServer : verify(purchaseToken, orderId) YourServer ->>+ Google : Get purchase(appid, purchaseToken) Google -->>- YourServer : Purchase Detail YourServer -->>- Client : verified","title":"Overview"},{"location":"etc/android/googleplay/overview/#overview","text":"Sequence flow of Google Play","title":"Overview"},{"location":"etc/android/googleplay/overview/#google-play-store","text":"sequenceDiagram Client ->>+ Google : Connection Google -->>- Client : void Client ->>+ Google : querySkuDetails(params) Google -->>- Client : skuDetails Client ->>+ Google : purchase(appid, skuid) Google -->>- Client : purchaseToken, orderId Client ->>+ YourServer : verify(purchaseToken, orderId) YourServer ->>+ Google : Get purchase(appid, purchaseToken) Google -->>- YourServer : Purchase Detail YourServer -->>- Client : verified","title":"Google Play Store"},{"location":"etc/android/publish/1_publish_overview/","text":"Publish your app You prepare application for release. You release application to user. Preparing your app for release Configuring your application for release. Building and signing a release version of your application. Testing the release version of your application. Updating application resources for release. Preparing remote servers and services that your application depends on. Releasing your app to users Releasing through an app marketplace Releasing your app on Google Play Google Play is a publishing platform that helps you publicize, sell and distribute your app to users around the world. - Preparing promotional materials. - Configuring options and uploading assets. - Publishing the release version of your applications.","title":"Publish your app"},{"location":"etc/android/publish/1_publish_overview/#publish-your-app","text":"You prepare application for release. You release application to user.","title":"Publish your app"},{"location":"etc/android/publish/1_publish_overview/#preparing-your-app-for-release","text":"Configuring your application for release. Building and signing a release version of your application. Testing the release version of your application. Updating application resources for release. Preparing remote servers and services that your application depends on.","title":"Preparing your app for release"},{"location":"etc/android/publish/1_publish_overview/#releasing-your-app-to-users","text":"","title":"Releasing your app to users"},{"location":"etc/android/publish/1_publish_overview/#releasing-through-an-app-marketplace","text":"","title":"Releasing through an app marketplace"},{"location":"etc/android/publish/1_publish_overview/#releasing-your-app-on-google-play","text":"Google Play is a publishing platform that helps you publicize, sell and distribute your app to users around the world. - Preparing promotional materials. - Configuring options and uploading assets. - Publishing the release version of your applications.","title":"Releasing your app on Google Play"},{"location":"etc/android/publish/2_prepare_for_release/","text":"Prepare for release Introduction Release-ready APK file is signed with your own certificate and it is optimized with the zipalign tool. Gathering materials and resources Cryptographic keys The Android system requires that each installed application be digitally signed with a certificate that is owned by the application's developer (this is, a certificate for which the developer holds the private key). The Android system uses the certificate as a means of identifying the author of an application and establishing trust relationships between applications Application icon End User License Agreement (EULA) Miscellaneous materials Configuring Your Application for release Choose a good package name Turn off logging and debugging Clean up your project directories Review and update your manifest and Gradle build settings Address compatibility issues Update URLs for servers and services Implement licensing (if you are releasing on Google Play) Building Your application for release Preparing external servers and resources Testing your application for release","title":"Prepare for release"},{"location":"etc/android/publish/2_prepare_for_release/#prepare-for-release","text":"","title":"Prepare for release"},{"location":"etc/android/publish/2_prepare_for_release/#introduction","text":"Release-ready APK file is signed with your own certificate and it is optimized with the zipalign tool.","title":"Introduction"},{"location":"etc/android/publish/2_prepare_for_release/#gathering-materials-and-resources","text":"","title":"Gathering materials and resources"},{"location":"etc/android/publish/2_prepare_for_release/#cryptographic-keys","text":"The Android system requires that each installed application be digitally signed with a certificate that is owned by the application's developer (this is, a certificate for which the developer holds the private key). The Android system uses the certificate as a means of identifying the author of an application and establishing trust relationships between applications","title":"Cryptographic keys"},{"location":"etc/android/publish/2_prepare_for_release/#application-icon","text":"","title":"Application icon"},{"location":"etc/android/publish/2_prepare_for_release/#end-user-license-agreement-eula","text":"","title":"End User License Agreement (EULA)"},{"location":"etc/android/publish/2_prepare_for_release/#miscellaneous-materials","text":"","title":"Miscellaneous materials"},{"location":"etc/android/publish/2_prepare_for_release/#configuring-your-application-for-release","text":"Choose a good package name Turn off logging and debugging Clean up your project directories Review and update your manifest and Gradle build settings Address compatibility issues Update URLs for servers and services Implement licensing (if you are releasing on Google Play)","title":"Configuring Your Application for release"},{"location":"etc/android/publish/2_prepare_for_release/#building-your-application-for-release","text":"","title":"Building Your application for release"},{"location":"etc/android/publish/2_prepare_for_release/#preparing-external-servers-and-resources","text":"","title":"Preparing external servers and resources"},{"location":"etc/android/publish/2_prepare_for_release/#testing-your-application-for-release","text":"","title":"Testing your application for release"},{"location":"etc/android/publish/3_version/","text":"Version your app Set application version information versionCode - A positive integer used as an internal version number. versionName - A string used as the version number shown to users. android { defaultConfig { ... versionCode 2 versionName \"1.1\" } productFlavors { demo { ... versionName \"1.1-demo\" } full { ... } } } Specify API level requirements minSdkVersion - The minimum version of the Android platform on which the app will run. targetSdkVersion - Specifies the API level on which the app is designed to run. andorid { defaultConfig { ... minSdkVersion 14 targetSdkVerison 24 } productFlavers { main { ... } afterLollipop { ... minSdkVersion 21 } } }","title":"Version your app"},{"location":"etc/android/publish/3_version/#version-your-app","text":"","title":"Version your app"},{"location":"etc/android/publish/3_version/#set-application-version-information","text":"versionCode - A positive integer used as an internal version number. versionName - A string used as the version number shown to users. android { defaultConfig { ... versionCode 2 versionName \"1.1\" } productFlavors { demo { ... versionName \"1.1-demo\" } full { ... } } }","title":"Set application version information"},{"location":"etc/android/publish/3_version/#specify-api-level-requirements","text":"minSdkVersion - The minimum version of the Android platform on which the app will run. targetSdkVersion - Specifies the API level on which the app is designed to run. andorid { defaultConfig { ... minSdkVersion 14 targetSdkVerison 24 } productFlavers { main { ... } afterLollipop { ... minSdkVersion 21 } } }","title":"Specify API level requirements"},{"location":"etc/android/publish/4_sign/","text":"Sign your app Certificates and keystores To help Android ensure that any future updates to your app are authentic and come from the original author. It needs a tool for identifying author. Android use public/private key pairs. A public-key certificate, also known as a digital certificate or an identity certificate is a public key. The public-key certificate serve as a \"fingerprint\" that uniquely associates the APK or app bundle to you and your corresponding private key. A keystore is a binary file that contains one or more private keys. Sign your debug build Android Studio automatically signs your app with a debug certificate generated by the Android SDK tools in $HOME/.android/debug.keystore . Expire of the debug certificate. When the certificate expires, you will get a build error. To fix this problem, simply delete the debug.keystore Manage your key Manage your own key and keystore. Use App Signing by Google Play. Manage your own key and keystore You are responsible for securing the key and the keystore. - A key(App signing key) is a private key. - A keystore is a binary file contains keys. If you loose access to your key or key is compromised, Google cannot retrieve the app singing key for your Use App Signing by Google Play (recommended) You export and encrypt your app signing key using the tool provided by Google Play, and then upload it to Google. Then you create a separate upload key and register it with Google. When you are ready to publish, you sign your app using the upload key and upload it Google Play. Google Play verify your identity and sing your APK(s) with your app signing key for distribution. When you lose your upload key, you can revoke your old upload key and generate a new one. Generate a key and keystore. You can generate one using Android Studio 0. Build > Build > Generate Signed Bundle/APK Configure gradle.build android { signingConfigs { release { storeFile project.KEYSTORE_STORE_FILE storePassword project.KEYSTORE_STORE_PASSWORD keyAlias project.KEYSTORE_KEY_ALIAS keyPassword project.KEYSTORE_KEY_PASSWORD } } buildTypes { release { ... signingConfig signingConfigs.release } } Sign your app from command line keytool -genkey -v -keystore my-release-key.jks -keyalg RSA -keysize 2048 -validity 10000 -alias my-alia Sign your app from command line","title":"Sign your app"},{"location":"etc/android/publish/4_sign/#sign-your-app","text":"","title":"Sign your app"},{"location":"etc/android/publish/4_sign/#certificates-and-keystores","text":"To help Android ensure that any future updates to your app are authentic and come from the original author. It needs a tool for identifying author. Android use public/private key pairs. A public-key certificate, also known as a digital certificate or an identity certificate is a public key. The public-key certificate serve as a \"fingerprint\" that uniquely associates the APK or app bundle to you and your corresponding private key. A keystore is a binary file that contains one or more private keys.","title":"Certificates and keystores"},{"location":"etc/android/publish/4_sign/#sign-your-debug-build","text":"Android Studio automatically signs your app with a debug certificate generated by the Android SDK tools in $HOME/.android/debug.keystore .","title":"Sign your debug build"},{"location":"etc/android/publish/4_sign/#expire-of-the-debug-certificate","text":"When the certificate expires, you will get a build error. To fix this problem, simply delete the debug.keystore","title":"Expire of the debug certificate."},{"location":"etc/android/publish/4_sign/#manage-your-key","text":"Manage your own key and keystore. Use App Signing by Google Play.","title":"Manage your key"},{"location":"etc/android/publish/4_sign/#manage-your-own-key-and-keystore","text":"You are responsible for securing the key and the keystore. - A key(App signing key) is a private key. - A keystore is a binary file contains keys. If you loose access to your key or key is compromised, Google cannot retrieve the app singing key for your","title":"Manage your own key and keystore"},{"location":"etc/android/publish/4_sign/#use-app-signing-by-google-play-recommended","text":"You export and encrypt your app signing key using the tool provided by Google Play, and then upload it to Google. Then you create a separate upload key and register it with Google. When you are ready to publish, you sign your app using the upload key and upload it Google Play. Google Play verify your identity and sing your APK(s) with your app signing key for distribution. When you lose your upload key, you can revoke your old upload key and generate a new one.","title":"Use App Signing by Google Play (recommended)"},{"location":"etc/android/publish/4_sign/#generate-a-key-and-keystore","text":"You can generate one using Android Studio 0. Build > Build > Generate Signed Bundle/APK","title":"Generate a key and keystore."},{"location":"etc/android/publish/4_sign/#configure-gradlebuild","text":"android { signingConfigs { release { storeFile project.KEYSTORE_STORE_FILE storePassword project.KEYSTORE_STORE_PASSWORD keyAlias project.KEYSTORE_KEY_ALIAS keyPassword project.KEYSTORE_KEY_PASSWORD } } buildTypes { release { ... signingConfig signingConfigs.release } }","title":"Configure gradle.build"},{"location":"etc/android/publish/4_sign/#sign-your-app-from-command-line","text":"keytool -genkey -v -keystore my-release-key.jks -keyalg RSA -keysize 2048 -validity 10000 -alias my-alia","title":"Sign your app from command line"},{"location":"etc/android/publish/4_sign/#sign-your-app-from-command-line_1","text":"","title":"Sign your app from command line"},{"location":"etc/books/2018_12_lovethatdog/","text":"Love that dog Feel It was easy and fun. I realized I can cry while reading a book wrote by English. This was my first novel which wrote in English.","title":"Love that dog"},{"location":"etc/books/2018_12_lovethatdog/#love-that-dog","text":"","title":"Love that dog"},{"location":"etc/books/2018_12_lovethatdog/#feel","text":"It was easy and fun. I realized I can cry while reading a book wrote by English. This was my first novel which wrote in English.","title":"Feel"},{"location":"etc/idea/launcher/","text":"Luncher App Goal \uc54c\ud504\ub808\ub4dc\uc640 \uac19\uc740 \uc548\ub4dc\ub85c\uc774\ub4dc \ub7f0\ucc98\ub97c \ub9cc\ub4e4\uc790. Why? \uc548\ub4dc\ub85c\uc774\ub4dc\uc5d0\uc11c \uc571\uc744 \ucc3e\uc744 \ub54c \uadc0\ucc2e\ub2e4. Functions \ucd08\uc131 \uac80\uc0c9\uc774 \ub41c\ub2e4. \ub7f0\uccd0\ub97c \ub9cc\ub4e4\uace0 \ub0a0\uc790, wifi, \uc704\uce58 \ub4f1\uc744 \uc0ac\uc6a9\ud574 \uc790\uc8fc \uc0ac\uc6a9\ud558\ub294 \uc571\uc744 \ubcf4\uc5ec\uc900\ub2e4. \uba38\uc2e0\ub7ec\ub2dd\uc744 \uc0ac\uc6a9\ud574 \ub7f0\ucc98\uc5d0 \ub178\ucd9c\ub418\ub294 \uac83\ub4e4\uc744 \ud559\uc2b5\uc2dc\ud0a8\ub2e4. Formula \\( P(\\text{Prioriry} | \\text{date, wifi, lat, lng}) \\)","title":"Luncher App"},{"location":"etc/idea/launcher/#luncher-app","text":"","title":"Luncher App"},{"location":"etc/idea/launcher/#goal","text":"\uc54c\ud504\ub808\ub4dc\uc640 \uac19\uc740 \uc548\ub4dc\ub85c\uc774\ub4dc \ub7f0\ucc98\ub97c \ub9cc\ub4e4\uc790.","title":"Goal"},{"location":"etc/idea/launcher/#why","text":"\uc548\ub4dc\ub85c\uc774\ub4dc\uc5d0\uc11c \uc571\uc744 \ucc3e\uc744 \ub54c \uadc0\ucc2e\ub2e4.","title":"Why?"},{"location":"etc/idea/launcher/#functions","text":"\ucd08\uc131 \uac80\uc0c9\uc774 \ub41c\ub2e4. \ub7f0\uccd0\ub97c \ub9cc\ub4e4\uace0 \ub0a0\uc790, wifi, \uc704\uce58 \ub4f1\uc744 \uc0ac\uc6a9\ud574 \uc790\uc8fc \uc0ac\uc6a9\ud558\ub294 \uc571\uc744 \ubcf4\uc5ec\uc900\ub2e4. \uba38\uc2e0\ub7ec\ub2dd\uc744 \uc0ac\uc6a9\ud574 \ub7f0\ucc98\uc5d0 \ub178\ucd9c\ub418\ub294 \uac83\ub4e4\uc744 \ud559\uc2b5\uc2dc\ud0a8\ub2e4.","title":"Functions"},{"location":"etc/idea/launcher/#formula","text":"\\( P(\\text{Prioriry} | \\text{date, wifi, lat, lng}) \\)","title":"Formula"},{"location":"etc/idea/memo/","text":"Memo App Goal \uc5b4\ub518\uac00 \ub098\uac08\ub54c \uaf2d \uccb4\ud06c\ud574\uc57c \ud558\ub294 \ud56d\ubaa9\ub4e4\uc5d0 \ub300\ud55c \uc571 \uce7c\ub79c\ub354\uc640 \uacb0\ud569\ud574 \ub450\uba74 \uc88b\uc744\ub4ef Why? \uc544\uc774\ub97c \ub300\ub9ac\uace0 \uc678\ucd9c \ud560 \ub54c \ud544\uc218 \uc900\ube44\ubb3c\uc744 \ub204\ub77d \ud558\ub294 \uacbd\uc6b0\uac00 \uc788\ub2e4. \uac01 \uc77c \uc2dc \ub9c8\ub2e4 \ud2b9\uc815 \ub178\ud2b8\ub97c \ubcf4\uc5ec\uc8fc\uace0 \ub9ac\ub9c8\uc778\ub4dc \ud574\uc8fc\ub294 \uc571","title":"Memo App"},{"location":"etc/idea/memo/#memo-app","text":"","title":"Memo App"},{"location":"etc/idea/memo/#goal","text":"\uc5b4\ub518\uac00 \ub098\uac08\ub54c \uaf2d \uccb4\ud06c\ud574\uc57c \ud558\ub294 \ud56d\ubaa9\ub4e4\uc5d0 \ub300\ud55c \uc571 \uce7c\ub79c\ub354\uc640 \uacb0\ud569\ud574 \ub450\uba74 \uc88b\uc744\ub4ef","title":"Goal"},{"location":"etc/idea/memo/#why","text":"\uc544\uc774\ub97c \ub300\ub9ac\uace0 \uc678\ucd9c \ud560 \ub54c \ud544\uc218 \uc900\ube44\ubb3c\uc744 \ub204\ub77d \ud558\ub294 \uacbd\uc6b0\uac00 \uc788\ub2e4. \uac01 \uc77c \uc2dc \ub9c8\ub2e4 \ud2b9\uc815 \ub178\ud2b8\ub97c \ubcf4\uc5ec\uc8fc\uace0 \ub9ac\ub9c8\uc778\ub4dc \ud574\uc8fc\ub294 \uc571","title":"Why?"},{"location":"etc/language/cpp/new_cpp/","text":"New c++11 standard New type c++11 adds long long unsingned long long char16_t char32_t Uniform initialization c++11 extends the applicability of the brace-enclosed list (list initialization) int x = {5}; double y {2.7}; short quar[2] = {1,2} int * ar = new int [2] {1,2}; class Test { private: int aa; int bb; public: Test(int a, int b): aa(a), bb(b) {} } Test t1(1,2); Test t2{1,2}; test t3 = {1,2}; std::initializer_list Can be used as a constructor argument. vector<int> a1(10); // uninitialized vector with 10 elements vector<int> a2{10}; // initializer-ist a2 has 1 elements set to 10 vecotr<int> a3{1,2,3}; // 3 elements set to 1,2,3 You can use an initializer_list argument for regular function as well as for constructor #include <initializer_list> double sum(std::initializer_list<double> li); int main() { double total = sum({1,2,3}) } double sum(std::initializer_list<double> ii) { double tot = 0; for (auto p = il.begin(); p != il.end(); p++) tot += *p; return tot; } Declarations auto c++11 strips the keyword auto of its former meaning as a storage class specifier and puts it to use to implement automatic type deduction, provided that an explicit initializer is given. auto a = 1; // a is type int auto pta = &a; // pta is type int * double b(double, int); ... for(auto p = il.begin(); p != il.end(); p++); decltype Create a variable of the type indicated by an expression. // decltype(x) y; double x; int n; decltype(x*n) q; // q same type as x*n, double decltype(&x) pd; // pd same as &x, double * //useful in template defininitions template<typename T, typename U> void ef(T t, U u) { decltype(T*U) tu; } Trailing Return type To use combination with decltype double f1(double int); auto f2(double, int) -> double; template<typename T, typename U> auto ef(T t, U u): decltype(T*U) { decltype(T*U) tu; } Template Aliases: using = typedef double newDouble; using newDouble = double; template<typename T> using newDoubleArr = std::arrary<T, 12> nullptr The null pointer is a pointer guaranteed not to point to valid data. It's same as pt = 0; Smart Pointers unique_ptr shared_ptr weak_ptr Scoped Enumerations You can use New1::yes and New2::yes. enum Old {yes, no}; enum class New1 {yes, no}; enum struct New2 {yes, no}; Class Changes explicit Conversion Operators Introduce the keyword explicit to suppress automatic conversions invoked by one-argument constructor: class Test { Test(int); explicit Test(double); } Test a, b; a = 5; // implicit converstion, call Test(int) b = 0.5 // not allowed b = Test(0.5) // explicit conversion conversion functions can be treated similarly: class Test { operator int() const; explicit operator double() const; } ... Test a, b; int n = a; // int-to-Test automatic conversion; double x= b // not allowrd x = double(b) // explicit convesrion, allowd Member In-Class Initialization class Test { int aval = 1; int bval = 2; int cval = 3; public: Test() {} Test(int c): cval(c) {} Test(int a, int b, int c): aval(a), bval(b), cval(c) {} } Template and STL Changes Range-based for Loop Use range-based for loop, such as the STL containers, that have begin() and end() methods identifying range. double prices[3] = {1, 2, 3} for (auto x: prices) cout << x << endl; // Modify elements for (auto & x: prices) x = x + 1; New STL Containtes forward_list : single linked list. unorderd_map, set, multimap, multset. arrary: Can't change the size but it have the begin() and end. std::arrary<int, 3> ar; New STL Methods AngleBrackets std::vector<std::list<int> > // >> not ok befor c++11 std::vector<std::list<int>> // ok in c++11 The rvalue reference lvalue is an expression, such as a variable name or dereferenced pointer, that represents data for which the program can obtain an address. Originally lvalue was one that could appear on the left side of assignment expression, but the advent of the const modifier allowed for constructs that cannot be assigned but which still addressable; lvalue reference is an identifier that can binds an lvalue. int n; // lvalue int * pt = new int; // lvalue const int b = 101; // lvalue int & rn = n; // lvalue reference int & rt = *pt; // lvalue reference cont int & rb = b; // lvalue reference rvalue is an values that can appear on the left side of assignment expression but for which cannot apply the address operator. literal constants, expression such as x+y and function return values, providing the function dose not a reference rvalue reference is identifier that can binds an rvalue; int x = 10 // rvalue int y = 20 // rvalue int && r1 = 13; // rvalue reference int && r2 = x + y; // rvalue reference. bind the value to which x + y evaluates at that time. double && r3 = std::sqrt(2.0); // revalue reference Reference declaration Declares a named variable a s a reference, that is, an alias to already-existing object or function. - & (attr) declarator: Lvalue reference declarator: the declaration S& D; declares D as an lvalue reference to the type determined by decl-specifier-seq S - && (attr) declarator: Rvalue reference declarator: the declaration S&& D: declares D as an rvalue reference to the type determined by decl-specifier-seq S. Move Semantics and the Rvalue Reference The Need for Move Semantics Let the compiler know the it needs to do a real copy and when it doesn't. Compiler modifies code to remove redundant job. Move Semantic vector<string> upper(vecter<string>& vs) { vector<string> temp; //code the store all upper case to temp return temp; } vector<string> vstr(100); vector<string> vstr_copy1(vstr); // #1 vector<string> vstr_copy2(upper(vstr)); // #2 #1 To make copy of vstr, vstr copy constructor will called. #2 create temp object which is upper case version of vstr. vstr_copy2 call copy constructor of temp object. delete temp object. Step 2 is redundant in this case. It's better the compiler transfer ownership of the data to vstr_copy2. Example When you move a file from one directory to another: The actual file stays where is is on the hard drive, and just the booking is altered. Somewhat paradoxically move semantic avoids moving the primary data;it just adjusts booking To implement move semantic, we need a way to let the compiler know the it needs to do a real copy and when it doesn't. Here's where the rvalue reference comes into play. We can define two constructor. One the regular copy constructor. The other, called move constructor, can use an rvalue reference, and it can bind to rvalue arguments, such as return value of upper(vsrt).. The copy constructor do the usually deep copy, while the move constructor can just adjust booking. A move constructor may alter its argument, and this implies that an rvalue reference parameter should not be const. Useless::Useless(Useless&& u): num(u.num) //move constructor { ++ct; pt = u.pt; // steal address u.pt = nullptr; // give old object nothing in return u.num = 0; showObj(); cout << \"move construtor(Useless&& u)\" << endl; } Move constructor make new object based on rvalue reference. Must pilfering original memory assigned by new, because it'll be called twice if it is not done. code Move Constructor Observation Useless two = one // matches Useless::Useless(const Useless &) = copy constructor Useless four (one + three) // matched Useless::Useless(const Useless &&) = move constructor Before Move constructor Useless four (one + three) // matched Useless::Useless(const Useless &&) = move constructor Operator+() makes temp1 object. Expression (temp1) calls copy constructor. According to spec, create new temp2 object, because it is a rvalue not a lvalue. Copy temp2 to crate four. delete temp1, temp2 Assignment Useless & Uesless::operator+(const Useless & f) { if (this == f) return *this; delete[] pc; n = f.n; pc = new char[n]; for (int i = 0; i < n; i++) pc[i] = f.pc[i] return *this; } Useless & Useless::operation=(Useless && f) //not a const! because method alter the source object. { if (this == f) return *this; delete[] pc; n = f.n; pc = f.pc; // pilfers the source object f.n = 0; f.pc = nullptr; // only one pointer to point to the data return *this; } Forcing a Move You can use std::move() function, If you want to use move constructor and move assignment with lvalue std::move is same as using the staitc_cast<> operator to case the object to type Type &&. From C++ Primer Plus (6th Edition)","title":"New c++11 standard"},{"location":"etc/language/cpp/new_cpp/#new-c11-standard","text":"","title":"New c++11 standard"},{"location":"etc/language/cpp/new_cpp/#new-type","text":"c++11 adds long long unsingned long long char16_t char32_t","title":"New type"},{"location":"etc/language/cpp/new_cpp/#uniform-initialization","text":"c++11 extends the applicability of the brace-enclosed list (list initialization) int x = {5}; double y {2.7}; short quar[2] = {1,2} int * ar = new int [2] {1,2}; class Test { private: int aa; int bb; public: Test(int a, int b): aa(a), bb(b) {} } Test t1(1,2); Test t2{1,2}; test t3 = {1,2};","title":"Uniform initialization"},{"location":"etc/language/cpp/new_cpp/#stdinitializer_list","text":"Can be used as a constructor argument. vector<int> a1(10); // uninitialized vector with 10 elements vector<int> a2{10}; // initializer-ist a2 has 1 elements set to 10 vecotr<int> a3{1,2,3}; // 3 elements set to 1,2,3 You can use an initializer_list argument for regular function as well as for constructor #include <initializer_list> double sum(std::initializer_list<double> li); int main() { double total = sum({1,2,3}) } double sum(std::initializer_list<double> ii) { double tot = 0; for (auto p = il.begin(); p != il.end(); p++) tot += *p; return tot; }","title":"std::initializer_list"},{"location":"etc/language/cpp/new_cpp/#declarations","text":"","title":"Declarations"},{"location":"etc/language/cpp/new_cpp/#auto","text":"c++11 strips the keyword auto of its former meaning as a storage class specifier and puts it to use to implement automatic type deduction, provided that an explicit initializer is given. auto a = 1; // a is type int auto pta = &a; // pta is type int * double b(double, int); ... for(auto p = il.begin(); p != il.end(); p++);","title":"auto"},{"location":"etc/language/cpp/new_cpp/#decltype","text":"Create a variable of the type indicated by an expression. // decltype(x) y; double x; int n; decltype(x*n) q; // q same type as x*n, double decltype(&x) pd; // pd same as &x, double * //useful in template defininitions template<typename T, typename U> void ef(T t, U u) { decltype(T*U) tu; }","title":"decltype"},{"location":"etc/language/cpp/new_cpp/#trailing-return-type","text":"To use combination with decltype double f1(double int); auto f2(double, int) -> double; template<typename T, typename U> auto ef(T t, U u): decltype(T*U) { decltype(T*U) tu; }","title":"Trailing Return type"},{"location":"etc/language/cpp/new_cpp/#template-aliases-using","text":"typedef double newDouble; using newDouble = double; template<typename T> using newDoubleArr = std::arrary<T, 12>","title":"Template Aliases: using ="},{"location":"etc/language/cpp/new_cpp/#nullptr","text":"The null pointer is a pointer guaranteed not to point to valid data. It's same as pt = 0;","title":"nullptr"},{"location":"etc/language/cpp/new_cpp/#smart-pointers","text":"unique_ptr shared_ptr weak_ptr","title":"Smart Pointers"},{"location":"etc/language/cpp/new_cpp/#scoped-enumerations","text":"You can use New1::yes and New2::yes. enum Old {yes, no}; enum class New1 {yes, no}; enum struct New2 {yes, no};","title":"Scoped Enumerations"},{"location":"etc/language/cpp/new_cpp/#class-changes","text":"","title":"Class Changes"},{"location":"etc/language/cpp/new_cpp/#explicit-conversion-operators","text":"Introduce the keyword explicit to suppress automatic conversions invoked by one-argument constructor: class Test { Test(int); explicit Test(double); } Test a, b; a = 5; // implicit converstion, call Test(int) b = 0.5 // not allowed b = Test(0.5) // explicit conversion conversion functions can be treated similarly: class Test { operator int() const; explicit operator double() const; } ... Test a, b; int n = a; // int-to-Test automatic conversion; double x= b // not allowrd x = double(b) // explicit convesrion, allowd","title":"explicit Conversion Operators"},{"location":"etc/language/cpp/new_cpp/#member-in-class-initialization","text":"class Test { int aval = 1; int bval = 2; int cval = 3; public: Test() {} Test(int c): cval(c) {} Test(int a, int b, int c): aval(a), bval(b), cval(c) {} }","title":"Member In-Class Initialization"},{"location":"etc/language/cpp/new_cpp/#template-and-stl-changes","text":"","title":"Template and STL Changes"},{"location":"etc/language/cpp/new_cpp/#range-based-for-loop","text":"Use range-based for loop, such as the STL containers, that have begin() and end() methods identifying range. double prices[3] = {1, 2, 3} for (auto x: prices) cout << x << endl; // Modify elements for (auto & x: prices) x = x + 1;","title":"Range-based for Loop"},{"location":"etc/language/cpp/new_cpp/#new-stl-containtes","text":"forward_list : single linked list. unorderd_map, set, multimap, multset. arrary: Can't change the size but it have the begin() and end. std::arrary<int, 3> ar;","title":"New STL Containtes"},{"location":"etc/language/cpp/new_cpp/#new-stl-methods","text":"","title":"New STL Methods"},{"location":"etc/language/cpp/new_cpp/#anglebrackets","text":"std::vector<std::list<int> > // >> not ok befor c++11 std::vector<std::list<int>> // ok in c++11","title":"AngleBrackets"},{"location":"etc/language/cpp/new_cpp/#the-rvalue-reference","text":"","title":"The rvalue reference"},{"location":"etc/language/cpp/new_cpp/#lvalue","text":"is an expression, such as a variable name or dereferenced pointer, that represents data for which the program can obtain an address. Originally lvalue was one that could appear on the left side of assignment expression, but the advent of the const modifier allowed for constructs that cannot be assigned but which still addressable;","title":"lvalue"},{"location":"etc/language/cpp/new_cpp/#lvalue-reference","text":"is an identifier that can binds an lvalue. int n; // lvalue int * pt = new int; // lvalue const int b = 101; // lvalue int & rn = n; // lvalue reference int & rt = *pt; // lvalue reference cont int & rb = b; // lvalue reference","title":"lvalue reference"},{"location":"etc/language/cpp/new_cpp/#rvalue","text":"is an values that can appear on the left side of assignment expression but for which cannot apply the address operator. literal constants, expression such as x+y and function return values, providing the function dose not a reference","title":"rvalue"},{"location":"etc/language/cpp/new_cpp/#rvalue-reference","text":"is identifier that can binds an rvalue; int x = 10 // rvalue int y = 20 // rvalue int && r1 = 13; // rvalue reference int && r2 = x + y; // rvalue reference. bind the value to which x + y evaluates at that time. double && r3 = std::sqrt(2.0); // revalue reference","title":"rvalue reference"},{"location":"etc/language/cpp/new_cpp/#reference-declaration","text":"Declares a named variable a s a reference, that is, an alias to already-existing object or function. - & (attr) declarator: Lvalue reference declarator: the declaration S& D; declares D as an lvalue reference to the type determined by decl-specifier-seq S - && (attr) declarator: Rvalue reference declarator: the declaration S&& D: declares D as an rvalue reference to the type determined by decl-specifier-seq S.","title":"Reference declaration"},{"location":"etc/language/cpp/new_cpp/#move-semantics-and-the-rvalue-reference","text":"","title":"Move Semantics and the Rvalue Reference"},{"location":"etc/language/cpp/new_cpp/#the-need-for-move-semantics","text":"Let the compiler know the it needs to do a real copy and when it doesn't. Compiler modifies code to remove redundant job.","title":"The Need for Move Semantics"},{"location":"etc/language/cpp/new_cpp/#move-semantic","text":"vector<string> upper(vecter<string>& vs) { vector<string> temp; //code the store all upper case to temp return temp; } vector<string> vstr(100); vector<string> vstr_copy1(vstr); // #1 vector<string> vstr_copy2(upper(vstr)); // #2","title":"Move Semantic"},{"location":"etc/language/cpp/new_cpp/#1","text":"To make copy of vstr, vstr copy constructor will called.","title":"#1"},{"location":"etc/language/cpp/new_cpp/#2","text":"create temp object which is upper case version of vstr. vstr_copy2 call copy constructor of temp object. delete temp object. Step 2 is redundant in this case. It's better the compiler transfer ownership of the data to vstr_copy2.","title":"#2"},{"location":"etc/language/cpp/new_cpp/#example","text":"When you move a file from one directory to another: The actual file stays where is is on the hard drive, and just the booking is altered. Somewhat paradoxically move semantic avoids moving the primary data;it just adjusts booking To implement move semantic, we need a way to let the compiler know the it needs to do a real copy and when it doesn't. Here's where the rvalue reference comes into play. We can define two constructor. One the regular copy constructor. The other, called move constructor, can use an rvalue reference, and it can bind to rvalue arguments, such as return value of upper(vsrt).. The copy constructor do the usually deep copy, while the move constructor can just adjust booking. A move constructor may alter its argument, and this implies that an rvalue reference parameter should not be const. Useless::Useless(Useless&& u): num(u.num) //move constructor { ++ct; pt = u.pt; // steal address u.pt = nullptr; // give old object nothing in return u.num = 0; showObj(); cout << \"move construtor(Useless&& u)\" << endl; } Move constructor make new object based on rvalue reference. Must pilfering original memory assigned by new, because it'll be called twice if it is not done. code","title":"Example"},{"location":"etc/language/cpp/new_cpp/#move-constructor-observation","text":"Useless two = one // matches Useless::Useless(const Useless &) = copy constructor Useless four (one + three) // matched Useless::Useless(const Useless &&) = move constructor","title":"Move Constructor Observation"},{"location":"etc/language/cpp/new_cpp/#before-move-constructor","text":"Useless four (one + three) // matched Useless::Useless(const Useless &&) = move constructor Operator+() makes temp1 object. Expression (temp1) calls copy constructor. According to spec, create new temp2 object, because it is a rvalue not a lvalue. Copy temp2 to crate four. delete temp1, temp2","title":"Before Move constructor"},{"location":"etc/language/cpp/new_cpp/#assignment","text":"Useless & Uesless::operator+(const Useless & f) { if (this == f) return *this; delete[] pc; n = f.n; pc = new char[n]; for (int i = 0; i < n; i++) pc[i] = f.pc[i] return *this; } Useless & Useless::operation=(Useless && f) //not a const! because method alter the source object. { if (this == f) return *this; delete[] pc; n = f.n; pc = f.pc; // pilfers the source object f.n = 0; f.pc = nullptr; // only one pointer to point to the data return *this; }","title":"Assignment"},{"location":"etc/language/cpp/new_cpp/#forcing-a-move","text":"You can use std::move() function, If you want to use move constructor and move assignment with lvalue std::move is same as using the staitc_cast<> operator to case the object to type Type &&.","title":"Forcing a Move"},{"location":"etc/language/cpp/new_cpp/#from","text":"C++ Primer Plus (6th Edition)","title":"From"},{"location":"etc/mkdocs/usage/","text":"HowTo Add javascrtip Mathjax.js Enable Mathjax.js add below configuration at mkdocs extra_javascript: - https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML Change math syntax from \\\\( ... \\\\) to \\$ ... \\$ window.MathJax = { tex2jax: { inlineMath: [[\"$\",\"$\"]], displayMath: [[\"$$\", \"$$\"]] }, TeX: { TagSide: \"right\", TagIndent: \".8em\", MultLineWidth: \"85%\", unicode: { fonts: \"STIXGeneral,'Arial Unicode MS'\" } }, CommonHTML: { scale: 90 }, showProcessingMessages: false, messageStyle: \"none\" }; Deploy cd home mkdocs build cd site git add . git commit -m git push open https://resoliwan.github.io","title":"HowTo"},{"location":"etc/mkdocs/usage/#howto","text":"","title":"HowTo"},{"location":"etc/mkdocs/usage/#add-javascrtip","text":"","title":"Add javascrtip"},{"location":"etc/mkdocs/usage/#mathjaxjs","text":"","title":"Mathjax.js"},{"location":"etc/mkdocs/usage/#enable-mathjaxjs","text":"add below configuration at mkdocs extra_javascript: - https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML","title":"Enable Mathjax.js"},{"location":"etc/mkdocs/usage/#change-math-syntax-from-9292-9292-to","text":"window.MathJax = { tex2jax: { inlineMath: [[\"$\",\"$\"]], displayMath: [[\"$$\", \"$$\"]] }, TeX: { TagSide: \"right\", TagIndent: \".8em\", MultLineWidth: \"85%\", unicode: { fonts: \"STIXGeneral,'Arial Unicode MS'\" } }, CommonHTML: { scale: 90 }, showProcessingMessages: false, messageStyle: \"none\" };","title":"Change math syntax from \\\\( ... \\\\) to \\$ ... \\$"},{"location":"etc/mkdocs/usage/#deploy","text":"cd home mkdocs build cd site git add . git commit -m git push open https://resoliwan.github.io","title":"Deploy"},{"location":"etc/ml/MNIST/","text":"MNIST Goal Predict category of images. Data X: digit image of 28 * 28 pixels. 1-d 784 pixel vector. y: the value of image (0~9) label,pixel0,...,pixel783 1 , 0,...,0 Plan Load data make X to (784, m) make y to (10, m) using one hot encoder. run session and check feed Create model define forward model. define optimize model. define loss function. Train data. optimize loss function. Measure performance Model Linear regression Forward Model $f(x) = W \\cdot X + b$ - X: (784, m), W (1, 784), b (1, 1) Loss $ H_{q}(p) = \\sum_{x} q(x) *\\log_{2} \\frac{1}{\\log p(x)} $ - Cross-Entroy: Average length of message from q(x) using code for p(x) Cost $ cost(\\theta) = \\sum_{i=0}^{M}loss(x^{(i)})$ Resource Information theory stanford-tensorflow-tutorials","title":"MNIST"},{"location":"etc/ml/MNIST/#mnist","text":"","title":"MNIST"},{"location":"etc/ml/MNIST/#goal","text":"Predict category of images.","title":"Goal"},{"location":"etc/ml/MNIST/#data","text":"X: digit image of 28 * 28 pixels. 1-d 784 pixel vector. y: the value of image (0~9) label,pixel0,...,pixel783 1 , 0,...,0","title":"Data"},{"location":"etc/ml/MNIST/#plan","text":"Load data make X to (784, m) make y to (10, m) using one hot encoder. run session and check feed Create model define forward model. define optimize model. define loss function. Train data. optimize loss function. Measure performance","title":"Plan"},{"location":"etc/ml/MNIST/#model","text":"","title":"Model"},{"location":"etc/ml/MNIST/#linear-regression","text":"","title":"Linear regression"},{"location":"etc/ml/MNIST/#forward-model","text":"$f(x) = W \\cdot X + b$ - X: (784, m), W (1, 784), b (1, 1)","title":"Forward Model"},{"location":"etc/ml/MNIST/#loss","text":"$ H_{q}(p) = \\sum_{x} q(x) *\\log_{2} \\frac{1}{\\log p(x)} $ - Cross-Entroy: Average length of message from q(x) using code for p(x)","title":"Loss"},{"location":"etc/ml/MNIST/#cost","text":"$ cost(\\theta) = \\sum_{i=0}^{M}loss(x^{(i)})$","title":"Cost"},{"location":"etc/ml/MNIST/#resource","text":"Information theory stanford-tensorflow-tutorials","title":"Resource"},{"location":"etc/ml/huber_loss/","text":"Huber loss Goal Want less sensitive function to the outliers than the square error loss. How to Use square function for small value. Use absolute function for large value. IDEA $ f(a) = \\begin{cases} a^2 & \\text{for }|a| \\leq 1, \\\\ |a| & \\text{ otherwise} \\end{cases} $ Huber loss $ L_{\\delta}(a) = \\begin{cases} \\frac{1}{2}a^2 & \\text{for }|a| \\leq \\delta, \\\\ \\delta (|a| - \\frac{1}{2} \\delta), & \\text{ otherwise} \\end{cases} $ Graph - Huber loss is green ($ \\delta = 1 $) - squared error loss is blue Code import tensorflow as tf import pandas as pd import numpy as np import math def huber_loss(y, y_hat, delta): diff = math.abs(y - y_hat) if diff < delta: return 0.5 * diff**2 else: return delta * diff - 0.5 * delta**2 def huber_loss(y, y_hat, delta=1.0): residual = tf.abs(y - y_hat) def square_f(): return 0.5 * tf.square(residual) def abs_f(): return delta * residual - 0.5 * tf.square(delta) return tf.cond(residual < delta, square_f, abs_f) Tag loss function ml huber loss","title":"Huber loss"},{"location":"etc/ml/huber_loss/#huber-loss","text":"","title":"Huber loss"},{"location":"etc/ml/huber_loss/#goal","text":"Want less sensitive function to the outliers than the square error loss.","title":"Goal"},{"location":"etc/ml/huber_loss/#how-to","text":"Use square function for small value. Use absolute function for large value.","title":"How to"},{"location":"etc/ml/huber_loss/#idea","text":"$ f(a) = \\begin{cases} a^2 & \\text{for }|a| \\leq 1, \\\\ |a| & \\text{ otherwise} \\end{cases} $","title":"IDEA"},{"location":"etc/ml/huber_loss/#huber-loss_1","text":"$ L_{\\delta}(a) = \\begin{cases} \\frac{1}{2}a^2 & \\text{for }|a| \\leq \\delta, \\\\ \\delta (|a| - \\frac{1}{2} \\delta), & \\text{ otherwise} \\end{cases} $","title":"Huber loss"},{"location":"etc/ml/huber_loss/#graph","text":"- Huber loss is green ($ \\delta = 1 $) - squared error loss is blue","title":"Graph"},{"location":"etc/ml/huber_loss/#code","text":"import tensorflow as tf import pandas as pd import numpy as np import math def huber_loss(y, y_hat, delta): diff = math.abs(y - y_hat) if diff < delta: return 0.5 * diff**2 else: return delta * diff - 0.5 * delta**2 def huber_loss(y, y_hat, delta=1.0): residual = tf.abs(y - y_hat) def square_f(): return 0.5 * tf.square(residual) def abs_f(): return delta * residual - 0.5 * tf.square(delta) return tf.cond(residual < delta, square_f, abs_f)","title":"Code"},{"location":"etc/ml/huber_loss/#tag","text":"loss function ml huber loss","title":"Tag"},{"location":"etc/ml/linear_regression/","text":"Linear regression Goal Make linear model to predict y value. Data x: birth_rate y: life_expectancy M: 190 Country Birth_rate Life_expectancy Vietnam 1.822 74.828243902 Vanuatu 3.869 70.819487805 Tonga 3.911 72.150658537 Plan Load data define input and target. Create model define forward model define optimize model define loss function. Train data Optimize loss function. Measure performance. predict data. Get measure cost. Model Linear regression. $f(x) = w * X + b$ $loss = (y - \\hat y)^2$ $cost(\\theta) = \\sum_{i=0}^{M}loss(x^{(i)})$ Code Use Place holder. import pandas as pd import numpy as np import tensorflow as tf import matplotlib.pyplot as plt df = pd.read_csv('./examples/data/birth_life_2010.txt', delimiter='\\t') df.describe() df.shape[0] input_label = 'Birthrate' target_label = 'Lifeexpectancy' X = tf.placeholder(tf.float32, name='X') y = tf.placeholder(tf.float32, name='y') W = tf.get_variable('w', initializer=tf.constant(0.0)) b = tf.get_variable('b', initializer=tf.constant(0.0)) init_variables = tf.global_variables_initializer() y_hat = tf.multiply(W, X) + b loss = tf.sqrt((y - y_hat)**2) optimizer = tf.train.GradientDescentOptimizer(learning_rate=1e-2).minimize(loss) with tf.Session() as sess: sess.run(init_variables) writer = tf.summary.FileWriter('./graphs/linear_reg2', sess.graph) for batch in range(100): cost = 0 for i in range(df.shape[0]): _, loss_out = sess.run([optimizer, loss], feed_dict={X: df[input_label][i], y: df[target_label][i]}) cost += loss_out W_out, b_out = sess.run([W, b]) print(W_out, b_out, cost) writer.close() plt.scatter(df[input_label], df[target_label]) x_min = df[input_label].min() x_max = df[input_label].max() plt.plot([x_min, x_max], [W_out * x_min + b_out, W_out * x_max + b_out]) plt.show() Use dataset import pandas as pd import numpy as np import tensorflow as tf import matplotlib.pyplot as plt df = pd.read_csv('./examples/data/birth_life_2010.txt', delimiter='\\t') df.describe() dataset = tf.data.Dataset.from_tensor_slices((df['Birthrate'], df['Lifeexpectancy'])) iterator = dataset.make_initializable_iterator() X, y = iterator.get_next() # with tf.Session() as sess: # sess.run(iterator.initializer) # sess.run(iterator.get_next()) W = tf.get_variable('weights', initializer=tf.constant(0.0, dtype=tf.float64)) b = tf.get_variable('bias', initializer=tf.constant(0.0, dtype=tf.float64)) y_hat = W * X + b loss = tf.square(y - y_hat) optimizer = tf.train.GradientDescentOptimizer(learning_rate=1e-3).minimize(loss) with tf.Session() as sess: sess.run(tf.global_variables_initializer()) for epoch in range(100): sess.run(iterator.initializer) cost = 0 try: while True: _, out_loss = sess.run([optimizer, loss]) cost += out_loss except: pass out_W, out_b = sess.run([W, b]) print('epoch %d out_W %f out_b %f cost %f' % (epoch, out_W, out_b, cost)) Resource stanford-tensorflow-tutorials","title":"Linear regression"},{"location":"etc/ml/linear_regression/#linear-regression","text":"","title":"Linear regression"},{"location":"etc/ml/linear_regression/#goal","text":"Make linear model to predict y value.","title":"Goal"},{"location":"etc/ml/linear_regression/#data","text":"x: birth_rate y: life_expectancy M: 190 Country Birth_rate Life_expectancy Vietnam 1.822 74.828243902 Vanuatu 3.869 70.819487805 Tonga 3.911 72.150658537","title":"Data"},{"location":"etc/ml/linear_regression/#plan","text":"Load data define input and target. Create model define forward model define optimize model define loss function. Train data Optimize loss function. Measure performance. predict data. Get measure cost.","title":"Plan"},{"location":"etc/ml/linear_regression/#model","text":"Linear regression. $f(x) = w * X + b$ $loss = (y - \\hat y)^2$ $cost(\\theta) = \\sum_{i=0}^{M}loss(x^{(i)})$","title":"Model"},{"location":"etc/ml/linear_regression/#code","text":"","title":"Code"},{"location":"etc/ml/linear_regression/#use-place-holder","text":"import pandas as pd import numpy as np import tensorflow as tf import matplotlib.pyplot as plt df = pd.read_csv('./examples/data/birth_life_2010.txt', delimiter='\\t') df.describe() df.shape[0] input_label = 'Birthrate' target_label = 'Lifeexpectancy' X = tf.placeholder(tf.float32, name='X') y = tf.placeholder(tf.float32, name='y') W = tf.get_variable('w', initializer=tf.constant(0.0)) b = tf.get_variable('b', initializer=tf.constant(0.0)) init_variables = tf.global_variables_initializer() y_hat = tf.multiply(W, X) + b loss = tf.sqrt((y - y_hat)**2) optimizer = tf.train.GradientDescentOptimizer(learning_rate=1e-2).minimize(loss) with tf.Session() as sess: sess.run(init_variables) writer = tf.summary.FileWriter('./graphs/linear_reg2', sess.graph) for batch in range(100): cost = 0 for i in range(df.shape[0]): _, loss_out = sess.run([optimizer, loss], feed_dict={X: df[input_label][i], y: df[target_label][i]}) cost += loss_out W_out, b_out = sess.run([W, b]) print(W_out, b_out, cost) writer.close() plt.scatter(df[input_label], df[target_label]) x_min = df[input_label].min() x_max = df[input_label].max() plt.plot([x_min, x_max], [W_out * x_min + b_out, W_out * x_max + b_out]) plt.show()","title":"Use Place holder."},{"location":"etc/ml/linear_regression/#use-dataset","text":"import pandas as pd import numpy as np import tensorflow as tf import matplotlib.pyplot as plt df = pd.read_csv('./examples/data/birth_life_2010.txt', delimiter='\\t') df.describe() dataset = tf.data.Dataset.from_tensor_slices((df['Birthrate'], df['Lifeexpectancy'])) iterator = dataset.make_initializable_iterator() X, y = iterator.get_next() # with tf.Session() as sess: # sess.run(iterator.initializer) # sess.run(iterator.get_next()) W = tf.get_variable('weights', initializer=tf.constant(0.0, dtype=tf.float64)) b = tf.get_variable('bias', initializer=tf.constant(0.0, dtype=tf.float64)) y_hat = W * X + b loss = tf.square(y - y_hat) optimizer = tf.train.GradientDescentOptimizer(learning_rate=1e-3).minimize(loss) with tf.Session() as sess: sess.run(tf.global_variables_initializer()) for epoch in range(100): sess.run(iterator.initializer) cost = 0 try: while True: _, out_loss = sess.run([optimizer, loss]) cost += out_loss except: pass out_W, out_b = sess.run([W, b]) print('epoch %d out_W %f out_b %f cost %f' % (epoch, out_W, out_b, cost))","title":"Use dataset"},{"location":"etc/ml/linear_regression/#resource","text":"stanford-tensorflow-tutorials","title":"Resource"},{"location":"etc/ml/softmax/","text":"Softmax Goals Input \uac12\ub4e4\uc744 \ub2e4 \ud569\uce58\uba74 1\uc774 \ub418\ub294 \ud655\ub960\uac12\uc73c\ub85c \ubcc0\ud658\ud574 \uc8fc\uace0 \uc2f6\ub2e4. \uadf8 \uc774\uc57c\uae30\ub294 \uc5b4\ub5a4 \uac12\uc774\ub358 0 \uacfc 1 \uc0ac\uc774\uc758 \uac12\uc744 \ub9ac\ud134\ud558\ub294 \ud568\uc218\ub97c \ub9cc\ub4e4\uace0 \uc2f6\ub2e4. $\\sigma: \\mathbb {R} ^{K}\\to (0,1)^{K} $ Idea \uc608\ub97c\ub4e4\uc5b4 input \uac12\uc774 [1,2,3] \uc77c \uacbd\uc6b0 \uacb0\uacfc\uc758 \ucd1d\ud569\uc774 1\uc774 \ub418\uac8c \ud574\uc904\ub824\uba74 input\uc744 \ub2e4 \ub354\ud55c\uac12 6 = 1 + 2 + 3\uc73c\ub85c \ubaa8\ub4e0 \uc778\ud48b\uac12\uc744 \ub098\ub204\uc5b4 \uc8fc\uba74 \ub41c\ub2e4. $\\sigma([1,2,3]) \\to [\\frac{1}{6},\\frac{2}{6},\\frac{3}{6}] \\approx [0.16, 0.33, 0.5] \\approx 1 $ \uc704\uc758 \uc2dd\uc744 \uc815\ub9ac\ud558\uba74 \uc544\ub798\uc758 \uc2dd\uc774 \ub41c\ub2e4. $\\sigma(\\mathbf{z_{j}}) = {\\frac {z_{j}}{\\sum_{k=1}^{K}z_{k}}}$ \uc704\uc758 \ud568\uc218\uc758 \uc0c1\uc218 z\ub97c \uc9c0\uc218\ub85c \ubc14\uafd4\uc8fc\uc790. $z_j \\to e^{z_j} \\approx 2.71^{z_j}$ $\\sigma(\\mathbf{z_{j}}) = {\\frac{e^{z_{j}}}{\\sum_{k=1}^{K}e^{z_{k}}}} $ \uadf8\ub807\ub2e4 \uc704\uc758 \uc2dd\uc774 softmax \uc774\uba70 \uc6b0\ub9ac\uc758 \uc608\uc81c\ub97c \uacc4\uc0b0\ud558\uba74 $\\sigma([1,2,3]) \\to [\\frac{2.7}{30.2},\\frac{7.3}{30.2},\\frac{20.1}{30.2}] \\approx [0.09, 0.24, 0.66] \\approx 1 $ Code import numpy as np x = [1,2,3] def softmax(x): np.exp(x) / np.sum(np.exp(x)) Tag softmax","title":"Softmax"},{"location":"etc/ml/softmax/#softmax","text":"","title":"Softmax"},{"location":"etc/ml/softmax/#goals","text":"Input \uac12\ub4e4\uc744 \ub2e4 \ud569\uce58\uba74 1\uc774 \ub418\ub294 \ud655\ub960\uac12\uc73c\ub85c \ubcc0\ud658\ud574 \uc8fc\uace0 \uc2f6\ub2e4. \uadf8 \uc774\uc57c\uae30\ub294 \uc5b4\ub5a4 \uac12\uc774\ub358 0 \uacfc 1 \uc0ac\uc774\uc758 \uac12\uc744 \ub9ac\ud134\ud558\ub294 \ud568\uc218\ub97c \ub9cc\ub4e4\uace0 \uc2f6\ub2e4. $\\sigma: \\mathbb {R} ^{K}\\to (0,1)^{K} $","title":"Goals"},{"location":"etc/ml/softmax/#idea","text":"\uc608\ub97c\ub4e4\uc5b4 input \uac12\uc774 [1,2,3] \uc77c \uacbd\uc6b0 \uacb0\uacfc\uc758 \ucd1d\ud569\uc774 1\uc774 \ub418\uac8c \ud574\uc904\ub824\uba74 input\uc744 \ub2e4 \ub354\ud55c\uac12 6 = 1 + 2 + 3\uc73c\ub85c \ubaa8\ub4e0 \uc778\ud48b\uac12\uc744 \ub098\ub204\uc5b4 \uc8fc\uba74 \ub41c\ub2e4. $\\sigma([1,2,3]) \\to [\\frac{1}{6},\\frac{2}{6},\\frac{3}{6}] \\approx [0.16, 0.33, 0.5] \\approx 1 $ \uc704\uc758 \uc2dd\uc744 \uc815\ub9ac\ud558\uba74 \uc544\ub798\uc758 \uc2dd\uc774 \ub41c\ub2e4. $\\sigma(\\mathbf{z_{j}}) = {\\frac {z_{j}}{\\sum_{k=1}^{K}z_{k}}}$ \uc704\uc758 \ud568\uc218\uc758 \uc0c1\uc218 z\ub97c \uc9c0\uc218\ub85c \ubc14\uafd4\uc8fc\uc790. $z_j \\to e^{z_j} \\approx 2.71^{z_j}$ $\\sigma(\\mathbf{z_{j}}) = {\\frac{e^{z_{j}}}{\\sum_{k=1}^{K}e^{z_{k}}}} $ \uadf8\ub807\ub2e4 \uc704\uc758 \uc2dd\uc774 softmax \uc774\uba70 \uc6b0\ub9ac\uc758 \uc608\uc81c\ub97c \uacc4\uc0b0\ud558\uba74 $\\sigma([1,2,3]) \\to [\\frac{2.7}{30.2},\\frac{7.3}{30.2},\\frac{20.1}{30.2}] \\approx [0.09, 0.24, 0.66] \\approx 1 $","title":"Idea"},{"location":"etc/ml/softmax/#code","text":"import numpy as np x = [1,2,3] def softmax(x): np.exp(x) / np.sum(np.exp(x))","title":"Code"},{"location":"etc/ml/softmax/#tag","text":"softmax","title":"Tag"},{"location":"etc/ml/tensorflow_dataset/","text":"tenserflow data Goal Provide data abstraction. tf.Data.Dataset Represent sequence of elements. Creating from source.(tf.Tensor) Creating from tf.dataset using Transformation. tf.data.Iterator Provide main way to extract data from Dataset Sample data l,d0,d1,d2,d3,d4 0,1,2,3,4 1,11,12,13,14 2,21,22,23,24 import pandas as pd import tensorflow as tf import numpy as np df = pd.read_csv('./data/test.csv') df.describe() dm = df.as_matrix() y = dm[:, 0] x = dm[:, 1:] max = np.max(dm[:, 0]) + 1 onehot_y = np.eye(max)[dm[:, 0]] dataset = tf.data.Dataset.from_tensor_slices((x, onehot_y)) iterator = dataset.make_initializable_iterator() X, y = iterator.get_next() with tf.Session() as sess: for e in range(3): sess.run(iterator.initializer) try: while True: X_out, y_out = sess.run([X, y]) print('X_out', X_out) print('y_out', y_out) except tf.errors.OutOfRangeError: print('OutOfRangeError') pass Tag tensorflow dataset iterator","title":"tenserflow data"},{"location":"etc/ml/tensorflow_dataset/#tenserflow-data","text":"","title":"tenserflow data"},{"location":"etc/ml/tensorflow_dataset/#goal","text":"Provide data abstraction. tf.Data.Dataset Represent sequence of elements. Creating from source.(tf.Tensor) Creating from tf.dataset using Transformation. tf.data.Iterator Provide main way to extract data from Dataset","title":"Goal"},{"location":"etc/ml/tensorflow_dataset/#sample-data","text":"l,d0,d1,d2,d3,d4 0,1,2,3,4 1,11,12,13,14 2,21,22,23,24 import pandas as pd import tensorflow as tf import numpy as np df = pd.read_csv('./data/test.csv') df.describe() dm = df.as_matrix() y = dm[:, 0] x = dm[:, 1:] max = np.max(dm[:, 0]) + 1 onehot_y = np.eye(max)[dm[:, 0]] dataset = tf.data.Dataset.from_tensor_slices((x, onehot_y)) iterator = dataset.make_initializable_iterator() X, y = iterator.get_next() with tf.Session() as sess: for e in range(3): sess.run(iterator.initializer) try: while True: X_out, y_out = sess.run([X, y]) print('X_out', X_out) print('y_out', y_out) except tf.errors.OutOfRangeError: print('OutOfRangeError') pass","title":"Sample data"},{"location":"etc/ml/tensorflow_dataset/#tag","text":"tensorflow dataset iterator","title":"Tag"},{"location":"etc/seminar/learn_to_learn/","text":"How to learn to learn? Idea \uac00\uc7a5 \uae30\ubcf8\uc801\uc778 \ud50c\ub79c\uc744 \uc9dc\ub294 \ubc29\ubc95 \ubaa9\uc801\uc744 \uc54c\uace0 \ud559\uc2b5\ud558\uba74 \ube60\ub974\ub2e4. \uc6b0\ub9ac\ub294 \ucd08\uae30\uac12\uc744 \uc54c\uace0 \ud559\uc2b5\ud55c\ub2e4. \uc778\uac04\uc740 \ucd08\uae30\uac12\uc744 \ucc45\uc73c\ub85c \uc804\ub2ec\ud574 \uc900\ub2e4. \ub1cc\ub294 \uadfc\uc721\uc774\ub2e4. \ub1cc\ub294 \uc138\ud3ec\ub85c \uc774\ub8e8\uc5b4\uc838 \uc788\ub2e4. \ub274\ub860\uc758 \ud2b9\uc9d5 \ub1cc\uc758 \uc0dd\uae40\uc0c8 \uc2ec\ubcfc\ud654 \ub2e8\uae30 \uc800\uc7a5 \uc7a5\uc18c \uc608\uc81c \ud504\ub85c\uadf8\ub798\ubc0d \uc774\uc57c\uae30 \ud560 \uac83\ub4e4 \ud559\uc2b5\uc774\ub780? \ud6a8\uc728\uc801\uc778 \ud559\uc2b5\uc774\ub780? \ud6a8\uacfc\uc801\uc778 \ud559\uc2b5\uc774\ub780? \ud559\uc2b5 \ubaa8\ub378\uacfc \uc608\uc81c \ud559\uc2b5\ud558\ub294 \ubc29\ubc95 \ub0a8\uc740\uac83. Goal \ub2e8\uc704 \uc2dc\uac04\uc548\uc5d0 \ud6a8\uacfc\uc801\uc778 \ud559\uc2b5\uc744 \ud558\uace0 \uc2f6\ub2e4. \ud559\uc2b5\uc774\ub780. \uacbd\ud5d8 \ub610\ub294 \ud6c8\ub828\uc744 \ud1b5\ud574 \ud2b9\uc815 \ubd84\uc57c\uc5d0\uc11c \ud2b9\uc815 \uc0c1\ud669\uc774 \uc8fc\uc5b4 \uc84c\uc744\ub54c \ubaa9\uc801 \ub2ec\uc131\uc744 \uc704\ud55c \ucd5c\uc801\uc758 \ubc29\uc548\uc744 \uc120\ud0dd\ud558\ub294\uac83 \uc774\ub77c\uace0 \uc815\uc758\ud55c\ub2e4. \uc774\ud574\ub97c \uc704\ud574 \uc608\ub97c \ub4e4\uc5b4\ubcf4\uc790. \uc601\uc5b4\ub97c \ud559\uc2b5\ud55c\ub2e4\uace0 \ud558\uc790. \uc774\ub54c\uc758 \ub2ec\uc131 \ubaa9\uc801\uc740 \uc601\uc5b4\uad8c \uc0ac\ub78c\ub4e4\uacfc \uc720\uc0ac\ud558\uac8c \uc758\uc0ac\ud45c\ud604\uc744 \ubaa9\uc801\uc73c\ub85c \uc7a1\uc744 \uc218 \uc788\ub2e4. \ub2e4\uc74c\uc5d0 \uc54c\ub9de\uc740 \ub3d9\uc0ac\ub97c \uace0\ub974\uc2dc\uc624. I __ a boy. 0. am 0. are \uc704\uc758 \ubb38\uc81c\ub97c \ud559\uc2b5\uc774\ub780 \uc815\uc758\uc5d0 \ub300\uc785\ud574\ubcf4\uc790. - \ud2b9\uc815\uc0c1\ud669 = \ubb38\uc81c \ud480\uc774 - \ubaa9\uc801 \ub2ec\uc131 = \uc601\uc5b4\uad8c \uc0ac\ub78c\ub4e4\uacfc \uc720\uc0ac\ud558\uac8c \uc758\uc0ac \ud45c\ud604 - \uc120\ud0dd\uc9c0 = 1. am, 2. are - \ucd5c\uc801 \ubc29\uc548 = 1. \ucd5c\uc801 \ubc29\uc548\uc774 1\uc778 \uc774\uc720\ub294 \ubaa9\uc801\uc744 \ub2ec\uc131\ud558\uae30 \ub54c\ubb38\uc774\ub2e4. \uc704 \uc640 \uac19\uc740 \ubb38\uc81c\uac00 100 \uac1c \uc788\ub294 \uc601\uc5b4 \uc2dc\ud5d8\uc9c0\ub97c \uac00\uc815\ud574\ubcf4\uc790 (\ubb38\uc81c 1\uac1c\ub2f9 1\uc810) \ud6a8\uc728\uc801\uc778 \ud559\uc2b5\uc774\ub780? \ub9cc\uc57d \uc6b0\ub9ac\uc758 \ubaa9\uc801\uc778 \uc720\uc0ac\ud55c \uc758\uc0ac\ud45c\ud604 == \ub192\uc740 \uc810\uc218\ub77c\uace0 \uc815\uc758\ud558\uc790. \uadf8\ub807\ub2e4\uba74 \uc801\uc740 \uc2dc\uac04\uc548\uc5d0 \ub192\uc740 \uc810\uc218\ub97c \ubc1b\ub294\uac8c \ud6a8\uc728 \uc801\uc778 \ud559\uc2b5\uc774\ub77c\uace0 \ud560 \uc218 \uc788\ub2e4. (\uc774\uac8c \uc0ac\uad50\uc721\uc758 \ud3d0\ud61c\ub97c \ubd88\ub7ec\uc654\ub2e4...) \ud6a8\uacfc\uc801\uc778 \ud559\uc2b5\uc774\ub780. \ub9cc\uc57d \uc6b0\ub9ac\uc758 \ubaa9\uc801\uc778 \uc720\uc0ac\ud55c \uc758\uc0ac\ud45c\ud604 == \ub192\uc740 \uc810\uc218\ub77c\uace0 \uc815\uc758\ud558\uc790. \uadf8\ub807\ub2e4\uba74 \ubb38\uc81c\uac00 \ubcc0\ud558\uc9c0 \uc54a\ub294\ub2e4\uace0 \uac00\uc815\ud558\uba74 \uc2dc\ud5d8\uc9c0 \uc815\ub2f5 \ubc88\ud638\ub97c \uc65c\uc6b0\ub294\uac1c \ud6a8\uacfc\uc801\uc774\ub2e4. \ud558\uc9c0\ub9cc \ubb38\uc81c\uac00 \ubcc0\ud55c\ub2e4\uba74 \ubb38\ubc95\uc744 \ubc30\uc6b0\ub294\uac8c \ub354 \ube60\ub974\ub2e4. \uc989 \ubaa9\uc801\uc5d0 \ub530\ub77c \ud559\uc2b5 \ubc29\ubc95\uc774 \ubcc0\ud558\uac8c \ub41c\ub2e4. \ud559\uc2b5\uc774\ub780? \uc870\uae08 \ub354 \uc704\uc758 \uc608\uc81c\ub97c \uc815\ud655\ud558\uace0 general \ud558\uac8c \uc815\uc758\ud574 \ubcf4\uc790. \uc544\ub798\uc758 \uc815\uc758\ub294 \uc0dd\ubb3c\ud559\uc5d0\uc11c\uc758 \uc778\uac04\uc758 \uc815\uc758 \uc774\uba70 \ubcf8\uc778\uacfc\ub294 \uc808\ub300\uc801\uc73c\ub85c \ubb34\uad00\ud558\ub2e4. \uc778\uac04\uc740 \ud2b9\uc815 \ubaa9\uc801\uc744 \ub2ec\uc131\ud558\uae30 \uc704\ud55c \uc54c\uace0\ub9ac\uc998\ub4e4\uc758 \uc9d1\ud569\uc774\ub2e4. \uc704\uc758 \uac00\uc815 \ub300\ub85c\ub77c\uba74 \uc6b0\ub9ac\ub294 \uc778\uac04\uc758 \ud559\uc2b5 \ubaa8\ub378\uc744 \uc54c\uace0\ub9ac\uc998\uc5d0 \uc720\ube44\ud574\uc11c \ud45c\ud604 \ud560 \uc218 \uc788\ub2e4. (\ubb3c\ub860 \ubaa8\ub4e0 \uc720\ube44\ub294 \ud2c0\ub9b0\ub2e4.) \ud559\uc2b5\uc758 \uc815\uc758 \ud559\uc2b5\uc744 \ud1b5\ud574 \ud2b9\uc815 \uc5c5\ubb34\uc758 \ucd5c\uc801 \uc810\uc218\ub97c \ub2ec\uc131\ud558\ub294 \uc54c\uace0\ub9ac\uc998\uc744 \uc6b0\ub9ac\ub294 \uc544\ub798\uc640 \uac19\uc774 \uc815\uc758\ud55c\ub2e4. A computer program is said to learn from experience E with respect to some class of tasks T and performance measure P if its performance at tasks in T, as measured by P, improves with experience E. E \ub294 \uc601\uc5b4 \uc2dc\ud5d8 \uacf5\ubd80 \ub77c\uace0 \ud558\uc790. T \ub294 \uc601\uc5b4 \uc2dc\ud5d8 \ubb38\uc81c\ub97c \ud478\ub294\uac83 \uc774\ub77c\uace0 \ud558\uc790. P \ub294 \uc810\uc218\ub77c\uace0 \ud558\uc790. \uc778\uac04\uc774 \uc601\uc5b4 \uc2dc\ud5d8 \uc871\ubcf4\ub97c \ud480\uc5b4\uc11c \uc2dc\ud5d8\uc5d0\uc11c \uc88b\uc740 \uc810\uc218\ub97c \ubc1b\ub294 \ub2e4\uace0 \ud55c\ub2e4\uba74 \uc704\uc758 \uc815\uc758\uc640 \uc77c\uce58\ud55c\ub2e4. \ud559\uc2b5 \ubaa8\ub378 \ub2e4\uc2dc \ubb38\uc81c\ub85c \ub3cc\uc544\uac00 \ubcf4\uc790. I __ a boy. 1. am 2. are \uc774 \uc608\uc81c\uc5d0\uc11c \uc6b0\ub9ac\ub294 \ubb34\uc5c7\uc73c\ub85c \ub2f5\uc744 \ub0b4\ub9ac\ub294 \uac78\uae4c? \uc8fc\uc5b4\uc758 \uc778\uce6d\uc5d0 \ub530\ub77c\uc11c \ub3d9\uc0ac\uac00 \ubcc0\ud654\ud55c\ub2e4 \ub77c\ub294 \ub8f0\ub85c \uacb0\uc815\ub41c\ub2e4. \uc774\ub8f0\uc740 \uc5b4\ub5bb\uac8c \ub098\uc62c\uae4c? I \uac00 \ub098\uc628 \ud6c4 am \uc774 \uc790\uc8fc \uc0ac\uc6a9\ub418\ub294\uac00 are \uac00 \uc790\uc8fc \uc0ac\uc6a9\ub418\ub294\uac00 \ub77c\ub294 \ubb38\uc81c\uac00 \ub41c\ub2e4. \uc601\uc5b4 \ubb38\uc7a5\uc5d0\uc11c \ube48\ub3c4\uc218\ub97c \uc870\uc0ac\ud588\ub354\ub2c8 I \uac00 \uc0ac\uc6a9 \ub418\uba74 am \uc774 99\ubc88 are \uac00 1\ubc88 \ub098\uc628\ub2e4\uace0 \ud558\uc790. \uc6b0\ub9ac\uac00 \uc704\uc758 \uc0ac\uc2e4\uc744 \uc54c\uace0 \uc788\ub2e4\uba74 \ubb38\uc81c\ub294 \uc544\ub798\uc640 \uac19\uc774 \ubcc0\uacbd \ud560 \uc218 \uc788\ub2e4. $P(am | I) = 0.99$ $P(are | I) = 0.01$ \uc989 \uc6b0\ub9ac\uac00 \ud559\uc2b5\uc774\ub77c\uace0 \ub9d0\ud558\ub294 \uac83\uc740 \ud2b9\uc815 \uc870\uac74\uc774 \uc8fc\uc5b4\uc84c\uc744\ub54c \uac00\uc7a5 \uac00\ub2a5\uc131\uc774 \ub192\uc740 \uac83\uc744 \uc120\ud0dd\ud55c\ub2e4 \ub77c\uace0 \ud560 \uc218 \uc788\ub2e4. \uadf8\ub7ec\uba74 \uc5b4\ub5bb\uac8c \ud558\uba74 \uc800\ub7f0\uac78 \ud558\ub294 \ubaa8\ub378\uc744 \ub9cc\ub4e4 \uc218 \uc788\uc744\uae4c? \uc5ec\ub7ec \ubc29\ubc95\uc774 \uc788\uaca0\uc9c0\ub9cc \ucd5c\ucd08\uc5d0 \uade0\uc77c\ud558\uac8c \ud655\ub960\uc744 \ubc30\uce58\ud55c\ub2e4. $P(am | I) = 0.50$ $P(are | I) = 0.50$ \uc0c8\ub85c\uc6b4 \ubb38\uc7a5\uc744 \uc77d\uc744\ub54c\ub9c8\ub2e4 \ud574\ub2f9 \ud655\ub960\uc744 $+-1$ \uc529 \ubcc0\ub3d9 \uc2dc\ud0a8\ub2e4. \uc608\ub97c \ub4e4\uc5b4 I am a girl \uc744 \ubd24\ub2e4\uba74 \ud655\ub960\uc744 \ubcc0\ub3d9 \uc2dc\ud0a8\ub2e4. $P(am | I) = 0.51$ $P(are | I) = 0.49$ \uadf8\ub7ec\uba74 \uc6b0\ub9ac\ub294 \uc5b8\uc820\uac00 \uc544\ub798\uc758 \uac12\uc744 \uac19\uac8c \ub418\uace0 \ud574\ub2f9 \ud559\uc2b5\uc774 \uc644\ub8cc\ub41c \uc0c1\ud0dc\ub77c\uace0 \ud560 \uc218 \uc788\ub2e4. $P(am | I) = 0.99$ $P(are | I) = 0.01$ \uc704\uc758 \ubaa8\ub378\uc744 \uac00\uc9c0\uace0 \uc774\uc81c \uc6b0\ub9ac\ub294 \uac00\uc124\ub4e4\uc744 \ud574\ub2f9 \ubaa8\ub378\uc5d0 \ube44\ucd94\uc5b4 \ubcfc\uac83\uc774\ub2e4. \uc608\uc81c \ud53c\ub4dc\ubc31 \uc704\uc758 \ubaa8\ub378\uc744 \ubb38\uc81c\uc758 \uc815\ub2f5\uc744 \uac00\uc9c0\uace0 \ubaa8\ub378\uc758 \uac12\uc744 \uc218\uc815\ud55c\ub2e4. \uc989 \uc870\uac74\uc5d0 \ub300\ud55c \uc815\ub2f5\uc744 \uc544\ub294\uac83\uc774 \uc911\uc694\ud558\ub2e4. \uc798\ubabb\ub41c \ud53c\ub4dc\ubc31 \ub9cc\uc57d \uc6b0\ub9ac\uac00 I are \ub97c \ub354 \ub9ce\uc774 \ubcf4\uac8c \ub418\uba74 \uc5b4\ub5bb\uac8c \ub420\uae4c? \uc989 \uc798\ubabb\ub41c \ub2f5\uc774 \ub41c\ub2e4. \uc989 \uc815\ud655\ud55c \ud53c\ub4dc\ubc31\uc740 \uc911\uc694\ud558\ub2e4. \ub9cc\uc57d \ud53c\ub4dc\ubc31\uc774 \ub2a6\uc73c\uba74 \uc624\uba74 \uc5b4\ub5bb\uac8c \ub420\uae4c? \ubaa8\ub378\uc758 \ucd5c\uc801 \uac12\uc740 \uc804\ud600 \ubcc0\uacbd\ub418\uc9c0 \uc54a\ub294\ub2e4. \uc989 \uc2dc\uac04 \ub0ad\ube44\ub2e4. \ub9cc\uc57d \ucd08\uae30\uac12\uc774 \uc5c6\uc73c\uba74 \uc5b4\ub5bb\uac8c \ub420\uae4c? \uc6b0\ub9ac\ub294 \ubaa8\ub378\uc758 \uc22b\uc790\ub97c \uac00\uac10 \uc2dc\ud0a8\ub2e4. \ub9cc\uc57d \ubaa8\ub378 \uc790\uccb4\uac00 \uc5c6\ub2e4\uba74 $\\infty$ \uc5d0 \uc5b4\ub5bb\uac12\uc744 \ub354\ud574\ub3c4 \uc798 \ubcc0\ud558\uc9c0 \uc54a\ub294\ub2e4. \uc720\ub2db \uc2dc\uac04\uc548\uc5d0 \ub9ce\uc740 \uc9c0\uc2dd\uc744 \uc2b5\ub4dd\ud558\uace0 \uc2f6\ub2e4.","title":"How to learn to learn?"},{"location":"etc/seminar/learn_to_learn/#how-to-learn-to-learn","text":"","title":"How to learn to learn?"},{"location":"etc/seminar/learn_to_learn/#idea","text":"\uac00\uc7a5 \uae30\ubcf8\uc801\uc778 \ud50c\ub79c\uc744 \uc9dc\ub294 \ubc29\ubc95 \ubaa9\uc801\uc744 \uc54c\uace0 \ud559\uc2b5\ud558\uba74 \ube60\ub974\ub2e4. \uc6b0\ub9ac\ub294 \ucd08\uae30\uac12\uc744 \uc54c\uace0 \ud559\uc2b5\ud55c\ub2e4. \uc778\uac04\uc740 \ucd08\uae30\uac12\uc744 \ucc45\uc73c\ub85c \uc804\ub2ec\ud574 \uc900\ub2e4. \ub1cc\ub294 \uadfc\uc721\uc774\ub2e4. \ub1cc\ub294 \uc138\ud3ec\ub85c \uc774\ub8e8\uc5b4\uc838 \uc788\ub2e4. \ub274\ub860\uc758 \ud2b9\uc9d5 \ub1cc\uc758 \uc0dd\uae40\uc0c8 \uc2ec\ubcfc\ud654 \ub2e8\uae30 \uc800\uc7a5 \uc7a5\uc18c \uc608\uc81c \ud504\ub85c\uadf8\ub798\ubc0d","title":"Idea"},{"location":"etc/seminar/learn_to_learn/#_1","text":"\ud559\uc2b5\uc774\ub780? \ud6a8\uc728\uc801\uc778 \ud559\uc2b5\uc774\ub780? \ud6a8\uacfc\uc801\uc778 \ud559\uc2b5\uc774\ub780? \ud559\uc2b5 \ubaa8\ub378\uacfc \uc608\uc81c \ud559\uc2b5\ud558\ub294 \ubc29\ubc95 \ub0a8\uc740\uac83.","title":"\uc774\uc57c\uae30 \ud560 \uac83\ub4e4"},{"location":"etc/seminar/learn_to_learn/#goal","text":"\ub2e8\uc704 \uc2dc\uac04\uc548\uc5d0 \ud6a8\uacfc\uc801\uc778 \ud559\uc2b5\uc744 \ud558\uace0 \uc2f6\ub2e4.","title":"Goal"},{"location":"etc/seminar/learn_to_learn/#_2","text":"\uacbd\ud5d8 \ub610\ub294 \ud6c8\ub828\uc744 \ud1b5\ud574 \ud2b9\uc815 \ubd84\uc57c\uc5d0\uc11c \ud2b9\uc815 \uc0c1\ud669\uc774 \uc8fc\uc5b4 \uc84c\uc744\ub54c \ubaa9\uc801 \ub2ec\uc131\uc744 \uc704\ud55c \ucd5c\uc801\uc758 \ubc29\uc548\uc744 \uc120\ud0dd\ud558\ub294\uac83 \uc774\ub77c\uace0 \uc815\uc758\ud55c\ub2e4. \uc774\ud574\ub97c \uc704\ud574 \uc608\ub97c \ub4e4\uc5b4\ubcf4\uc790. \uc601\uc5b4\ub97c \ud559\uc2b5\ud55c\ub2e4\uace0 \ud558\uc790. \uc774\ub54c\uc758 \ub2ec\uc131 \ubaa9\uc801\uc740 \uc601\uc5b4\uad8c \uc0ac\ub78c\ub4e4\uacfc \uc720\uc0ac\ud558\uac8c \uc758\uc0ac\ud45c\ud604\uc744 \ubaa9\uc801\uc73c\ub85c \uc7a1\uc744 \uc218 \uc788\ub2e4.","title":"\ud559\uc2b5\uc774\ub780."},{"location":"etc/seminar/learn_to_learn/#_3","text":"I __ a boy. 0. am 0. are \uc704\uc758 \ubb38\uc81c\ub97c \ud559\uc2b5\uc774\ub780 \uc815\uc758\uc5d0 \ub300\uc785\ud574\ubcf4\uc790. - \ud2b9\uc815\uc0c1\ud669 = \ubb38\uc81c \ud480\uc774 - \ubaa9\uc801 \ub2ec\uc131 = \uc601\uc5b4\uad8c \uc0ac\ub78c\ub4e4\uacfc \uc720\uc0ac\ud558\uac8c \uc758\uc0ac \ud45c\ud604 - \uc120\ud0dd\uc9c0 = 1. am, 2. are - \ucd5c\uc801 \ubc29\uc548 = 1. \ucd5c\uc801 \ubc29\uc548\uc774 1\uc778 \uc774\uc720\ub294 \ubaa9\uc801\uc744 \ub2ec\uc131\ud558\uae30 \ub54c\ubb38\uc774\ub2e4. \uc704 \uc640 \uac19\uc740 \ubb38\uc81c\uac00 100 \uac1c \uc788\ub294 \uc601\uc5b4 \uc2dc\ud5d8\uc9c0\ub97c \uac00\uc815\ud574\ubcf4\uc790 (\ubb38\uc81c 1\uac1c\ub2f9 1\uc810)","title":"\ub2e4\uc74c\uc5d0 \uc54c\ub9de\uc740 \ub3d9\uc0ac\ub97c \uace0\ub974\uc2dc\uc624."},{"location":"etc/seminar/learn_to_learn/#_4","text":"\ub9cc\uc57d \uc6b0\ub9ac\uc758 \ubaa9\uc801\uc778 \uc720\uc0ac\ud55c \uc758\uc0ac\ud45c\ud604 == \ub192\uc740 \uc810\uc218\ub77c\uace0 \uc815\uc758\ud558\uc790. \uadf8\ub807\ub2e4\uba74 \uc801\uc740 \uc2dc\uac04\uc548\uc5d0 \ub192\uc740 \uc810\uc218\ub97c \ubc1b\ub294\uac8c \ud6a8\uc728 \uc801\uc778 \ud559\uc2b5\uc774\ub77c\uace0 \ud560 \uc218 \uc788\ub2e4. (\uc774\uac8c \uc0ac\uad50\uc721\uc758 \ud3d0\ud61c\ub97c \ubd88\ub7ec\uc654\ub2e4...)","title":"\ud6a8\uc728\uc801\uc778 \ud559\uc2b5\uc774\ub780?"},{"location":"etc/seminar/learn_to_learn/#_5","text":"\ub9cc\uc57d \uc6b0\ub9ac\uc758 \ubaa9\uc801\uc778 \uc720\uc0ac\ud55c \uc758\uc0ac\ud45c\ud604 == \ub192\uc740 \uc810\uc218\ub77c\uace0 \uc815\uc758\ud558\uc790. \uadf8\ub807\ub2e4\uba74 \ubb38\uc81c\uac00 \ubcc0\ud558\uc9c0 \uc54a\ub294\ub2e4\uace0 \uac00\uc815\ud558\uba74 \uc2dc\ud5d8\uc9c0 \uc815\ub2f5 \ubc88\ud638\ub97c \uc65c\uc6b0\ub294\uac1c \ud6a8\uacfc\uc801\uc774\ub2e4. \ud558\uc9c0\ub9cc \ubb38\uc81c\uac00 \ubcc0\ud55c\ub2e4\uba74 \ubb38\ubc95\uc744 \ubc30\uc6b0\ub294\uac8c \ub354 \ube60\ub974\ub2e4. \uc989 \ubaa9\uc801\uc5d0 \ub530\ub77c \ud559\uc2b5 \ubc29\ubc95\uc774 \ubcc0\ud558\uac8c \ub41c\ub2e4.","title":"\ud6a8\uacfc\uc801\uc778 \ud559\uc2b5\uc774\ub780."},{"location":"etc/seminar/learn_to_learn/#_6","text":"\uc870\uae08 \ub354 \uc704\uc758 \uc608\uc81c\ub97c \uc815\ud655\ud558\uace0 general \ud558\uac8c \uc815\uc758\ud574 \ubcf4\uc790. \uc544\ub798\uc758 \uc815\uc758\ub294 \uc0dd\ubb3c\ud559\uc5d0\uc11c\uc758 \uc778\uac04\uc758 \uc815\uc758 \uc774\uba70 \ubcf8\uc778\uacfc\ub294 \uc808\ub300\uc801\uc73c\ub85c \ubb34\uad00\ud558\ub2e4. \uc778\uac04\uc740 \ud2b9\uc815 \ubaa9\uc801\uc744 \ub2ec\uc131\ud558\uae30 \uc704\ud55c \uc54c\uace0\ub9ac\uc998\ub4e4\uc758 \uc9d1\ud569\uc774\ub2e4. \uc704\uc758 \uac00\uc815 \ub300\ub85c\ub77c\uba74 \uc6b0\ub9ac\ub294 \uc778\uac04\uc758 \ud559\uc2b5 \ubaa8\ub378\uc744 \uc54c\uace0\ub9ac\uc998\uc5d0 \uc720\ube44\ud574\uc11c \ud45c\ud604 \ud560 \uc218 \uc788\ub2e4. (\ubb3c\ub860 \ubaa8\ub4e0 \uc720\ube44\ub294 \ud2c0\ub9b0\ub2e4.)","title":"\ud559\uc2b5\uc774\ub780?"},{"location":"etc/seminar/learn_to_learn/#_7","text":"\ud559\uc2b5\uc744 \ud1b5\ud574 \ud2b9\uc815 \uc5c5\ubb34\uc758 \ucd5c\uc801 \uc810\uc218\ub97c \ub2ec\uc131\ud558\ub294 \uc54c\uace0\ub9ac\uc998\uc744 \uc6b0\ub9ac\ub294 \uc544\ub798\uc640 \uac19\uc774 \uc815\uc758\ud55c\ub2e4. A computer program is said to learn from experience E with respect to some class of tasks T and performance measure P if its performance at tasks in T, as measured by P, improves with experience E. E \ub294 \uc601\uc5b4 \uc2dc\ud5d8 \uacf5\ubd80 \ub77c\uace0 \ud558\uc790. T \ub294 \uc601\uc5b4 \uc2dc\ud5d8 \ubb38\uc81c\ub97c \ud478\ub294\uac83 \uc774\ub77c\uace0 \ud558\uc790. P \ub294 \uc810\uc218\ub77c\uace0 \ud558\uc790. \uc778\uac04\uc774 \uc601\uc5b4 \uc2dc\ud5d8 \uc871\ubcf4\ub97c \ud480\uc5b4\uc11c \uc2dc\ud5d8\uc5d0\uc11c \uc88b\uc740 \uc810\uc218\ub97c \ubc1b\ub294 \ub2e4\uace0 \ud55c\ub2e4\uba74 \uc704\uc758 \uc815\uc758\uc640 \uc77c\uce58\ud55c\ub2e4.","title":"\ud559\uc2b5\uc758 \uc815\uc758"},{"location":"etc/seminar/learn_to_learn/#_8","text":"\ub2e4\uc2dc \ubb38\uc81c\ub85c \ub3cc\uc544\uac00 \ubcf4\uc790. I __ a boy. 1. am 2. are \uc774 \uc608\uc81c\uc5d0\uc11c \uc6b0\ub9ac\ub294 \ubb34\uc5c7\uc73c\ub85c \ub2f5\uc744 \ub0b4\ub9ac\ub294 \uac78\uae4c? \uc8fc\uc5b4\uc758 \uc778\uce6d\uc5d0 \ub530\ub77c\uc11c \ub3d9\uc0ac\uac00 \ubcc0\ud654\ud55c\ub2e4 \ub77c\ub294 \ub8f0\ub85c \uacb0\uc815\ub41c\ub2e4. \uc774\ub8f0\uc740 \uc5b4\ub5bb\uac8c \ub098\uc62c\uae4c? I \uac00 \ub098\uc628 \ud6c4 am \uc774 \uc790\uc8fc \uc0ac\uc6a9\ub418\ub294\uac00 are \uac00 \uc790\uc8fc \uc0ac\uc6a9\ub418\ub294\uac00 \ub77c\ub294 \ubb38\uc81c\uac00 \ub41c\ub2e4. \uc601\uc5b4 \ubb38\uc7a5\uc5d0\uc11c \ube48\ub3c4\uc218\ub97c \uc870\uc0ac\ud588\ub354\ub2c8 I \uac00 \uc0ac\uc6a9 \ub418\uba74 am \uc774 99\ubc88 are \uac00 1\ubc88 \ub098\uc628\ub2e4\uace0 \ud558\uc790. \uc6b0\ub9ac\uac00 \uc704\uc758 \uc0ac\uc2e4\uc744 \uc54c\uace0 \uc788\ub2e4\uba74 \ubb38\uc81c\ub294 \uc544\ub798\uc640 \uac19\uc774 \ubcc0\uacbd \ud560 \uc218 \uc788\ub2e4. $P(am | I) = 0.99$ $P(are | I) = 0.01$ \uc989 \uc6b0\ub9ac\uac00 \ud559\uc2b5\uc774\ub77c\uace0 \ub9d0\ud558\ub294 \uac83\uc740 \ud2b9\uc815 \uc870\uac74\uc774 \uc8fc\uc5b4\uc84c\uc744\ub54c \uac00\uc7a5 \uac00\ub2a5\uc131\uc774 \ub192\uc740 \uac83\uc744 \uc120\ud0dd\ud55c\ub2e4 \ub77c\uace0 \ud560 \uc218 \uc788\ub2e4. \uadf8\ub7ec\uba74 \uc5b4\ub5bb\uac8c \ud558\uba74 \uc800\ub7f0\uac78 \ud558\ub294 \ubaa8\ub378\uc744 \ub9cc\ub4e4 \uc218 \uc788\uc744\uae4c? \uc5ec\ub7ec \ubc29\ubc95\uc774 \uc788\uaca0\uc9c0\ub9cc \ucd5c\ucd08\uc5d0 \uade0\uc77c\ud558\uac8c \ud655\ub960\uc744 \ubc30\uce58\ud55c\ub2e4. $P(am | I) = 0.50$ $P(are | I) = 0.50$ \uc0c8\ub85c\uc6b4 \ubb38\uc7a5\uc744 \uc77d\uc744\ub54c\ub9c8\ub2e4 \ud574\ub2f9 \ud655\ub960\uc744 $+-1$ \uc529 \ubcc0\ub3d9 \uc2dc\ud0a8\ub2e4. \uc608\ub97c \ub4e4\uc5b4 I am a girl \uc744 \ubd24\ub2e4\uba74 \ud655\ub960\uc744 \ubcc0\ub3d9 \uc2dc\ud0a8\ub2e4. $P(am | I) = 0.51$ $P(are | I) = 0.49$ \uadf8\ub7ec\uba74 \uc6b0\ub9ac\ub294 \uc5b8\uc820\uac00 \uc544\ub798\uc758 \uac12\uc744 \uac19\uac8c \ub418\uace0 \ud574\ub2f9 \ud559\uc2b5\uc774 \uc644\ub8cc\ub41c \uc0c1\ud0dc\ub77c\uace0 \ud560 \uc218 \uc788\ub2e4. $P(am | I) = 0.99$ $P(are | I) = 0.01$ \uc704\uc758 \ubaa8\ub378\uc744 \uac00\uc9c0\uace0 \uc774\uc81c \uc6b0\ub9ac\ub294 \uac00\uc124\ub4e4\uc744 \ud574\ub2f9 \ubaa8\ub378\uc5d0 \ube44\ucd94\uc5b4 \ubcfc\uac83\uc774\ub2e4.","title":"\ud559\uc2b5 \ubaa8\ub378"},{"location":"etc/seminar/learn_to_learn/#_9","text":"","title":"\uc608\uc81c"},{"location":"etc/seminar/learn_to_learn/#_10","text":"\uc704\uc758 \ubaa8\ub378\uc744 \ubb38\uc81c\uc758 \uc815\ub2f5\uc744 \uac00\uc9c0\uace0 \ubaa8\ub378\uc758 \uac12\uc744 \uc218\uc815\ud55c\ub2e4. \uc989 \uc870\uac74\uc5d0 \ub300\ud55c \uc815\ub2f5\uc744 \uc544\ub294\uac83\uc774 \uc911\uc694\ud558\ub2e4.","title":"\ud53c\ub4dc\ubc31"},{"location":"etc/seminar/learn_to_learn/#_11","text":"\ub9cc\uc57d \uc6b0\ub9ac\uac00 I are \ub97c \ub354 \ub9ce\uc774 \ubcf4\uac8c \ub418\uba74 \uc5b4\ub5bb\uac8c \ub420\uae4c? \uc989 \uc798\ubabb\ub41c \ub2f5\uc774 \ub41c\ub2e4. \uc989 \uc815\ud655\ud55c \ud53c\ub4dc\ubc31\uc740 \uc911\uc694\ud558\ub2e4.","title":"\uc798\ubabb\ub41c \ud53c\ub4dc\ubc31"},{"location":"etc/seminar/learn_to_learn/#_12","text":"\ubaa8\ub378\uc758 \ucd5c\uc801 \uac12\uc740 \uc804\ud600 \ubcc0\uacbd\ub418\uc9c0 \uc54a\ub294\ub2e4. \uc989 \uc2dc\uac04 \ub0ad\ube44\ub2e4.","title":"\ub9cc\uc57d \ud53c\ub4dc\ubc31\uc774 \ub2a6\uc73c\uba74 \uc624\uba74 \uc5b4\ub5bb\uac8c \ub420\uae4c?"},{"location":"etc/seminar/learn_to_learn/#_13","text":"\uc6b0\ub9ac\ub294 \ubaa8\ub378\uc758 \uc22b\uc790\ub97c \uac00\uac10 \uc2dc\ud0a8\ub2e4. \ub9cc\uc57d \ubaa8\ub378 \uc790\uccb4\uac00 \uc5c6\ub2e4\uba74 $\\infty$ \uc5d0 \uc5b4\ub5bb\uac12\uc744 \ub354\ud574\ub3c4 \uc798 \ubcc0\ud558\uc9c0 \uc54a\ub294\ub2e4. \uc720\ub2db \uc2dc\uac04\uc548\uc5d0 \ub9ce\uc740 \uc9c0\uc2dd\uc744 \uc2b5\ub4dd\ud558\uace0 \uc2f6\ub2e4.","title":"\ub9cc\uc57d \ucd08\uae30\uac12\uc774 \uc5c6\uc73c\uba74 \uc5b4\ub5bb\uac8c \ub420\uae4c?"},{"location":"etc/vi/etc/","text":"Tips Markdown with Mathjax syntax bug With mermaid function! MathAndLiquid() \"\" Define certain regions \" Block math. Look for \"$$[anything]$$\" \" syn region math start=/\\$\\$/ end=/\\$\\$/ syn region math start=/\\\\\\\\/ end=/\\\\\\\\/ \" inline math. Look for \"$[not $][anything]$\" syn match math_block '\\$[^$].\\{-}\\$' \" Liquid single line. Look for \"{%[anything]%}\" syn match liquid '{%.*%}' \" Liquid multiline. Look for \"{%[anything]%}[anything]{%[anything]%}\" syn region highlight_block start='{% highlight .*%}' end='{%.*%}' \" Fenced code blocks, used in GitHub Flavored Markdown (GFM) syn region highlight_block start='```' end='```' \"\" Actually highlight those regions. hi link math Statement hi link liquid Statement hi link highlight_block Function hi link math_block Function \"\"mermaid syn region mermaid start=/<div class=\\\"mermaid/ end=/<\\/div>/ hi link mermaid Function endfunction \" Call everytime we open a Markdown file autocmd BufRead,BufNewFile,BufEnter *.md,*.markdown call MathAndLiquid() \" https://stsievert.com/blog/2016/01/06/vim-jekyll-mathjax/","title":"Tips"},{"location":"etc/vi/etc/#tips","text":"","title":"Tips"},{"location":"etc/vi/etc/#markdown-with-mathjax-syntax-bug","text":"With mermaid function! MathAndLiquid() \"\" Define certain regions \" Block math. Look for \"$$[anything]$$\" \" syn region math start=/\\$\\$/ end=/\\$\\$/ syn region math start=/\\\\\\\\/ end=/\\\\\\\\/ \" inline math. Look for \"$[not $][anything]$\" syn match math_block '\\$[^$].\\{-}\\$' \" Liquid single line. Look for \"{%[anything]%}\" syn match liquid '{%.*%}' \" Liquid multiline. Look for \"{%[anything]%}[anything]{%[anything]%}\" syn region highlight_block start='{% highlight .*%}' end='{%.*%}' \" Fenced code blocks, used in GitHub Flavored Markdown (GFM) syn region highlight_block start='```' end='```' \"\" Actually highlight those regions. hi link math Statement hi link liquid Statement hi link highlight_block Function hi link math_block Function \"\"mermaid syn region mermaid start=/<div class=\\\"mermaid/ end=/<\\/div>/ hi link mermaid Function endfunction \" Call everytime we open a Markdown file autocmd BufRead,BufNewFile,BufEnter *.md,*.markdown call MathAndLiquid() \" https://stsievert.com/blog/2016/01/06/vim-jekyll-mathjax/","title":"Markdown with Mathjax syntax bug"},{"location":"etc/vi/multi_lang/","text":"Multi language BackGround vim \uc5d0\uc11c \ud55c\uae00 \ubb38\uc11c\ub97c \uc791\uc131\ud558\ub824\uace0 \ud558\uba74 \uc5c4\uccad\ub098\uac8c \ud798\ub4e4\ub2e4. visual mode, command \ub4f1\uc5d0\uc11c \ud55c\uae00\ub85c \ub3d9\uc791\ud558\uc9c0 \uc54a\uae30 \ub54c\ubb38\uc774\ub2e4. mac os vim 8 * iterm2 Goal \uc778\uc124\ud2b8 \ubaa8\ub450\ub97c \ubc97\uc5b4 \ub0a0\ub54c \uc790\ub3d9\uc73c\ub85c \uc601\ubb38\uc73c\ub85c \ubcc0\uacbd\ub418\uac8c \ud574\ubcf4\uc790. \ucee4\ub9e8\ub4dc \ud0a4\ubcf4\ub4dc \ubcc0\ud658 \ud234 \uc124\uce58 https://github.com/vovkasm/input-source-switcher git clone https://github.com/vovkasm/input-source-switcher.git cd input-source-switcher mkdir build && cd build cmake .. make make install issw //\ub85c \ud655\uc778 Pluging \uc124\uce58 https://github.com/lyokha/vim-xkbswitch * \uc800\ub294 \ubc88\ub4e4\uc744 \uad00\ub9ac \ud234\ub85c \uc0ac\uc6a9\ud569\ub2c8\ub2e4. //.vimrc Plugin 'lyokha/vim-xkbswitch' :PluginInstall let g:XkbSwitchEnabled = 1 let g:XkbSwitchLib = '/usr/local/lib/libInputSourceSwitcher.dylib' ESC \ub300\uc2e0 Ctrl+c \ub97c \uc4f0\ub294 \uc720\uc800\ub97c \uc704\ud55c \ud301 .vimrc \uc5d0 \uc544\ub798 \uc124\uc815 \ucd94\uac00. ino <C-C> <Esc>","title":"Multi language"},{"location":"etc/vi/multi_lang/#multi-language","text":"","title":"Multi language"},{"location":"etc/vi/multi_lang/#background","text":"vim \uc5d0\uc11c \ud55c\uae00 \ubb38\uc11c\ub97c \uc791\uc131\ud558\ub824\uace0 \ud558\uba74 \uc5c4\uccad\ub098\uac8c \ud798\ub4e4\ub2e4. visual mode, command \ub4f1\uc5d0\uc11c \ud55c\uae00\ub85c \ub3d9\uc791\ud558\uc9c0 \uc54a\uae30 \ub54c\ubb38\uc774\ub2e4. mac os vim 8 * iterm2","title":"BackGround"},{"location":"etc/vi/multi_lang/#goal","text":"\uc778\uc124\ud2b8 \ubaa8\ub450\ub97c \ubc97\uc5b4 \ub0a0\ub54c \uc790\ub3d9\uc73c\ub85c \uc601\ubb38\uc73c\ub85c \ubcc0\uacbd\ub418\uac8c \ud574\ubcf4\uc790.","title":"Goal"},{"location":"etc/vi/multi_lang/#_1","text":"https://github.com/vovkasm/input-source-switcher git clone https://github.com/vovkasm/input-source-switcher.git cd input-source-switcher mkdir build && cd build cmake .. make make install issw //\ub85c \ud655\uc778","title":"\ucee4\ub9e8\ub4dc \ud0a4\ubcf4\ub4dc \ubcc0\ud658 \ud234 \uc124\uce58"},{"location":"etc/vi/multi_lang/#pluging","text":"https://github.com/lyokha/vim-xkbswitch * \uc800\ub294 \ubc88\ub4e4\uc744 \uad00\ub9ac \ud234\ub85c \uc0ac\uc6a9\ud569\ub2c8\ub2e4. //.vimrc Plugin 'lyokha/vim-xkbswitch' :PluginInstall let g:XkbSwitchEnabled = 1 let g:XkbSwitchLib = '/usr/local/lib/libInputSourceSwitcher.dylib'","title":"Pluging \uc124\uce58"},{"location":"etc/vi/multi_lang/#esc-ctrlc","text":".vimrc \uc5d0 \uc544\ub798 \uc124\uc815 \ucd94\uac00. ino <C-C> <Esc>","title":"ESC \ub300\uc2e0 Ctrl+c \ub97c \uc4f0\ub294 \uc720\uc800\ub97c \uc704\ud55c \ud301"},{"location":"framework/grpc/introduction/","text":"Introduction gRPC (Google Remote Procedure Calls) is an open source remote procedure call. Why MSA\ub97c \ud558\ub2e4 \ubcf4\uba74 \uc11c\ube44\uc2a4 \uac04 \ud1b5\uc2e0\uc774 \uc790\uc8fc \uc77c\uc5b4 \ub098\uac8c \ub41c\ub2e4. \uc11c\ube44\uc2a4 \uac04 \ud1b5\uc2e0\uc740 \uc544\ub798\uc640 \uac19\uc740 \uad6c\uc870\ub97c \uac19\ub294\ub2e4. \ud1b5\uc2e0 \uba85\uc138\uac00 \uc874\uc7ac \ud558\uace0 \ud574\ub2f9 \uba85\uc138\ub97c \uac01 \uc5b8\uc5b4\uc5d0 \ub9de\ub294 serialize/ deserialize \ucf54\ub4dc\ub97c \uc791\uc131\ud55c\ub2e4. network \ub97c \uc0ac\uc6a9 \ud574\uc57c \ud558\ub294 \uacbd\uc6b0 \ud2b9\uc815 \ud504\ub85c\ud1a0\ucf5c\ub85c \uad6c\ud604\ud55c\ub2e4. \uc790\ub3d9\ud654 \ud574\ubcf4\uc790. \ud1b5\uc2e0 \uba85\uc138 = protobuf.proto \uac01\uc5b8\uc5b4 \ucf54\ub4dc = protoc network \uac04 \ud638\ucd9c = http2 Grpc \ub780 \uc704\uc758 \uae30\ub2a5\uc744 \uc790\ub3d9\ud654 \ud55c \uad6c\ud604\uccb4\uc774\ub2e4. Example protobuff Components Uses HTTP/2 for transport. Protocol Buffers as the interface description language. Overview Define // The greeter service definition. service Greeter { // Sends a greeting rpc SayHello (HelloRequest) returns (HelloResponse) {} } // The request message containing the user's name. message HelloRequest { string name = 1; } // The response message containing the greetings message HelloResponse { string message = 1; } Methods Unary RPC rpc SayHello(HelloRequest) return (HelloResponse) {} sequenceDiagram client ->>+ stub : sayHello(\"hi\") stub ->> server : metadata opt if need server -->> stub : metadata end stub ->>+ server : request server -->>- stub : respond, status stub -->>- client : return respond Server streaming RPC rpc LotsOfReplies(HelloRequest) return (stream HelloResponse) {} sequenceDiagram client ->>+ server : request server -->> client : respond 1 server -->> client : respond * n server -->>- client : status Client streaming RPC rpc LotsOfRequest(stream HelloRequest) return (HelloResponse) {} The server sends back a single response, typically but not necessarily after it has received all the client\u2019s requests sequenceDiagram client ->>+ server : request 1 client ->> server : request * n server -->>- client : respond Bidirectional streaming RPC rpc BidHello(steam HelloRequest) return (stream HelloResponse) {} The client and server can read and write any order Features Authentication Bidirectional streaming and flow control Blocking or nonblocking bindings Cancellation and timeout Link gRPC-design-and-implementation","title":"Introduction"},{"location":"framework/grpc/introduction/#introduction","text":"gRPC (Google Remote Procedure Calls) is an open source remote procedure call.","title":"Introduction"},{"location":"framework/grpc/introduction/#why","text":"MSA\ub97c \ud558\ub2e4 \ubcf4\uba74 \uc11c\ube44\uc2a4 \uac04 \ud1b5\uc2e0\uc774 \uc790\uc8fc \uc77c\uc5b4 \ub098\uac8c \ub41c\ub2e4.","title":"Why"},{"location":"framework/grpc/introduction/#_1","text":"\ud1b5\uc2e0 \uba85\uc138\uac00 \uc874\uc7ac \ud558\uace0 \ud574\ub2f9 \uba85\uc138\ub97c \uac01 \uc5b8\uc5b4\uc5d0 \ub9de\ub294 serialize/ deserialize \ucf54\ub4dc\ub97c \uc791\uc131\ud55c\ub2e4. network \ub97c \uc0ac\uc6a9 \ud574\uc57c \ud558\ub294 \uacbd\uc6b0 \ud2b9\uc815 \ud504\ub85c\ud1a0\ucf5c\ub85c \uad6c\ud604\ud55c\ub2e4.","title":"\uc11c\ube44\uc2a4 \uac04 \ud1b5\uc2e0\uc740 \uc544\ub798\uc640 \uac19\uc740 \uad6c\uc870\ub97c \uac19\ub294\ub2e4."},{"location":"framework/grpc/introduction/#_2","text":"\ud1b5\uc2e0 \uba85\uc138 = protobuf.proto \uac01\uc5b8\uc5b4 \ucf54\ub4dc = protoc network \uac04 \ud638\ucd9c = http2","title":"\uc790\ub3d9\ud654 \ud574\ubcf4\uc790."},{"location":"framework/grpc/introduction/#grpc","text":"\uc704\uc758 \uae30\ub2a5\uc744 \uc790\ub3d9\ud654 \ud55c \uad6c\ud604\uccb4\uc774\ub2e4.","title":"Grpc \ub780"},{"location":"framework/grpc/introduction/#example","text":"protobuff","title":"Example"},{"location":"framework/grpc/introduction/#components","text":"Uses HTTP/2 for transport. Protocol Buffers as the interface description language.","title":"Components"},{"location":"framework/grpc/introduction/#overview","text":"","title":"Overview"},{"location":"framework/grpc/introduction/#define","text":"// The greeter service definition. service Greeter { // Sends a greeting rpc SayHello (HelloRequest) returns (HelloResponse) {} } // The request message containing the user's name. message HelloRequest { string name = 1; } // The response message containing the greetings message HelloResponse { string message = 1; }","title":"Define"},{"location":"framework/grpc/introduction/#methods","text":"","title":"Methods"},{"location":"framework/grpc/introduction/#unary-rpc","text":"rpc SayHello(HelloRequest) return (HelloResponse) {} sequenceDiagram client ->>+ stub : sayHello(\"hi\") stub ->> server : metadata opt if need server -->> stub : metadata end stub ->>+ server : request server -->>- stub : respond, status stub -->>- client : return respond","title":"Unary RPC"},{"location":"framework/grpc/introduction/#server-streaming-rpc","text":"rpc LotsOfReplies(HelloRequest) return (stream HelloResponse) {} sequenceDiagram client ->>+ server : request server -->> client : respond 1 server -->> client : respond * n server -->>- client : status","title":"Server streaming RPC"},{"location":"framework/grpc/introduction/#client-streaming-rpc","text":"rpc LotsOfRequest(stream HelloRequest) return (HelloResponse) {} The server sends back a single response, typically but not necessarily after it has received all the client\u2019s requests sequenceDiagram client ->>+ server : request 1 client ->> server : request * n server -->>- client : respond","title":"Client streaming RPC"},{"location":"framework/grpc/introduction/#bidirectional-streaming-rpc","text":"rpc BidHello(steam HelloRequest) return (stream HelloResponse) {} The client and server can read and write any order","title":"Bidirectional streaming RPC"},{"location":"framework/grpc/introduction/#features","text":"Authentication Bidirectional streaming and flow control Blocking or nonblocking bindings Cancellation and timeout","title":"Features"},{"location":"framework/grpc/introduction/#link","text":"gRPC-design-and-implementation","title":"Link"},{"location":"framework/grpc/protocolbuffer/","text":"Protocol Buffers Protocol buffers are method of serializing structured data. Goal Want to use lingua franca in CS. Simplicity and performance. In particular, it was designed to be smaller and faster than XML. Components Interface description language. IDL compiler : Program that generate source code from the description. HowTo Define structure at proto definition file (.proto) Compile it with protoc. Use generated file. Example $vi test.proto //define $protoc test.proto //compile to generate code $ls test.pb.cc //for cpp test.pb.h HowTo Cpp tutorial proto proto.h code Caution Prefer use only optional and repeated.","title":"Protocol Buffers"},{"location":"framework/grpc/protocolbuffer/#protocol-buffers","text":"Protocol buffers are method of serializing structured data.","title":"Protocol Buffers"},{"location":"framework/grpc/protocolbuffer/#goal","text":"Want to use lingua franca in CS. Simplicity and performance. In particular, it was designed to be smaller and faster than XML.","title":"Goal"},{"location":"framework/grpc/protocolbuffer/#components","text":"Interface description language. IDL compiler : Program that generate source code from the description.","title":"Components"},{"location":"framework/grpc/protocolbuffer/#howto","text":"Define structure at proto definition file (.proto) Compile it with protoc. Use generated file.","title":"HowTo"},{"location":"framework/grpc/protocolbuffer/#example","text":"$vi test.proto //define $protoc test.proto //compile to generate code $ls test.pb.cc //for cpp test.pb.h","title":"Example"},{"location":"framework/grpc/protocolbuffer/#howto_1","text":"Cpp tutorial proto proto.h code","title":"HowTo"},{"location":"framework/grpc/protocolbuffer/#caution","text":"Prefer use only optional and repeated.","title":"Caution"},{"location":"framework/http2/introduction/","text":"Introduction HTTP/2 is a major revision of HTTP network protocol use by the World Wide Web. It was derived from the SPDY(pronounced \"speedy\") protocol. Goals Create a negotiation mechanism that allows clients and servers to elect to use protocol. Maintain high-level compatibility with HTTP 1.1 Decrease latency to improve page load speed. Header data compression. HTTP/2 Server push. Pipelineing of requests. Multiplexing multiple request over a single TCP connection. Difference from HTTP 1.1 Same as HTTP1.1 Methods. Status codes. Header fields. URIS Different How the data is framed. How the data is transported between the client and server. HTTP/2 Protocol Overview HTTP/2 provides an optimized transport for HTTP semantics. HTTP/2 support all of core features of HTTP/1.1 but aims to be more efficient in several ways. The basic protocol unit in HTTP/2 is a frame. Each frame type servers different purpose. For Example HEADERS, and DATA frames form the basis of HTTP request and response. Other frame type like SETTING, WINDOW_UPDATE, PUSH_NOTIFICATION are used in support of other HTTP/2 features. Multiplexing of requests is achieved by having each HTTP request/response exchange associated with its own stream. Streams are largely independent of each other(Streams are identified by an integer.) Flow control and prioritization ensure that it is possible to efficiently use multiplexed streams. Flow control helps to ensure that only data that can be used by receiver is transmitted. Prioritization ensures that limited resources can be directed to the most important stream first. (Priority unit is a stream.) HTTP/2 adds a new interaction mode whereby a server can push response to a client. Server push allows a server to speculatively send data to a client that the server anticipate the client will need, trading off some network usage against a potential latency gain. The server dose this by synthesizing a request, which it sends as a PUSH_PROMISE frame. The server is then able to send a response to the synthetic request on a separate stream. Because HTTP header fields used in a connection can contain large amount of redundant data, frames that contain them are compressed. This has especially advantageous impact upon request sizes in the common case, allowing many request to be compressed into one packet. from RFC7540 Limitation HTTP/2 allows a server to push responses (along with corresponding \"promised\" requests) to a client in association with a previous client-initiated request. HTTP/2 server push is made for loading webpage as fast as possible. sequenceDiagram Server ->>+ Client : PUSH_PROMISE (request) Client -->>- Server : void Server ->>+ Client : response (response to above reqeust) Client -->>- Server : void SPDY SPDY is network protocol. Goal Reduce webpage load latency. Improve web security. HowTo Compression. Multiplexing. prioritization.","title":"Introduction"},{"location":"framework/http2/introduction/#introduction","text":"HTTP/2 is a major revision of HTTP network protocol use by the World Wide Web. It was derived from the SPDY(pronounced \"speedy\") protocol.","title":"Introduction"},{"location":"framework/http2/introduction/#goals","text":"Create a negotiation mechanism that allows clients and servers to elect to use protocol. Maintain high-level compatibility with HTTP 1.1 Decrease latency to improve page load speed. Header data compression. HTTP/2 Server push. Pipelineing of requests. Multiplexing multiple request over a single TCP connection.","title":"Goals"},{"location":"framework/http2/introduction/#difference-from-http-11","text":"","title":"Difference from HTTP 1.1"},{"location":"framework/http2/introduction/#same-as-http11","text":"Methods. Status codes. Header fields. URIS","title":"Same as HTTP1.1"},{"location":"framework/http2/introduction/#different","text":"How the data is framed. How the data is transported between the client and server.","title":"Different"},{"location":"framework/http2/introduction/#http2-protocol-overview","text":"HTTP/2 provides an optimized transport for HTTP semantics. HTTP/2 support all of core features of HTTP/1.1 but aims to be more efficient in several ways. The basic protocol unit in HTTP/2 is a frame. Each frame type servers different purpose. For Example HEADERS, and DATA frames form the basis of HTTP request and response. Other frame type like SETTING, WINDOW_UPDATE, PUSH_NOTIFICATION are used in support of other HTTP/2 features. Multiplexing of requests is achieved by having each HTTP request/response exchange associated with its own stream. Streams are largely independent of each other(Streams are identified by an integer.) Flow control and prioritization ensure that it is possible to efficiently use multiplexed streams. Flow control helps to ensure that only data that can be used by receiver is transmitted. Prioritization ensures that limited resources can be directed to the most important stream first. (Priority unit is a stream.) HTTP/2 adds a new interaction mode whereby a server can push response to a client. Server push allows a server to speculatively send data to a client that the server anticipate the client will need, trading off some network usage against a potential latency gain. The server dose this by synthesizing a request, which it sends as a PUSH_PROMISE frame. The server is then able to send a response to the synthetic request on a separate stream. Because HTTP header fields used in a connection can contain large amount of redundant data, frames that contain them are compressed. This has especially advantageous impact upon request sizes in the common case, allowing many request to be compressed into one packet. from RFC7540","title":"HTTP/2 Protocol Overview"},{"location":"framework/http2/introduction/#limitation","text":"HTTP/2 allows a server to push responses (along with corresponding \"promised\" requests) to a client in association with a previous client-initiated request. HTTP/2 server push is made for loading webpage as fast as possible. sequenceDiagram Server ->>+ Client : PUSH_PROMISE (request) Client -->>- Server : void Server ->>+ Client : response (response to above reqeust) Client -->>- Server : void","title":"Limitation"},{"location":"framework/http2/introduction/#spdy","text":"SPDY is network protocol.","title":"SPDY"},{"location":"framework/http2/introduction/#goal","text":"Reduce webpage load latency. Improve web security.","title":"Goal"},{"location":"framework/http2/introduction/#howto","text":"Compression. Multiplexing. prioritization.","title":"HowTo"},{"location":"framework/react/reactive_introduction/","text":"Introduction to Reactive Programming Reactor 3 is a library built around Reactive streams specification. Why To make asynchronous code more readable and maintainable. Declarative paradigm. Build asynchronous processing pipeline. It is event-based model where data is pushed to the consumer, as it become available. Deal with asynchronous sequences of events. Reactive Stream Reactive Stream Idea sequenceDiagram Publisher ->>+ Subscriber : push event Subscriber -->>- Publisher : feedback Operator Applying an operator returns a new intermediate Publisher sequenceDiagram Publisher ->>+ Operator_Publiser : push event opt Operator Operator_Publiser ->>+ Subscriber : push event Subscriber -->>- Operator_Publiser : void end Operator_Publiser -->>- Publisher : feedback Flux Flux is a stream which can emit 0..N elements: - implements Publisher - Flux Flux<String> fl = Flux.just(\"a\", \"b\", \"c\"); Mono Mono is a stream of 0..1 elements: implements Publisher Mono Mono<String> mn = Mono.just(\"hello\");","title":"Introduction to Reactive Programming"},{"location":"framework/react/reactive_introduction/#introduction-to-reactive-programming","text":"Reactor 3 is a library built around Reactive streams specification.","title":"Introduction to Reactive Programming"},{"location":"framework/react/reactive_introduction/#why","text":"To make asynchronous code more readable and maintainable. Declarative paradigm. Build asynchronous processing pipeline. It is event-based model where data is pushed to the consumer, as it become available. Deal with asynchronous sequences of events.","title":"Why"},{"location":"framework/react/reactive_introduction/#reactive-stream","text":"Reactive Stream","title":"Reactive Stream"},{"location":"framework/react/reactive_introduction/#idea","text":"sequenceDiagram Publisher ->>+ Subscriber : push event Subscriber -->>- Publisher : feedback","title":"Idea"},{"location":"framework/react/reactive_introduction/#operator","text":"Applying an operator returns a new intermediate Publisher sequenceDiagram Publisher ->>+ Operator_Publiser : push event opt Operator Operator_Publiser ->>+ Subscriber : push event Subscriber -->>- Operator_Publiser : void end Operator_Publiser -->>- Publisher : feedback","title":"Operator"},{"location":"framework/react/reactive_introduction/#flux","text":"Flux is a stream which can emit 0..N elements: - implements Publisher - Flux Flux<String> fl = Flux.just(\"a\", \"b\", \"c\");","title":"Flux"},{"location":"framework/react/reactive_introduction/#mono","text":"Mono is a stream of 0..1 elements: implements Publisher Mono Mono<String> mn = Mono.just(\"hello\");","title":"Mono"},{"location":"framework/react/reactive_stream_introduction/","text":"Reactive streams Goal Process a potentially unbounded number of elements in sequences, asynchronously passing elements between components, with mandatory non-blocking back pressure. Components The API: specification. The Technology Comparability Kit: is a test suit for conformance testing. API Component Publisher Subscriber Subscription Processor Publisher Provider of a number of sequenced elements, publishing them according the demand received from its Subscriber public interface Publisher<T> { public void subscribe(Subscriber<? super T> s); } Subscriber public interface Subscriber<T> { public void onSubscrive(Subscription s); public void onNext(T t); public void onError(Throwable t); public void onComplete(); } Subscription It is shared by exactly one Publisher and one Subscriber for the purpose of mediating the data exchange between this pair. public interface Subscription { public void request(long n); public void cancel(); } Processor A Processor represents a processing stage\u2014which is both a Subscriber and a Publisher and MUST obey the contracts of both. public interface Processor<T, R> extends Subscriber<T>, Publisher<R> { } Subscriber controlled queue bounds the total number of elements requested: P the number of elements that have been processed: N Then the maximum number of elements that may arrive (until more demand is signaled to the Publisher) is P - N. In the case that the subscriber also knows the number of elements B in its input buffer then this bound can be refined to P - B - N.","title":"Reactive streams"},{"location":"framework/react/reactive_stream_introduction/#reactive-streams","text":"","title":"Reactive streams"},{"location":"framework/react/reactive_stream_introduction/#goal","text":"Process a potentially unbounded number of elements in sequences, asynchronously passing elements between components, with mandatory non-blocking back pressure.","title":"Goal"},{"location":"framework/react/reactive_stream_introduction/#components","text":"The API: specification. The Technology Comparability Kit: is a test suit for conformance testing.","title":"Components"},{"location":"framework/react/reactive_stream_introduction/#api-component","text":"Publisher Subscriber Subscription Processor","title":"API Component"},{"location":"framework/react/reactive_stream_introduction/#publisher","text":"Provider of a number of sequenced elements, publishing them according the demand received from its Subscriber public interface Publisher<T> { public void subscribe(Subscriber<? super T> s); }","title":"Publisher"},{"location":"framework/react/reactive_stream_introduction/#subscriber","text":"public interface Subscriber<T> { public void onSubscrive(Subscription s); public void onNext(T t); public void onError(Throwable t); public void onComplete(); }","title":"Subscriber"},{"location":"framework/react/reactive_stream_introduction/#subscription","text":"It is shared by exactly one Publisher and one Subscriber for the purpose of mediating the data exchange between this pair. public interface Subscription { public void request(long n); public void cancel(); }","title":"Subscription"},{"location":"framework/react/reactive_stream_introduction/#processor","text":"A Processor represents a processing stage\u2014which is both a Subscriber and a Publisher and MUST obey the contracts of both. public interface Processor<T, R> extends Subscriber<T>, Publisher<R> { }","title":"Processor"},{"location":"framework/react/reactive_stream_introduction/#subscriber-controlled-queue-bounds","text":"the total number of elements requested: P the number of elements that have been processed: N Then the maximum number of elements that may arrive (until more demand is signaled to the Publisher) is P - N. In the case that the subscriber also knows the number of elements B in its input buffer then this bound can be refined to P - B - N.","title":"Subscriber controlled queue bounds"},{"location":"framework/spring/spring_overview/","text":"Spring overview. Spring \uc740 \uc6f9\uc11c\ubc84 \ud504\ub808\uc784\uc6cc\ud06c\ub85c \uc2dc\uc791\ud588\uc2b5\ub2c8\ub2e4. \uc790\ubc14\uc758 \uc720\uba85 \uc11c\ubc84\uad70. Servlet \uc740 \uae30\ubcf8\uc801\uc73c\ub85c \ube14\ub77d\ud0b9 \uc720\uc800\uac00 \uc624\uba74 \uc720\uc800\ub2f9 \uc4f0\ub808\ub4dc\ub97c \ud558\ub098\uc529 \ud560\ub2f9. I/O \ub4f1 \ube44\ub3d9\uae30 \ucf5c\uc774 \ubc1c\uc0dd\ub418\uba74 \uc720\uc800 \uc4f0\ub808\ub4dc\ub97c \ube14\ub77d Servlet interface void do[Method](HttpServletRequest req, HttpServletResponse resp) void doGet(HttpServletRequest req, HttpServletResponse resp) \uc6f9\uc11c\ubc84 \uae30\ubcf8 \uc720\uc800\uc758 \ud2b9\uc815 \uc694\uccad\uc744 \ucc98\ub9ac\ud55c\ub2e4. \ub77c\uc6b0\ud130 + \ud578\ub4e4\ub7ec Spring DispatherHandler DispatherHandler == \ub77c\uc6b0\ud130 handler().method(url, criteria, handler) route().GET(\"/person/{id}\", accept(APPLICATION_JSON), handler::getPerson) url, handler mapping. \uc5ec\ub7ec\uac00\uc9c0 \uc870\uac74\uc5d0 \ub530\ub77c \ub9f5\ud551 \uac00\ub2a5. Handler \uc720\uc800 \ub9ac\ud018\uc2a4\ud2b8\ub97c \ucc98\ub9ac\ud574 \ub9ac\uc2a4\ud310\uc2a4\ub97c \uc791\uc131 \ud6c4 \ub9ac\ud134 public class WebHandler { public String getPerson(ServerRequest request) { return \"Hello\" } } Service \ube44\uc9c0\ub2c8\uc2a4 \ub85c\uc9c1\uc744 \uc218\ud589 public class Service { public String getPersonName(int id) { return JDBC.selectName(id); } } Sequence flow sequenceDiagram User ->>+ Servlet : GET /person/1 Servlet ->>+ DispatherHandler : Create new thread DispatherHandler ->>+ WebHandler : handler::getPerson(req) WebHandler ->>+ Service : getPersonName(id) Service ->>+ DB : select id from person where.. DB -->>- Service : record Service -->>- WebHandler : 1 WebHandler -->>- DispatherHandler : resposne.body(1) DispatherHandler -->>- Servlet : response.body(1) Servlet -->>- User : response.body(1) , return thread to thread pool 0. \uc720\uc800\uac00 person 1\uc5d0 \ub300\ud574 \uc694\uccad 0. Servlet\uc774 \uc720\uc800 request \uc5d0 new Thread \uc0dd\uc131(or \uc4f0\ub808\ub4dc \ud480\uc5d0 \uc694\uccad) 0. DispatherHandler \uac00 \uc720\uc800\uc758 \uc694\uccad\uc744 \ubcf4\uace0 Webhandler \uacb0\uc815 0. WebHandler\uac00 \ud574\ub2f9 \uc694\uccad\uc744 \ud2b9\uc815 \uc11c\ube44\uc2a4\ub85c \uc694\uccad 0. \uc11c\ube44\uc2a4\uac00 \ud574\ub2f9 \uc791\uc5c5\uc744 \ucc98\ub9ac 0. WebHandler \uac00 response \uc791\uc131 0. \uc720\uc800\uc5d0\uac8c response \ub9ac\ud134 0. Servlet \uc774 Thread\ub97c Thread pool \ub85c \ub9ac\ud134","title":"Spring overview."},{"location":"framework/spring/spring_overview/#spring-overview","text":"Spring \uc740 \uc6f9\uc11c\ubc84 \ud504\ub808\uc784\uc6cc\ud06c\ub85c \uc2dc\uc791\ud588\uc2b5\ub2c8\ub2e4.","title":"Spring overview."},{"location":"framework/spring/spring_overview/#_1","text":"Servlet \uc740 \uae30\ubcf8\uc801\uc73c\ub85c \ube14\ub77d\ud0b9 \uc720\uc800\uac00 \uc624\uba74 \uc720\uc800\ub2f9 \uc4f0\ub808\ub4dc\ub97c \ud558\ub098\uc529 \ud560\ub2f9. I/O \ub4f1 \ube44\ub3d9\uae30 \ucf5c\uc774 \ubc1c\uc0dd\ub418\uba74 \uc720\uc800 \uc4f0\ub808\ub4dc\ub97c \ube14\ub77d","title":"\uc790\ubc14\uc758 \uc720\uba85 \uc11c\ubc84\uad70."},{"location":"framework/spring/spring_overview/#servlet-interface","text":"void do[Method](HttpServletRequest req, HttpServletResponse resp) void doGet(HttpServletRequest req, HttpServletResponse resp)","title":"Servlet interface"},{"location":"framework/spring/spring_overview/#_2","text":"\uc720\uc800\uc758 \ud2b9\uc815 \uc694\uccad\uc744 \ucc98\ub9ac\ud55c\ub2e4. \ub77c\uc6b0\ud130 + \ud578\ub4e4\ub7ec","title":"\uc6f9\uc11c\ubc84 \uae30\ubcf8"},{"location":"framework/spring/spring_overview/#spring","text":"","title":"Spring"},{"location":"framework/spring/spring_overview/#dispatherhandler","text":"DispatherHandler == \ub77c\uc6b0\ud130 handler().method(url, criteria, handler) route().GET(\"/person/{id}\", accept(APPLICATION_JSON), handler::getPerson) url, handler mapping. \uc5ec\ub7ec\uac00\uc9c0 \uc870\uac74\uc5d0 \ub530\ub77c \ub9f5\ud551 \uac00\ub2a5.","title":"DispatherHandler"},{"location":"framework/spring/spring_overview/#handler","text":"\uc720\uc800 \ub9ac\ud018\uc2a4\ud2b8\ub97c \ucc98\ub9ac\ud574 \ub9ac\uc2a4\ud310\uc2a4\ub97c \uc791\uc131 \ud6c4 \ub9ac\ud134 public class WebHandler { public String getPerson(ServerRequest request) { return \"Hello\" } }","title":"Handler"},{"location":"framework/spring/spring_overview/#service","text":"\ube44\uc9c0\ub2c8\uc2a4 \ub85c\uc9c1\uc744 \uc218\ud589 public class Service { public String getPersonName(int id) { return JDBC.selectName(id); } }","title":"Service"},{"location":"framework/spring/spring_overview/#sequence-flow","text":"sequenceDiagram User ->>+ Servlet : GET /person/1 Servlet ->>+ DispatherHandler : Create new thread DispatherHandler ->>+ WebHandler : handler::getPerson(req) WebHandler ->>+ Service : getPersonName(id) Service ->>+ DB : select id from person where.. DB -->>- Service : record Service -->>- WebHandler : 1 WebHandler -->>- DispatherHandler : resposne.body(1) DispatherHandler -->>- Servlet : response.body(1) Servlet -->>- User : response.body(1) , return thread to thread pool 0. \uc720\uc800\uac00 person 1\uc5d0 \ub300\ud574 \uc694\uccad 0. Servlet\uc774 \uc720\uc800 request \uc5d0 new Thread \uc0dd\uc131(or \uc4f0\ub808\ub4dc \ud480\uc5d0 \uc694\uccad) 0. DispatherHandler \uac00 \uc720\uc800\uc758 \uc694\uccad\uc744 \ubcf4\uace0 Webhandler \uacb0\uc815 0. WebHandler\uac00 \ud574\ub2f9 \uc694\uccad\uc744 \ud2b9\uc815 \uc11c\ube44\uc2a4\ub85c \uc694\uccad 0. \uc11c\ube44\uc2a4\uac00 \ud574\ub2f9 \uc791\uc5c5\uc744 \ucc98\ub9ac 0. WebHandler \uac00 response \uc791\uc131 0. \uc720\uc800\uc5d0\uac8c response \ub9ac\ud134 0. Servlet \uc774 Thread\ub97c Thread pool \ub85c \ub9ac\ud134","title":"Sequence flow"},{"location":"framework/spring/spring_webflux/","text":"Spring WebFlux. \ubc30\uacbd \uc5b4\ub290 \uc21c\uac04 \ube44\ub3d9\uae30\uac00 \uc720\ud589\ud558\uac8c \ub418\uace0 \uc0b4\uc544\ub0a8\uae30 \uc704\ud574\uc11c\ub294 \uc720\ud589\uc744 \ucad3\uc544 \uac00\uc57c \ud569\ub2c8\ub2e4.[\ub1cc\ud53c\uc15c] Servlet 3.1 \ubd80\ud130 \ube44\ub3d9\uae30 \uc9c0\uc6d0. \ube44\ub3d9\uae30\uac00 \uc720\ud589 \uc774\ub354\ub77c. \ud568\uc218\ud615 \uc5b8\uc5b4\uac00 \uc720\ud589\uc774\ub354\ub77c. \ube44\ub3d9\uae30 + \ud568\uc218\ud615\uc5b8\uc5b4 + java + spring = WebFlux Performance \ub354 \ube68\ub77c\uc9c0\uc9c0 \uc54a\ub294\ub2e4. \uc801\uc740 \uc218\uc758 thread \uc640 \uba54\ubaa8\ub9ac\ub97c \uc0ac\uc6a9\ud558\uae30 \ub54c\ubb38\uc5d0 \uc608\uce21 \uac00\ub2a5\ud558\uac8c \ud655\uc7a5 \ud560 \uc218 \uc788\ub2e4. Reactive reactive programming is a declarative programming paradigm concerned with data streams and the propagation of change Wiki \uc120\uc5b8\uc801\uc774\uace0 \ub370\uc774\ud130 \uc2a4\ud2b8\ub9bc\uc744 \uc0ac\uc6a9\ud574 \ubcc0\ud654\uac00 \uc804\ud30c \ub418\ub294\ub300 \uad00\uc2ec\uc744 \ub454 \ud504\ub85c\uadf8\ub798\uc784 \ud328\ub7ec\ub2e4\uc784. b = 1 c = 1 a = b + c b = 2 print(a) //imperactive => 2 //reactive =>3 Reactive stream \ub370\uc774\ud130\uc758 \uc2a4\ud2b8\ub9bc \ud45c\ud604 \ubc29\uc2dd \uaddc\uc57d ReativeGit \ube44\ub3d9\uae30 \uc2a4\ud2b8\ub9bc\uc758\ub85c \ub370\uc774\ud130\ub97c \ucd94\uc0c1\ud654 \ud558\uba74 \uac00\uc7a5 \ud070 \ubb38\uc81c\ub294 consumer \uac00 producer \uc758 \uc18d\ub3c4\ub97c \ub530\ub77c\uc624\uc9c0 \ubabb\ud560\ub54c \ubc1c\uc0dd consumer \uac00 producer \uc758 \uc18d\ub3c4\ub97c \uc870\uc808 \ud560 \uc218 \uc788\uc74c Definition process a potentially unbounded number of elements in sequence, asynchronously passing elements between components, with mandatory non-blocking backpressure. None-blocking asynchronous I/O (also non-sequential I/O) is a form of input/output processing that permits other processing to continue before the transmission has finished. non-blocking web stack to handle concurrency with a small number of threads and scale with fewer hardware resources Functional Treats computation as the evaluation of mathematical functions and avoids changing-state and mutable data. It is a declarative programming paradigm, which means programming is done with expressions or declarations WebFlux None-blocking Reactive (stream) Functional Spring Sequece flow sequenceDiagram User ->>+ EventLoop : GET /person/1 EventLoop ->> DispatherHandler : server thread DispatherHandler ->> WebHandler : handler::getPerson(req) WebHandler ->> Service : getPersonName(id) Service ->> DB : select id from person where.. DB -->> EventLoop : return server thread EventLoop ->> DB : server thread DB -->> Service : record Service -->> WebHandler : 1 WebHandler -->> DispatherHandler : resposne.body(1) DispatherHandler -->> EventLoop : resposne.body(1) EventLoop -->>- User : response.body(1) Async Servlet 3.1+ Client sends a request Servlet container allocates a thread and invokes a servlet in it The servlet calls request.startAsync(), saves the AsyncContext, and returns The container thread is exited all the way but the response remains open Some other thread uses the saved AsyncContext to complete the response Client receives the response Concurrency Model (thread model) WebFlux","title":"Spring WebFlux."},{"location":"framework/spring/spring_webflux/#spring-webflux","text":"","title":"Spring WebFlux."},{"location":"framework/spring/spring_webflux/#_1","text":"\uc5b4\ub290 \uc21c\uac04 \ube44\ub3d9\uae30\uac00 \uc720\ud589\ud558\uac8c \ub418\uace0 \uc0b4\uc544\ub0a8\uae30 \uc704\ud574\uc11c\ub294 \uc720\ud589\uc744 \ucad3\uc544 \uac00\uc57c \ud569\ub2c8\ub2e4.[\ub1cc\ud53c\uc15c] Servlet 3.1 \ubd80\ud130 \ube44\ub3d9\uae30 \uc9c0\uc6d0. \ube44\ub3d9\uae30\uac00 \uc720\ud589 \uc774\ub354\ub77c. \ud568\uc218\ud615 \uc5b8\uc5b4\uac00 \uc720\ud589\uc774\ub354\ub77c. \ube44\ub3d9\uae30 + \ud568\uc218\ud615\uc5b8\uc5b4 + java + spring = WebFlux","title":"\ubc30\uacbd"},{"location":"framework/spring/spring_webflux/#performance","text":"\ub354 \ube68\ub77c\uc9c0\uc9c0 \uc54a\ub294\ub2e4. \uc801\uc740 \uc218\uc758 thread \uc640 \uba54\ubaa8\ub9ac\ub97c \uc0ac\uc6a9\ud558\uae30 \ub54c\ubb38\uc5d0 \uc608\uce21 \uac00\ub2a5\ud558\uac8c \ud655\uc7a5 \ud560 \uc218 \uc788\ub2e4.","title":"Performance"},{"location":"framework/spring/spring_webflux/#reactive","text":"reactive programming is a declarative programming paradigm concerned with data streams and the propagation of change Wiki \uc120\uc5b8\uc801\uc774\uace0 \ub370\uc774\ud130 \uc2a4\ud2b8\ub9bc\uc744 \uc0ac\uc6a9\ud574 \ubcc0\ud654\uac00 \uc804\ud30c \ub418\ub294\ub300 \uad00\uc2ec\uc744 \ub454 \ud504\ub85c\uadf8\ub798\uc784 \ud328\ub7ec\ub2e4\uc784. b = 1 c = 1 a = b + c b = 2 print(a) //imperactive => 2 //reactive =>3","title":"Reactive"},{"location":"framework/spring/spring_webflux/#reactive-stream","text":"\ub370\uc774\ud130\uc758 \uc2a4\ud2b8\ub9bc \ud45c\ud604 \ubc29\uc2dd \uaddc\uc57d ReativeGit \ube44\ub3d9\uae30 \uc2a4\ud2b8\ub9bc\uc758\ub85c \ub370\uc774\ud130\ub97c \ucd94\uc0c1\ud654 \ud558\uba74 \uac00\uc7a5 \ud070 \ubb38\uc81c\ub294 consumer \uac00 producer \uc758 \uc18d\ub3c4\ub97c \ub530\ub77c\uc624\uc9c0 \ubabb\ud560\ub54c \ubc1c\uc0dd consumer \uac00 producer \uc758 \uc18d\ub3c4\ub97c \uc870\uc808 \ud560 \uc218 \uc788\uc74c","title":"Reactive stream"},{"location":"framework/spring/spring_webflux/#definition","text":"process a potentially unbounded number of elements in sequence, asynchronously passing elements between components, with mandatory non-blocking backpressure.","title":"Definition"},{"location":"framework/spring/spring_webflux/#none-blocking","text":"asynchronous I/O (also non-sequential I/O) is a form of input/output processing that permits other processing to continue before the transmission has finished. non-blocking web stack to handle concurrency with a small number of threads and scale with fewer hardware resources","title":"None-blocking"},{"location":"framework/spring/spring_webflux/#functional","text":"Treats computation as the evaluation of mathematical functions and avoids changing-state and mutable data. It is a declarative programming paradigm, which means programming is done with expressions or declarations","title":"Functional"},{"location":"framework/spring/spring_webflux/#webflux","text":"None-blocking Reactive (stream) Functional Spring","title":"WebFlux"},{"location":"framework/spring/spring_webflux/#sequece-flow","text":"sequenceDiagram User ->>+ EventLoop : GET /person/1 EventLoop ->> DispatherHandler : server thread DispatherHandler ->> WebHandler : handler::getPerson(req) WebHandler ->> Service : getPersonName(id) Service ->> DB : select id from person where.. DB -->> EventLoop : return server thread EventLoop ->> DB : server thread DB -->> Service : record Service -->> WebHandler : 1 WebHandler -->> DispatherHandler : resposne.body(1) DispatherHandler -->> EventLoop : resposne.body(1) EventLoop -->>- User : response.body(1)","title":"Sequece flow"},{"location":"framework/spring/spring_webflux/#async-servlet-31","text":"Client sends a request Servlet container allocates a thread and invokes a servlet in it The servlet calls request.startAsync(), saves the AsyncContext, and returns The container thread is exited all the way but the response remains open Some other thread uses the saved AsyncContext to complete the response Client receives the response","title":"Async Servlet 3.1+"},{"location":"framework/spring/spring_webflux/#concurrency-model-thread-model","text":"WebFlux","title":"Concurrency Model (thread model)"},{"location":"framework/unity/key/","text":"Short Cut Visual studio Cmd + ': reference","title":"Short Cut"},{"location":"framework/unity/key/#short-cut","text":"","title":"Short Cut"},{"location":"framework/unity/key/#visual-studio","text":"Cmd + ': reference","title":"Visual studio"},{"location":"rl/4_rl_introduction/","text":"1. Introduction to Reinforcement Learning \ubaa9\ucc28 \uac15\ud654 \ud559\uc2b5\uc740 \ubb34\uc5c7\uc778\uac00? \ud575\uc2ec \uc0dd\uac01\ub4e4 Agent\uc758 \uad6c\uc131\uc694\uc18c \uac15\ud654 \ud559\uc2b5\uc5d0 \ub0a8\uc740 \ub3c4\uc804\ub4e4 \ub3d9\uae30 1.\ubb3c\ub9ac\uc801 \ubc18\ubcf5 \uc791\uc5c5\uc5d0 \ub300\ud55c \uc790\ub3d9\ud654 \uc0b0\uc5c5\ud601\uba85 - \uc0dd\uc0b0\ub77c\uc778 \ub4f1 2.\uc815\uc2e0\uc801 \ubc18\ubcf5 \uc791\uc5c5\uc5d0 \ub300\ud55c \uc790\ub3d9\ud654 \uc815\ubcf4\ud654 \ud601\uba85 - \uacc4\uc0b0\uae30 \ub4f1 \uc5b4\ub5bb\uac8c \ud558\ub294\uc9c0 \uaddc\uce59\uc744 \uc815\ud574\uc11c \uad6c\ud604 \ud588\uc74c. 3.\uae30\uacc4\uac00 \ubb38\uc81c\uc5d0 \ub300\ud55c \ud574\ubc95\uc744 \uc790\uc2e0\uc774 \ucc3e\uc74c AI \ud601\uba85 \uacb0\uc815\uc744 \ub0b4\ub9ac\ub294 \ubc29\ubc95\uc5d0 \ub300\ud55c \uc790\ub3d9 \ud559\uc2b5\uc774 \ud544\uc694\ud574\uc9d0 \uac15\ud654 \ud559\uc2b5\uc774\ub780 \ubb34\uc5c7\uc778\uac00? \uc8fc\uc5b4\uc9c4 \uc0c1\ud669\uc5d0\uc11c \ucd5c\uc120\uc774\ub77c \uc0dd\uac01\ub418\ub294 \ud589\ub3d9\uc744 \ud559\uc2b5\ud558\ub294 \uac83. \uc0c1\ud638\uc791\uc6a9\uc744 \ud1b5\ud574\uc11c \uacb0\uc815\uc744 \ub0b4\ub9ac\ub294 \ubc95\uc744 \ud559\uc2b5\ud558\ub294 \uacfc\ud559 \ud658\uacbd\uacfc \uc0c1\ud638 \uc791\uc6a9 \ud558\uba74\uc11c \ud559\uc2b5\ud568. \uc9c0\ub3c4 \ud559\uc2b5\uacfc \ub2e4\ub978\uc810 \ub3d9\uc801\uc784 (\uc218\ub3d9\uc801\uc774\uc9c0 \uc54a\uc74c) \uc0c1\ud638\uc791\uc6a9\uc774 \uc787\ub530\ub77c \uc77c\uc5b4\ub0a8 (\ub2e4\uc74c \ud589\ub3d9\uc740 \uc774\uc804\uc758 \ud589\ub3d9\uc5d0 \uc758\uc874\uc131\uc774 \uc788\uc744 \uc218 \uc788\uc74c) \ubaa9\ud45c \uc9c0\ud5a5\uc801\uc784 \uc608\uc81c \uc5c6\uc774 \ucd5c\uc801 \ud589\ub3d9 \uc591\uc2dd\uc744 \ucc3e\uc744 \uc218 \uc788\uc74c. Learn by try and error. \uc0ac\uace0\uc758 \ud2c0\uacfc \uc54c\uace0\ub9ac\uc998 \uc591\ucabd \ub2e4 \uc9c0\uce6d \uc0c1\ud638\uc791\uc6a9 loop \uc0c1\ud638\uc791\uc6a9\uc744 \ud1b5\ud574\uc11c \uacb0\uc815\uc744 \ub0b4\ub9ac\ub294 \ubc95\uc744 \ud559\uc2b5\ud558\ub294 \uacfc\ud559 \uc704\uc758 \uc815\uc758\ub97c \ub2ec\uc131\ud558\uae30 \uc704\ud574 \uace0\ub824\ud574\uc57c \ud558\ub294 \uac83\ub4e4 - \uc2dc\uac04 - \ud589\ub3d9\uc5d0 \ub300\ud55c \uacb0\uacfc(\uc7a5$\\cdot$\ub2e8\uae30\uc801) - \uacbd\ud5d8\uc758 \ucd95\uc801 - \ubbf8\ub798\uc5d0 \ub300\ud55c \uc608\uce21 - \ubd88\ud655\uc2e4 \uc131\uc5d0 \ub300\ud55c \ucc98\ub9ac \uac15\ud654 \ud559\uc2b5\uc758 \ud2b9\uc9d5 \ub2e4\ub978 \ud559\uc2b5\ub4e4\uacfc \ub2e4\ub978 \ubd80\ubd84 - \uc9c0\ub3c4 \ud559\uc2b5\uc774 \uc544\ub2d8, \ubcf4\uc0c1 \uc2e0\ud638\ub9cc \uc788\uc74c - \ud53c\ub4dc\ubc31\uc774 \uc9c0\uc5f0 \ub420 \uc218 \uc788\uc74c(\uc989\uac01\uc801\uc774\uc9c0 \uc54a\uc544\ub3c4 \ub428) - \uc2dc\uac04\uc774 \uc911\uc694\ud568 - \uc774\uc804 \uacb0\uc815\uc774 \uc774\ud6c4 \uc0c1\ud638 \uc791\uc6a9\uc5d0 \uc601\ud5a5\uc744 \uc90c \ud575\uc2ec \uc0dd\uac01\ub4e4 \ud658\uacbd \ubcf4\uc0c1 \uc2e0\ud638 Agent Agent state Policy Value function Model (Optional) Agent and Environment \uac01\uac01\uc758 \ub2e8\uacc4 t \uc5d0 Agent Observation $O_{t}$ \uc744 \ubc1b\uc74c(\uadf8\ub9ac\uace0 \ubcf4\uc0c1$R_{t}$ \uc744 \ubc1b\uc74c) \uc561\uc158\uc744 $A_{t}$ \ud589\ud568 The environment \uc561\uc158 $A_{t}$\ub97c \ubc1b\uc74c Observation $O_{t+1}$ \uc744 \uc0dd\uc131(\uadf8\ub9ac\uace0 \ubcf4\uc0c1$R_{t+1}$ \uc744 \uc0dd\uc131) def agent(time, observation, reward): // \uac00\uc7a5 \uc88b\uc740 action \uc120\ud0dd return action def env(time, action): // action\uc5d0 \uc758\ud574 \ubc18\uc751\ud55c \ud658\uacbd\uacfc \ubcf4\uc0c1\uc744 \ub9ac\ud134 return (observation, reward) t = 0 action, observaion, reward = None, None, None while True: t++ action = agent(t, observation, reward) observation, reward = evn(t, action) \ubcf4\uc0c1 \ubcf4\uc0c1 $R_{t}$\ub294 scalar \uac12\uc774\ub2e4. Agent \uac00 step t \uc5d0 \uc5bc\ub9c8\ub098 \uc798\ud588\ub294\uc9c0\uc5d0 \ub300\ud55c \ud53c\ub4dc\ubc31 \uc2e0\ud638 Agent \uc758 \ubaa9\ud45c\ub294 \ub204\uc801 \ubcf4\uc0c1\uc744 \ucd5c\ub300\uac12\uc73c\ub85c \ub9cc\ub4dc\ub294 \uac83\uc774\ub2e4. $$ G_{t} = R_{t+1} + R_{t+2} + R_{t+3} + ... $$ \uc6b0\ub9ac\ub294 \uc704\uc758 \ub204\uc801 \ubcf4\uc0c1\uc744 the return \uc774\ub77c\uace0 \ud560 \uac83\uc774\ub2e4. \ubcf4\uc0c1 \uac00\uc124 \uc5b4\ub5a0\ud55c \ubaa9\ud45c\ub3c4 \ub204\uc801 \ubcf4\uc0c1\uc744 \ucd5c\ub300\ud654 \uc2dc\ud0a4\ub294 \ubc29\ubc95\uc73c\ub85c \ud615\uc2dd\ud654 \ud560 \uc218 \uc788\ub2e4. Values \ud2b9\uc815 \uc0c1\ud669 s \uc5d0\uc11c \ub204\uc801 \ubcf4\uc0c1\uc758 \uae30\ub300\uac12\uc744 value \ub77c\uace0 \ud558\uc790. $$ \\begin{align} \\mathtt{v}(s) = & \\mathbb{E} [ G_{t} | S_{t}=s ] \\\\ = & \\mathbb{E} [ R_{t+1} + R_{t+2} + R_{t+3} + ... | S_{t}=s ] \\end{align} $$ \uc774\uc81c agent\uc758 \ubaa9\ud45c\ub294 value\ub97c \ucd5c\ub300\ud654 \ud558\ub294\uac83\uc774\ub77c\uace0 \uc7ac \uc815\uc758 \ud560 \uc218 \uc788\ub2e4. Reward \uadf8\ub9ac\uace0 Value \ub294 \ud2b9\uc815 \uc0c1\ud669\uc5d0\uc11c \ud2b9\uc815 action \uc774 \uc5bc\ub9c8\ub098 \uc801\ud569\ud55c\uc9c0\uc758 \uc815\ub3c4\ub97c \ub098\ud0c0\ub0b8\ub2e4(\uc9c0\ub3c4 \ud53c\ub4dc\ubc31\uc774 \ud544\uc694 \uc5c6\ub2e4.) retuns \uc640 values \ub294 \uc7ac\uadc0\ub85c \uc815\uc758 \ub420 \uc218 \uc788\ub2e4. $$ G_{t} = R_{t+1} + G_{t+1} $$ \uc21c\ucc28\uc801 Action\ub4e4 value \uac12\uc744 \ucd5c\ub300\ud654 \ud558\ub294 actions \uc744 \uace0\ub974\ub294\uac78 \ubaa9\ud45c\ub85c \ud558\uc790. \uc774\uc81c agent\uc758 \ubaa9\ud45c\ub294 \ud2b9\uc815 action\ub4e4\uc744 \uc120\ud0dd\ud574\uc11c value\ub97c \ucd5c\ub300\ud654 \ud558\ub294\uac83\uc774\ub77c\uace0 \uc7ac \uc815\uc758 \ud560 \uc218 \uc788\ub2e4. actions \ub294 \uc7a5\uae30\uc801 \uacb0\uacfc\ub97c \uac00\uc9c8 \uc218\ub3c4 \uc788\ub2e4. \ubcf4\uc0c1\uc740 \uc9c0\uc5f0 \ub420 \uc218 \uc788\ub2e4. \uc7a5\uae30\uc801 \ubcf4\uc0c1\uc744 \uc704\ud574 \uc989\uac01\uc801\uc778 \ubcf4\uc0c1\uc744 \ud3ec\uae30\ud558\ub294\uac8c \uc88b\uc744 \uc218 \ub3c4 \uc788\ub2e4. \ud5ec\ub9ac\ucf65\ud130 \uc5f0\ub8cc \ucda9\uc804(\uba87\uc2dc\uac04 \ud6c4 \uc5d0 \ucd94\ub77d \ud560 \uc218 \uc788\uc73c\ub2c8) \uc8fc\uc2dd \ud22c\uc790 (\uc7a5\uae30\uc801\uc73c\ub85c \uc774\uc775\uc774 \ub354 \uc62c\ub54c) states \ub85c \ubd80\ud130 actions \ub85c\uc758 \ub9f5\ud551\uc744 policy \ub77c\uace0 \ud55c\ub2e4. $$ \\text{policy} = f: \\text{states} \\to \\text{action} $$ Action values value \uc758 \uc870\uac74\uc2dd\uc5d0 action \uc744 \ub123\uc744\uac78 action value \ub77c\uace0\ud55c\ub2e4. $$ \\begin{align} q(s, a) = & \\mathbb{E}[ G_{t} | S_{t}=s, A_{t}=a ] \\\\ = & \\mathbb{E} [ R_{t+1} + R_{t+2} + R_{t+3} + ... | S_{t}=s, A_{t}=a ] \\end{align} $$ Agent State Actions\ub294 agent\uc758 state \uc5d0 \uc758\uc874\uc131\uc774 \uc788\ub2e4. \ud589\uc704\uc790\uc640 \ud658\uacbd\uc740 \uac01\uac01 \ub0b4\ubd80 state\ub97c \uac00\uc9c8 \uc218 \uc788\ub2e4. \uac04\ub2e8\ud55c \uc608\uc81c\uc5d0\uc11c\ub294 state \uac00 \ud55c\uac1c \uc77c \uc218 \uc788\ub2e4. \ubcf4\ud1b5 \uc0c1\ud0dc\uac00 \uc5c4\uccad \ub9ce\ub2e4. - \uac00\ub054\uc529 \ubb34\ud55c\ub300\uc758 \uacbd\uc6b0\ub3c4 \uc788\ub2e4. \ud589\uc704\uc790\uc758 \uc0c1\ud0dc\uc640 \ud658\uacbd\uc758 \uc0c1\ud0dc\ub294 \uc77c\ubc18\uc801\uc73c\ub85c \ub2e4\ub974\ub2e4. \ud589\uc704\uc790\ub294 \ud658\uacbd\uc758 \ubaa8\ub4e0 \uc0c1\ud0dc\ub97c \ubaa8\ub97c \uc218 \uc788\ub2e4. Environment state \ud658\uacbd\uc758 \ub0b4\ubd80 \uc0c1\ud0dc \uc77c\ubc18\uc801\uc73c\ub85c \ud589\uc704\uc790\uac00 \uc54c \uc218 \uc5c6\ub2e4. \ub9cc\uc57d \uc548\ub2e4\uace0 \ud574\ub3c4 \uc0c1\uad00\uc5c6\ub294 \uc815\ubcf4\ub97c \ub9ce\uc774 \uac00\uc9c0\uace0 \uc788\uc744 \uc218 \uc788\ub2e4. Agent state (Observation, action, reward)\ub4e4\uc758 \uc5ed\uc0ac $$ H_{t} = O_{0}, A_{0}, R_{1}, O_{1}, ... ,O_{t-1}, A_{t-1}, R_{t}, O_{t} $$ \uc704\uc758 \uc5ed\uc0ac\uac00 \ud589\uc704\uc790\uc758 \uc0c1\ud0dc$S_{t}$\ub97c \ub9cc\ub4dc\ub294\ub300 \uc0ac\uc6a9\ub41c\ub2e4. \uc561\uc158\uc740 \uc0c1\ud0dc\uc5d0 \uc758\uc874\uc131\uc774 \uc788\ub2e4. Fully Obervable Environments \ud589\uc704\uc790\uac00 \ud658\uacbd\uc758 \uc804\uccb4 \uc0c1\ud0dc\ub97c \uad00\ucc30 \ud560 \uc218 \uc788\ub2e4\uace0 \uac00\uc815 \ud558\uc790. - observation = \ud658\uacbd \uc0c1\ud0dc - \ud589\uc704\uc790\uc758 \uc0c1\ud0dc\uac00 \ud658\uacbd \uc0c1\ud0dc\uc640 \uac19\uc744 \uc218 \uc788\ub2e4. $$S_{t} = O_{t} = \\text{environment state}$$ - \ud589\uc704\uc790\uac00 Markov decision process \uc5d0 \uc788\ub2e4. Markov decision processes MDPs \ub294 \ud2b9\uc815 \uc218\ud559\uc801 \uc18d\uc131\uc744 \uc758\ubbf8\ud55c\ub2e4. \uc608\ub97c \ub4e4\uc5b4 \uc790\uc5f0\uc218\uc758 \uc18d\uc131\uc740 \uc74c\uc758 \uc815\uc218\uac00 \uc544\ub2cc \uc815\uc218 \uc774\ub2e4. \uc6b0\ub9ac\ub294 \uc74c\uc758 \uc815\uc218\uac00 \uc544\ub2cc \uc815\uc218\ub97c \uc790\uc5f0\uc218\uc758 \uc18d\uc131\uc744 \ub9cc\uc871\ud55c\ub2e4\uace0 \ud558\uace0 \uc790\uc5f0\uc218\ub77c\uace0 \uce6d\ud558\uae30\ub3c4 \ud55c\ub2e4. \uc815\uc758 \uc544\ub798\uc758 \uc870\uac74\uc744 \ucda9\uc871\ud558\ub294 \uacb0\uc815 \uacfc\uc815\uc744 Markov \ub77c\uace0 \ud55c\ub2e4. A decision process is Markov if p == probability joint probability of r, s given $S_{t}, A_{t}$ is same as given $H_{t}, A_{t}$ $$ p(r,s| S_{t}, A_{t}) = p(r,s| H_{t}, A_{t})$$ \ud604\uc7ac\ub97c \uc8fc\uba74 \ubbf8\ub798\ub294 \uacfc\uac70\ub85c \ubd80\ud130 \ub3c5\ub9bd\uc801\uc774\ub2e4. The future is independent of the past given the present $$ H_{t} \\to S_{t} \\to H_{t+1} $$ \ud574\ub2f9 \uc18d\uc131\uc744 \ub9cc\uc871\ud558\ub294 state \ub97c \uc54c\uac8c \ub418\uba74 \uc5ed\uc0ac\ub97c \ubc84\ub824\ub3c4 \ub41c\ub2e4. \uc608\ub97c \ub4e4\uc5b4 stationary \ud658\uacbd \uc0c1\ud0dc\ub294 Markov \uc774\ub2e4. \uc5ed\uc0ac $H_{t+1}$\ub294 Markov \uc774\ub2e4. Partially Observable Environments Agent \uac00 \uc815\ubcf4\uc758 \uc77c\ubd80\ubd84\ub9cc \ubc1b\ub294\ub2e4. - \ud3ec\ucee4\uce74\ub4dc \uac8c\uc784 - observation \uc774 Markov \uac00 \uc544\ub2c8\ub2e4. - patially obsevable Markov decision process (POMDP) - \ud658\uacbd \uc0c1\ud0dc\uac12\uc740 Markov \uc774\uc9c0\ub9cc \ud589\uc704\uc790\uac00 \uc774\uac78 \uc54c \uc218 \uc5c6\ub2e4. Agent state angent state \ub294 \uc5ed\uc0ac\uc5d0 \ub300\ud55c \ud568\uc218\uc774\ub2e4. $$ \\text{agent state} = f: H \\to S $$ \ud589\uc704\uc790\uc758 \uc561\uc158\uc740 \uc0c1\ud0dc\uc5d0 \uc758\uc874\ud55c\ub2e4. State update function == f $$S_{t+1} = f(S_{t},A_{t},R_{t+1},O_{t+1})$$ \ud589\uc704\uc790\ub294 t \uc5d0 \uc788\uc74c $S_t$ \ub97c \uc0ac\uc6a9\ud574 $A_t$ \ub97c \uacb0\uc815\ud558\uace0 \uc2e4\ud589. \ud658\uacbd\uc774 $R_{t+1}, O_{t+1}$\uc744 \uc0dd\uc131. \ud589\uc704\uc790\ub294 \uc774\uc81c $t + 1$ \uc5d0 \uc788\uc74c $S_{t+1}$ \uc744 $f(S_t, A_t, R_{t+1}, O_{t+1})$ \uc744 \uc0ac\uc6a9\ud574 \ubcc0\uacbd \uad00\uc2b5\uc801\uc73c\ub85c t \ub294 \ud589\uc704\uc790\uac00 \ud658\uacbd\uc5d0\uc11c \uc561\uc158\uc744 \ubcf4\ub0b4\ub294 \uc2dc\uc810\uc784 \ud589\uc704\uc790\uc758 \uc0c1\ud0dc\ub294 \ud658\uacbd\uc758 \uc0c1\ud0dc\ubcf4\ub2e4 \ud6e8\uc52c \uc791\ub2e4. Example \ubd80\ubd84 \uad00\ucc30\uc774 \uac00\ub2a5\ud55c \ud658\uacbd\uc5d0\uc11c \ud589\uc704\uc790\uc758 \uc0c1\ud0dc\ub97c \ub9cc\ub4e4\uc5b4\ubcf4\uc790. \ud589\uc704\uc790\ub294 2\ubc88 \ucc98\ub7fc \ud658\uacbd\uc758 \uc77c\ubd80\ubd84\uc744 observation \uc73c\ub85c \ubc1b\ub294\ub2e4. \ub9cc\uc57d $S_{t} = O_{t}$\ub97c \uc0ac\uc6a9\ud588\ub2e4\uba74 3\ubc88 \ucc98\ub7fc \ub450\uac1c\uc758 \ub2e4\ub978 observation\uc744 \uad6c\ubd84 \ud560 \ubc29\ubc95\uc774 \uc5c6\ub2e4. \uc989 \ud589\uc704\uc790\uc758 \uc0c1\ud0dc\uac00 Markov \uac00 \uc544\ub2cc \uc0c1\ud0dc\uac00 \ub418\uc5c8\ub2e4. \uc5b4\ub5bb\uac8c \ud558\uba74 \ud589\uc704\uc790\uc758 \uc0c1\ud0dc\ub97c Markov \ud558\uac8c \ud560 \uc218 \uc788\uc744\uae4c? \ud589\uc704\uc790\uac00 \uc5ed\uc0ac\ub97c \uc0ac\uc6a9\ud574 \uad6c\ubd84 \ud560 \uc218 \uc788\ub294 \uc0c1\ud0dc\ub97c \ub9cc\ub4e4\uba74 \ub41c\ub2e4. Partially Observable Enviroments \ubd80\ubd84 \uad00\ucc30 \ud658\uacbd\uc5d0\uc11c \ud589\uc704\uc790\ub294 Markov \uc18d\uc131\uc744 \uac19\ub294 \uc0c1\ud0dc\ub97c \ub9cc\ub4e4\uc5b4\uc57c \ud55c\ub2e4. \ud589\uc704\uc790\uc758 \uc0c1\ud0dc \uc608\uc81c \ub9c8\uc9c0\ub9c9 \uad00\ucc30: $S_{t} = O_{t}$ (\uc704\uc758 \ubbf8\ub85c \uc608\uc81c\ucc98\ub7fc \ub9cc\uc871\ub418\uc9c0 \uc54a\uc744\uc218 \uc788\uc74c) \ubaa8\ub4e0 \uc5ed\uc0ac: $S_{t} = H_{t}$ (\uc591\uc774 \ub108\ubb34 \ub9ce\uc744 \uc218 \uc788\uc74c) \uc21c\ucc28\uc801\uc73c\ub85c \ubcc0\ud654\ud558\ub294 \uc0c1\ud0dc: $S_{t} = f(S_{t-1}, O_{t})$ \uc704\uc758 \ubbf8\ub85c\uc5d0\uc11c\ub294 \uc2dc\uc791\uc810\uc744 \uae30\uc900\uc73c\ub85c \ud558\ub294 \ud3c9\uba74 \uc88c\ud45c\uacc4\ub97c \ucd94\uac00\ud558\uba74 \ub428 recurrent nerual network \ub85c \uad6c\ud604 \ub420\uc218 \uc788\uc74c \uac00\ub054 \uba54\ubaa8\ub9ac \ub77c\uace0\ub3c4 \ubd88\ub9bc \ud589\uc704\uc790\uc758 \uc0c1\ud0dc\uac00 Markov \uc18d\uc131\uc744 \ub9cc\uc871\ud558\uac8c \ud558\uae30\uac00 \uc27d\uc9c0 \uc54a\uc740 \uacbd\uc6b0\uac00 \ub9ce\uc74c \uc0c1\ud0dc\ub294 \uc88b\uc740 police \uc640 \uc88b\uc740 value \uc744 \uc608\uce21\ud558\uae30 \uc704\ud55c \ucda9\ubd84\ud55c \uc815\ubcf4\ub97c \ud3ec\ud568 \ud574\uc57c\ud568. Policy Policy \ub294 \ud589\uc704\uc790\uc758 \ud589\ub3d9\uc591\uc2dd\uc744 \uc815\uc758 \ud55c\ub2e4. \ud589\uc704\uc790 \uc0c1\ud0dc\uc5d0\uc11c action \uc73c\ub85c \uc5f0\uacb0\ub418\ub294 \ud568\uc218\ub2e4. $f: \\text{state} \\to \\text{action}$ \uacb0\uc815\ub860\uc801 \uc815\ucc45: $A = \\pi(S)$ \ud655\ub960\uc801 \uc815\ucc45: $ \\pi(A|S) = p(A|S) $ Value function The value function is the expected return condition on state $$ \\begin{align} v_{\\pi}(s) = & \\mathbb{E} [ G_{t} | S_{t} = s, \\pi ] \\\\ = & \\mathbb{E} [ R_{t+1} + \\gamma R_{t+2} + \\gamma^{2} R_{t+3} + ... | S_{t} = s, \\pi ] \\end{align} $$ The discount factor. $ \\gamma \\in [0, 1]$ \uc989\uac01\uc801\uc778 \ubcf4\uc0c1\uacfc \uc7a5\uae30 \ubcf4\uc0c1\uc5d0 \ub300\ud55c trade-off \ub97c \uc8fc\ub294 \uc6a9\ub3c4\ub85c \uc0ac\uc6a9 trade-off: a balance achieved between two desirable but incompatible features \ubbf8\ub85c \ud0c8\ucd9c\uc5d0\uc11c \uc124\uc815 \ud558\uba74 \ud589\uc704\uc790\ub294 \ud560\uc778 \ub418\uc9c0 \uc54a\uc740\ucd5c\ub300 \ubcf4\uc0c1\uc744 \ubc1b\uae30 \uc704\ud574 \ube68\ub9ac \ud0c8\ucd9c \ud560\ub824\uace0 \uc2dc\ub3c4. Value \ub294 \uc815\ucc45\uc5d0 \uc758\uc874\ud55c\ub2e4. \ubc14\ub78c\uc9c1\ud55c \ub2e4\ub984 \uc0c1\ud0dc\ub97c \ud3c9\uac00\ud558\ub294\ub300 \uc0ac\uc6a9 \ud560 \uc218 \uc788\ub2e4. actions \ub97c \uc120\ud0dd\ud558\uae30 \uc704\ud574 \uc0ac\uc6a9 \ud560 \uc218 \uc788\ub2e4. Bellman equation Return \uc740 \uc7ac\uadc0\uc801 \ud615\uc2dd\uc73c\ub85c \ud45c\ud604 \ud560 \uc218 \uc788\ub2e4. $G_{t} = R_{t+1} + \\gamma G_{t+1}$ \uadf8\ub7ec\ubbc0\ub85c \ub2e4\uc74c\uacfc \uac19\ub2e4. $ a \\sim \\pi(s) $ action \uc774 \uc0c1\ud0dc s \uc77c\ud0dc policy \uc5d0 \uc758\ud574 \uacb0\uc815\ub428\uc744 \uc758\ubbf8($\\pi$ \uac00 \uacb0\uc815\ub860\uc801\uc77c \ub54c\ub3c4 \ub3d9\uc77c) $$ \\begin{align} v_{\\pi}(S_{t+1}) = & \\mathbb{E} [ G_{t+1} \\mid S_{t+1} = s, \\pi ] \\\\ \\\\ v_{\\pi}(s) = & \\mathbb{E} [ G_{t} \\mid S_{t} = s, A_{t} \\sim \\pi(s) ] \\\\ = & \\mathbb{E} [ R_{t+1} + \\gamma G_{t+1} \\mid S_{t} = s, A_{t} \\sim \\pi(s) ] \\\\ = & \\mathbb{E} [ R_{t+1} + \\gamma v_{\\pi}(S_{t+1}) | S_{t} = s, A_{t} \\sim \\pi(s) ] \\\\ \\end{align} $$ \uc704\uc758 \ud568\uc218\uac00 \uc788\ub2e4\uba74 \ud2b9\uc815 \uc0c1\ud669\uc5d0\uc11c\uc758 \ucd5c\uc801 \ud589\ub3d9\uc744 \uc544\ub798\uc758 \uc2dd\uc73c\ub85c \uad6c \ud560 \uc218 \uc788\ub2e4. \uc544\ub798\uc2dd\uc740 policy \uc5d0 \uc758\uc874\uc131\uc774 \uc5c6\ub2e4. \ub9cc\uc57d \uc81c\ud55c \ub41c \uc0c1\ud0dc\uc640 \ud589\ub3d9\uc774\ub77c\uba74 \uc6b0\ub9ac\ub294 \uc544\ub798\uc758 \ubc29\uc815\uc2dd\uc744 \ud480 \uc218 \uc788\ub2e4. $$ v_{*}(s) = \\underset{a}{\\operatorname{argmax}} \\mathbb{E} [ R_{t+1} + \\gamma v_{*}(S_{t+1}) | S_{t} = s, A_{t} = a ] \\\\ $$ Value Function approximations \ud589\uc704\uc790\ub294 \uc885\uc885 approxmate value \ud568\uc218\ub97c \uc0ac\uc6a9\ud55c\ub2e4. \uc774\ub7f0 \ud568\uc218\uac00 \uc788\ub2e4\uba74 \uc6b0\ub9ac\ub294 \ucd5c\uc801\ud654\ub294 \uc544\ub2c8\uc9c0\ub9cc \uc798 \ub3d9\uc791\ud558\ub294 \ud589\uc704\uc790\ub97c \ub9cc\ub4e4 \uc218 \uc788\ub2e4. Model(optional) \ubaa8\ub378\uc740 \ud658\uacbd\uc774 \ub2e4\uc74c\uc5d0 \ubb34\uc5c7\uc744 \ud560 \uac83\uc778\uac00\ub97c \uc608\uce21\ud558\ub294\ub300 \uc0ac\uc6a9\ub41c\ub2e4. \ub2e4\uc74c \ud658\uacbd \uc0c1\ud0dc\uc744 \uc608\uce21 \ud55c\ub2e4. $$ P(s, a, s') \\approx P(S_{t+1} = s^{\\prime} \\mid S_{t} = s, A_{t} = a) $$ \ub2e4\uc74c \ubcf4\uc0c1\uc744 \uc608\uce21 $$ R(s, a) \\approx \\mathbb{E} [ R_{t} \\mid S_{t} = s, A_{t} = a ]$$ Maze Example \uc704\uc5d0\uc11c \uc815\uc758\ud55c \uac1c\ub150\ub4e4\uc744 \ubbf8\ub85c\uc5d0 \uc801\uc6a9 \uc2dc\ucf1c\ubcf4\uc790. \uadf8\ub9bc1. \ud658\uacbd \uc804\uccb4\ub97c \ubcf4\uc5ec\uc900\ub2e4. action: up, down, left, right reward: \ud55c step \ub9c8\ub2e4 -1 state: agent location \uadf8\ub9bc2. \ud654\uc0b4\ud45c\ub294 Policy \ub97c \uc758\ubbf8\ud55c\ub2e4. policy: \uc0c1\ud0dc\uac00 \uc8fc\uc5b4\uc84c\uc744\ub54c\uc758 \ud589\ub3d9\uc591\uc2dd $ f: \\text{state} \\to \\text{action} $ \uadf8\ub9bc3. value \uac12 \uc22b\uc790\ub294 \uac01 \uc0c1\ud0dc\uc758 value \uac12 $ v_{\\pi}(s)$ \ub97c \uc758\ubbf8 \uadf8\ub9bc4. Model \uadf8\ub9ac\ub4dc\uc758 \uaca9\uc790\ub294 \ub2e4\uc74c \uc0c1\ud0dc\ub85c\uc758 \ubd80\ubd84 \uc804\uc774 \ubaa8\ub378$P_{ss^{\\prime}}^{a}$\uc744 \uc758\ubbf8 \uc22b\uc790\ub294 \uac01 \uc0c1\ud0dc\ubcc4 \uc989\uac01 \ubcf4\uc0c1 $R_{ss^{\\prime}}^{a}$\uc744 \uc758\ubbf8 Agent \uad6c\ubd84 Value based No policy(implcit) Value function Policy based Policy Value function Actor Critic Policy == actior Value function == critic Agent \uad6c\ubd842 Model Free Policy and/or Value Fuction No Model Model Based Optionally Policy and/or Value Fuction Model Learing and Planning \uac15\ud654\ud559\uc2b5\uc5d0\ub294 \ud06c\uac8c \ub450 \uc885\ub958\uc758 \ubb38\uc81c\uac00 \uc788\uc74c \ud559\uc2b5 \ud658\uacbd\uc744 \ubaa8\ub974\uace0 \uc2dc\uc791 \ud589\uc704\uc790\ub294 \ud658\uacbd\uacfc \uc0c1\ud638 \uc791\uc6a9 \ud568 \uacc4\ud68d \ud589\ub3d9\ud558\uc9c0 \uc54a\uace0 \uc0dd\uac01\ub9cc \ud558\ub294\uac83. \ud658\uacbd \ubaa8\ub378\uc774 \uc8fc\uc5b4\uc9d0 \ud589\uc704\uc790\ub294 \uc8fc\uc5b4\uc9c4 \ubaa8\ub378\uc744 \uac00\uc9c0\uace0 \uacc4\ud68d\uc744 \uc0dd\uc131(\uc0c1\ud638 \uc791\uc6a9 \uc5c6\uc774) Prediction and Control Prediction: Policy \ub97c \uc8fc\uba74 \ubbf8\ub798\ub97c \ud3c9\uac00\ud568 \uc9c0\ub3c4\ud559\uc2b5\uc744 \uc774\uacf3\uc5d0 \uc0ac\uc6a9 \ud560 \uc218 \uc788\uc74c. Control: \ubbf8\ub798\ub97c \ucd5c\uc801\ud654\ud568 (\uac00\uc7a5 \uc88b\uc740 \ubbf8\ub798\ub97c \ucc3e\uc74c) \uc544\ub798\uc758 \uc2dd\uacfc \uc5f0\uad00\ub418\uc5b4 \uc788\uc74c $$ \\pi_{*}(s) = \\underset{\\pi}{\\operatorname{argmax}} v_{\\pi}(s) $$ \ud589\uc704\uc790\uc758 \uad6c\uc131 \uc694\uc18c\ub97c \ud559\uc2b5 \ud558\ub294 \ubc29\ubc95 \ubaa8\ub4e0 \uad6c\uc131\uc694\uc18c\ub294 \ud568\uc218\uc784 Policy: $$ \\pi: \\text{state} \\to \\text{action} $$ Value function: $$ v: \\text{state} \\to \\text{value} $$ Model: $$ P_{ss^{\\prime}}^{a}: \\text{state} \\to \\text{next state} \\\\ R_{ss^{\\prime}}^{a}: \\text{state} \\to \\text{reward} $$ Status updates: $$ f: \\text{state, observation} \\to \\text{new state} $$ \uc704\uc758 \ud568\uc218\ub4e4\uc744 nn \uc73c\ub85c \ud45c\ud604 \ud558\uace0 deep learning \ubc29\ubc95\uc744 \uc0ac\uc6a9\ud574\uc11c \ucd5c\uc801\ud654 \ud560 \uc218 \uc788\uc74c \uc6b0\ub9ac\ub294 \uc885\uc885 \uc9c0\ub3c4\ud559\uc2b5\uc758 \uac00\uc815\uc778 idd, \uc640 stationarity \ub97c \ubb34\uc2dc\ud558\ub294\uacbd\uc6b0\uac00 \ub9ce\uae30 \ub54c\ubb38\uc5d0 \uc8fc\uc758 \ud574\uc57c\ud568. Atari game \uc758 \uac00\uc815 \uac8c\uc784\uc758 \uaddc\uce59\uc744 \uc54c\uc9c0 \ubabb\ud55c\ub2e4\uace0 \uac00\uc815. \uac8c\uc784\uc744 \ud558\uba74\uc11c \ud559\uc2b5\ud568(\uc0c1\ud638\uc791\uc6a9) \uc870\uc774\uc2a4\ud2f1\uc744 \ud1b5\ud574 \ud589\ub3d9\uc744 \ud558\uace0 \ud53d\uc140\uacfc \uc810\uc218\ub97c \ubc1b\uc74c. \ud658\uacbd == \uc544\ud0c0\ub9ac \uac8c\uc784 \uc561\uc158 == \uc870\uc774\uc2a4\ud2f1 Observation == \ud544\uc140 Reward == \uc810\uc218 Exploration and Exploitation Exploration: \uc815\ubcf4\ub97c \ub354 \ubaa8\uc73c\ub294\uac83 Exploitation: \uc54c\uace0\uc788\ub294 \uc815\ubcf4\ub97c \ud65c\uc6a9\ud574 \ubcf4\uc0c1\uc744 \ucd5c\ub300\ud558 \ud558\ub294\uac83. \ub450\uac1c\ub97c \uc798 \uc870\uc808\ud558\ub294\uac8c \uc911\uc694. Reference \ucc38\uc870 code","title":"1. Introduction to Reinforcement Learning"},{"location":"rl/4_rl_introduction/#1-introduction-to-reinforcement-learning","text":"","title":"1. Introduction to Reinforcement Learning"},{"location":"rl/4_rl_introduction/#_1","text":"\uac15\ud654 \ud559\uc2b5\uc740 \ubb34\uc5c7\uc778\uac00? \ud575\uc2ec \uc0dd\uac01\ub4e4 Agent\uc758 \uad6c\uc131\uc694\uc18c \uac15\ud654 \ud559\uc2b5\uc5d0 \ub0a8\uc740 \ub3c4\uc804\ub4e4","title":"\ubaa9\ucc28"},{"location":"rl/4_rl_introduction/#_2","text":"1.\ubb3c\ub9ac\uc801 \ubc18\ubcf5 \uc791\uc5c5\uc5d0 \ub300\ud55c \uc790\ub3d9\ud654 \uc0b0\uc5c5\ud601\uba85 - \uc0dd\uc0b0\ub77c\uc778 \ub4f1 2.\uc815\uc2e0\uc801 \ubc18\ubcf5 \uc791\uc5c5\uc5d0 \ub300\ud55c \uc790\ub3d9\ud654 \uc815\ubcf4\ud654 \ud601\uba85 - \uacc4\uc0b0\uae30 \ub4f1 \uc5b4\ub5bb\uac8c \ud558\ub294\uc9c0 \uaddc\uce59\uc744 \uc815\ud574\uc11c \uad6c\ud604 \ud588\uc74c. 3.\uae30\uacc4\uac00 \ubb38\uc81c\uc5d0 \ub300\ud55c \ud574\ubc95\uc744 \uc790\uc2e0\uc774 \ucc3e\uc74c AI \ud601\uba85 \uacb0\uc815\uc744 \ub0b4\ub9ac\ub294 \ubc29\ubc95\uc5d0 \ub300\ud55c \uc790\ub3d9 \ud559\uc2b5\uc774 \ud544\uc694\ud574\uc9d0","title":"\ub3d9\uae30"},{"location":"rl/4_rl_introduction/#_3","text":"\uc8fc\uc5b4\uc9c4 \uc0c1\ud669\uc5d0\uc11c \ucd5c\uc120\uc774\ub77c \uc0dd\uac01\ub418\ub294 \ud589\ub3d9\uc744 \ud559\uc2b5\ud558\ub294 \uac83. \uc0c1\ud638\uc791\uc6a9\uc744 \ud1b5\ud574\uc11c \uacb0\uc815\uc744 \ub0b4\ub9ac\ub294 \ubc95\uc744 \ud559\uc2b5\ud558\ub294 \uacfc\ud559 \ud658\uacbd\uacfc \uc0c1\ud638 \uc791\uc6a9 \ud558\uba74\uc11c \ud559\uc2b5\ud568. \uc9c0\ub3c4 \ud559\uc2b5\uacfc \ub2e4\ub978\uc810 \ub3d9\uc801\uc784 (\uc218\ub3d9\uc801\uc774\uc9c0 \uc54a\uc74c) \uc0c1\ud638\uc791\uc6a9\uc774 \uc787\ub530\ub77c \uc77c\uc5b4\ub0a8 (\ub2e4\uc74c \ud589\ub3d9\uc740 \uc774\uc804\uc758 \ud589\ub3d9\uc5d0 \uc758\uc874\uc131\uc774 \uc788\uc744 \uc218 \uc788\uc74c) \ubaa9\ud45c \uc9c0\ud5a5\uc801\uc784 \uc608\uc81c \uc5c6\uc774 \ucd5c\uc801 \ud589\ub3d9 \uc591\uc2dd\uc744 \ucc3e\uc744 \uc218 \uc788\uc74c. Learn by try and error. \uc0ac\uace0\uc758 \ud2c0\uacfc \uc54c\uace0\ub9ac\uc998 \uc591\ucabd \ub2e4 \uc9c0\uce6d","title":"\uac15\ud654 \ud559\uc2b5\uc774\ub780 \ubb34\uc5c7\uc778\uac00?"},{"location":"rl/4_rl_introduction/#loop","text":"","title":"\uc0c1\ud638\uc791\uc6a9 loop"},{"location":"rl/4_rl_introduction/#_4","text":"\uc704\uc758 \uc815\uc758\ub97c \ub2ec\uc131\ud558\uae30 \uc704\ud574 \uace0\ub824\ud574\uc57c \ud558\ub294 \uac83\ub4e4 - \uc2dc\uac04 - \ud589\ub3d9\uc5d0 \ub300\ud55c \uacb0\uacfc(\uc7a5$\\cdot$\ub2e8\uae30\uc801) - \uacbd\ud5d8\uc758 \ucd95\uc801 - \ubbf8\ub798\uc5d0 \ub300\ud55c \uc608\uce21 - \ubd88\ud655\uc2e4 \uc131\uc5d0 \ub300\ud55c \ucc98\ub9ac","title":"\uc0c1\ud638\uc791\uc6a9\uc744 \ud1b5\ud574\uc11c \uacb0\uc815\uc744 \ub0b4\ub9ac\ub294 \ubc95\uc744 \ud559\uc2b5\ud558\ub294 \uacfc\ud559"},{"location":"rl/4_rl_introduction/#_5","text":"\ub2e4\ub978 \ud559\uc2b5\ub4e4\uacfc \ub2e4\ub978 \ubd80\ubd84 - \uc9c0\ub3c4 \ud559\uc2b5\uc774 \uc544\ub2d8, \ubcf4\uc0c1 \uc2e0\ud638\ub9cc \uc788\uc74c - \ud53c\ub4dc\ubc31\uc774 \uc9c0\uc5f0 \ub420 \uc218 \uc788\uc74c(\uc989\uac01\uc801\uc774\uc9c0 \uc54a\uc544\ub3c4 \ub428) - \uc2dc\uac04\uc774 \uc911\uc694\ud568 - \uc774\uc804 \uacb0\uc815\uc774 \uc774\ud6c4 \uc0c1\ud638 \uc791\uc6a9\uc5d0 \uc601\ud5a5\uc744 \uc90c","title":"\uac15\ud654 \ud559\uc2b5\uc758 \ud2b9\uc9d5"},{"location":"rl/4_rl_introduction/#_6","text":"\ud658\uacbd \ubcf4\uc0c1 \uc2e0\ud638 Agent Agent state Policy Value function Model (Optional)","title":"\ud575\uc2ec \uc0dd\uac01\ub4e4"},{"location":"rl/4_rl_introduction/#agent-and-environment","text":"\uac01\uac01\uc758 \ub2e8\uacc4 t \uc5d0 Agent Observation $O_{t}$ \uc744 \ubc1b\uc74c(\uadf8\ub9ac\uace0 \ubcf4\uc0c1$R_{t}$ \uc744 \ubc1b\uc74c) \uc561\uc158\uc744 $A_{t}$ \ud589\ud568 The environment \uc561\uc158 $A_{t}$\ub97c \ubc1b\uc74c Observation $O_{t+1}$ \uc744 \uc0dd\uc131(\uadf8\ub9ac\uace0 \ubcf4\uc0c1$R_{t+1}$ \uc744 \uc0dd\uc131) def agent(time, observation, reward): // \uac00\uc7a5 \uc88b\uc740 action \uc120\ud0dd return action def env(time, action): // action\uc5d0 \uc758\ud574 \ubc18\uc751\ud55c \ud658\uacbd\uacfc \ubcf4\uc0c1\uc744 \ub9ac\ud134 return (observation, reward) t = 0 action, observaion, reward = None, None, None while True: t++ action = agent(t, observation, reward) observation, reward = evn(t, action)","title":"Agent and Environment"},{"location":"rl/4_rl_introduction/#_7","text":"\ubcf4\uc0c1 $R_{t}$\ub294 scalar \uac12\uc774\ub2e4. Agent \uac00 step t \uc5d0 \uc5bc\ub9c8\ub098 \uc798\ud588\ub294\uc9c0\uc5d0 \ub300\ud55c \ud53c\ub4dc\ubc31 \uc2e0\ud638 Agent \uc758 \ubaa9\ud45c\ub294 \ub204\uc801 \ubcf4\uc0c1\uc744 \ucd5c\ub300\uac12\uc73c\ub85c \ub9cc\ub4dc\ub294 \uac83\uc774\ub2e4. $$ G_{t} = R_{t+1} + R_{t+2} + R_{t+3} + ... $$ \uc6b0\ub9ac\ub294 \uc704\uc758 \ub204\uc801 \ubcf4\uc0c1\uc744 the return \uc774\ub77c\uace0 \ud560 \uac83\uc774\ub2e4.","title":"\ubcf4\uc0c1"},{"location":"rl/4_rl_introduction/#_8","text":"\uc5b4\ub5a0\ud55c \ubaa9\ud45c\ub3c4 \ub204\uc801 \ubcf4\uc0c1\uc744 \ucd5c\ub300\ud654 \uc2dc\ud0a4\ub294 \ubc29\ubc95\uc73c\ub85c \ud615\uc2dd\ud654 \ud560 \uc218 \uc788\ub2e4.","title":"\ubcf4\uc0c1 \uac00\uc124"},{"location":"rl/4_rl_introduction/#values","text":"\ud2b9\uc815 \uc0c1\ud669 s \uc5d0\uc11c \ub204\uc801 \ubcf4\uc0c1\uc758 \uae30\ub300\uac12\uc744 value \ub77c\uace0 \ud558\uc790. $$ \\begin{align} \\mathtt{v}(s) = & \\mathbb{E} [ G_{t} | S_{t}=s ] \\\\ = & \\mathbb{E} [ R_{t+1} + R_{t+2} + R_{t+3} + ... | S_{t}=s ] \\end{align} $$ \uc774\uc81c agent\uc758 \ubaa9\ud45c\ub294 value\ub97c \ucd5c\ub300\ud654 \ud558\ub294\uac83\uc774\ub77c\uace0 \uc7ac \uc815\uc758 \ud560 \uc218 \uc788\ub2e4. Reward \uadf8\ub9ac\uace0 Value \ub294 \ud2b9\uc815 \uc0c1\ud669\uc5d0\uc11c \ud2b9\uc815 action \uc774 \uc5bc\ub9c8\ub098 \uc801\ud569\ud55c\uc9c0\uc758 \uc815\ub3c4\ub97c \ub098\ud0c0\ub0b8\ub2e4(\uc9c0\ub3c4 \ud53c\ub4dc\ubc31\uc774 \ud544\uc694 \uc5c6\ub2e4.) retuns \uc640 values \ub294 \uc7ac\uadc0\ub85c \uc815\uc758 \ub420 \uc218 \uc788\ub2e4. $$ G_{t} = R_{t+1} + G_{t+1} $$","title":"Values"},{"location":"rl/4_rl_introduction/#action","text":"value \uac12\uc744 \ucd5c\ub300\ud654 \ud558\ub294 actions \uc744 \uace0\ub974\ub294\uac78 \ubaa9\ud45c\ub85c \ud558\uc790. \uc774\uc81c agent\uc758 \ubaa9\ud45c\ub294 \ud2b9\uc815 action\ub4e4\uc744 \uc120\ud0dd\ud574\uc11c value\ub97c \ucd5c\ub300\ud654 \ud558\ub294\uac83\uc774\ub77c\uace0 \uc7ac \uc815\uc758 \ud560 \uc218 \uc788\ub2e4. actions \ub294 \uc7a5\uae30\uc801 \uacb0\uacfc\ub97c \uac00\uc9c8 \uc218\ub3c4 \uc788\ub2e4. \ubcf4\uc0c1\uc740 \uc9c0\uc5f0 \ub420 \uc218 \uc788\ub2e4. \uc7a5\uae30\uc801 \ubcf4\uc0c1\uc744 \uc704\ud574 \uc989\uac01\uc801\uc778 \ubcf4\uc0c1\uc744 \ud3ec\uae30\ud558\ub294\uac8c \uc88b\uc744 \uc218 \ub3c4 \uc788\ub2e4. \ud5ec\ub9ac\ucf65\ud130 \uc5f0\ub8cc \ucda9\uc804(\uba87\uc2dc\uac04 \ud6c4 \uc5d0 \ucd94\ub77d \ud560 \uc218 \uc788\uc73c\ub2c8) \uc8fc\uc2dd \ud22c\uc790 (\uc7a5\uae30\uc801\uc73c\ub85c \uc774\uc775\uc774 \ub354 \uc62c\ub54c) states \ub85c \ubd80\ud130 actions \ub85c\uc758 \ub9f5\ud551\uc744 policy \ub77c\uace0 \ud55c\ub2e4. $$ \\text{policy} = f: \\text{states} \\to \\text{action} $$","title":"\uc21c\ucc28\uc801 Action\ub4e4"},{"location":"rl/4_rl_introduction/#action-values","text":"value \uc758 \uc870\uac74\uc2dd\uc5d0 action \uc744 \ub123\uc744\uac78 action value \ub77c\uace0\ud55c\ub2e4. $$ \\begin{align} q(s, a) = & \\mathbb{E}[ G_{t} | S_{t}=s, A_{t}=a ] \\\\ = & \\mathbb{E} [ R_{t+1} + R_{t+2} + R_{t+3} + ... | S_{t}=s, A_{t}=a ] \\end{align} $$","title":"Action values"},{"location":"rl/4_rl_introduction/#agent","text":"","title":"Agent"},{"location":"rl/4_rl_introduction/#state","text":"Actions\ub294 agent\uc758 state \uc5d0 \uc758\uc874\uc131\uc774 \uc788\ub2e4. \ud589\uc704\uc790\uc640 \ud658\uacbd\uc740 \uac01\uac01 \ub0b4\ubd80 state\ub97c \uac00\uc9c8 \uc218 \uc788\ub2e4. \uac04\ub2e8\ud55c \uc608\uc81c\uc5d0\uc11c\ub294 state \uac00 \ud55c\uac1c \uc77c \uc218 \uc788\ub2e4. \ubcf4\ud1b5 \uc0c1\ud0dc\uac00 \uc5c4\uccad \ub9ce\ub2e4. - \uac00\ub054\uc529 \ubb34\ud55c\ub300\uc758 \uacbd\uc6b0\ub3c4 \uc788\ub2e4. \ud589\uc704\uc790\uc758 \uc0c1\ud0dc\uc640 \ud658\uacbd\uc758 \uc0c1\ud0dc\ub294 \uc77c\ubc18\uc801\uc73c\ub85c \ub2e4\ub974\ub2e4. \ud589\uc704\uc790\ub294 \ud658\uacbd\uc758 \ubaa8\ub4e0 \uc0c1\ud0dc\ub97c \ubaa8\ub97c \uc218 \uc788\ub2e4.","title":"State"},{"location":"rl/4_rl_introduction/#environment-state","text":"\ud658\uacbd\uc758 \ub0b4\ubd80 \uc0c1\ud0dc \uc77c\ubc18\uc801\uc73c\ub85c \ud589\uc704\uc790\uac00 \uc54c \uc218 \uc5c6\ub2e4. \ub9cc\uc57d \uc548\ub2e4\uace0 \ud574\ub3c4 \uc0c1\uad00\uc5c6\ub294 \uc815\ubcf4\ub97c \ub9ce\uc774 \uac00\uc9c0\uace0 \uc788\uc744 \uc218 \uc788\ub2e4.","title":"Environment state"},{"location":"rl/4_rl_introduction/#agent-state","text":"(Observation, action, reward)\ub4e4\uc758 \uc5ed\uc0ac $$ H_{t} = O_{0}, A_{0}, R_{1}, O_{1}, ... ,O_{t-1}, A_{t-1}, R_{t}, O_{t} $$ \uc704\uc758 \uc5ed\uc0ac\uac00 \ud589\uc704\uc790\uc758 \uc0c1\ud0dc$S_{t}$\ub97c \ub9cc\ub4dc\ub294\ub300 \uc0ac\uc6a9\ub41c\ub2e4. \uc561\uc158\uc740 \uc0c1\ud0dc\uc5d0 \uc758\uc874\uc131\uc774 \uc788\ub2e4.","title":"Agent state"},{"location":"rl/4_rl_introduction/#fully-obervable-environments","text":"\ud589\uc704\uc790\uac00 \ud658\uacbd\uc758 \uc804\uccb4 \uc0c1\ud0dc\ub97c \uad00\ucc30 \ud560 \uc218 \uc788\ub2e4\uace0 \uac00\uc815 \ud558\uc790. - observation = \ud658\uacbd \uc0c1\ud0dc - \ud589\uc704\uc790\uc758 \uc0c1\ud0dc\uac00 \ud658\uacbd \uc0c1\ud0dc\uc640 \uac19\uc744 \uc218 \uc788\ub2e4. $$S_{t} = O_{t} = \\text{environment state}$$ - \ud589\uc704\uc790\uac00 Markov decision process \uc5d0 \uc788\ub2e4.","title":"Fully Obervable Environments"},{"location":"rl/4_rl_introduction/#markov-decision-processes","text":"MDPs \ub294 \ud2b9\uc815 \uc218\ud559\uc801 \uc18d\uc131\uc744 \uc758\ubbf8\ud55c\ub2e4. \uc608\ub97c \ub4e4\uc5b4 \uc790\uc5f0\uc218\uc758 \uc18d\uc131\uc740 \uc74c\uc758 \uc815\uc218\uac00 \uc544\ub2cc \uc815\uc218 \uc774\ub2e4. \uc6b0\ub9ac\ub294 \uc74c\uc758 \uc815\uc218\uac00 \uc544\ub2cc \uc815\uc218\ub97c \uc790\uc5f0\uc218\uc758 \uc18d\uc131\uc744 \ub9cc\uc871\ud55c\ub2e4\uace0 \ud558\uace0 \uc790\uc5f0\uc218\ub77c\uace0 \uce6d\ud558\uae30\ub3c4 \ud55c\ub2e4.","title":"Markov decision processes"},{"location":"rl/4_rl_introduction/#_9","text":"\uc544\ub798\uc758 \uc870\uac74\uc744 \ucda9\uc871\ud558\ub294 \uacb0\uc815 \uacfc\uc815\uc744 Markov \ub77c\uace0 \ud55c\ub2e4. A decision process is Markov if p == probability joint probability of r, s given $S_{t}, A_{t}$ is same as given $H_{t}, A_{t}$ $$ p(r,s| S_{t}, A_{t}) = p(r,s| H_{t}, A_{t})$$ \ud604\uc7ac\ub97c \uc8fc\uba74 \ubbf8\ub798\ub294 \uacfc\uac70\ub85c \ubd80\ud130 \ub3c5\ub9bd\uc801\uc774\ub2e4. The future is independent of the past given the present $$ H_{t} \\to S_{t} \\to H_{t+1} $$ \ud574\ub2f9 \uc18d\uc131\uc744 \ub9cc\uc871\ud558\ub294 state \ub97c \uc54c\uac8c \ub418\uba74 \uc5ed\uc0ac\ub97c \ubc84\ub824\ub3c4 \ub41c\ub2e4. \uc608\ub97c \ub4e4\uc5b4 stationary \ud658\uacbd \uc0c1\ud0dc\ub294 Markov \uc774\ub2e4. \uc5ed\uc0ac $H_{t+1}$\ub294 Markov \uc774\ub2e4.","title":"\uc815\uc758"},{"location":"rl/4_rl_introduction/#partially-observable-environments","text":"Agent \uac00 \uc815\ubcf4\uc758 \uc77c\ubd80\ubd84\ub9cc \ubc1b\ub294\ub2e4. - \ud3ec\ucee4\uce74\ub4dc \uac8c\uc784 - observation \uc774 Markov \uac00 \uc544\ub2c8\ub2e4. - patially obsevable Markov decision process (POMDP) - \ud658\uacbd \uc0c1\ud0dc\uac12\uc740 Markov \uc774\uc9c0\ub9cc \ud589\uc704\uc790\uac00 \uc774\uac78 \uc54c \uc218 \uc5c6\ub2e4.","title":"Partially Observable Environments"},{"location":"rl/4_rl_introduction/#agent-state_1","text":"angent state \ub294 \uc5ed\uc0ac\uc5d0 \ub300\ud55c \ud568\uc218\uc774\ub2e4. $$ \\text{agent state} = f: H \\to S $$ \ud589\uc704\uc790\uc758 \uc561\uc158\uc740 \uc0c1\ud0dc\uc5d0 \uc758\uc874\ud55c\ub2e4. State update function == f $$S_{t+1} = f(S_{t},A_{t},R_{t+1},O_{t+1})$$ \ud589\uc704\uc790\ub294 t \uc5d0 \uc788\uc74c $S_t$ \ub97c \uc0ac\uc6a9\ud574 $A_t$ \ub97c \uacb0\uc815\ud558\uace0 \uc2e4\ud589. \ud658\uacbd\uc774 $R_{t+1}, O_{t+1}$\uc744 \uc0dd\uc131. \ud589\uc704\uc790\ub294 \uc774\uc81c $t + 1$ \uc5d0 \uc788\uc74c $S_{t+1}$ \uc744 $f(S_t, A_t, R_{t+1}, O_{t+1})$ \uc744 \uc0ac\uc6a9\ud574 \ubcc0\uacbd \uad00\uc2b5\uc801\uc73c\ub85c t \ub294 \ud589\uc704\uc790\uac00 \ud658\uacbd\uc5d0\uc11c \uc561\uc158\uc744 \ubcf4\ub0b4\ub294 \uc2dc\uc810\uc784 \ud589\uc704\uc790\uc758 \uc0c1\ud0dc\ub294 \ud658\uacbd\uc758 \uc0c1\ud0dc\ubcf4\ub2e4 \ud6e8\uc52c \uc791\ub2e4.","title":"Agent state"},{"location":"rl/4_rl_introduction/#example","text":"\ubd80\ubd84 \uad00\ucc30\uc774 \uac00\ub2a5\ud55c \ud658\uacbd\uc5d0\uc11c \ud589\uc704\uc790\uc758 \uc0c1\ud0dc\ub97c \ub9cc\ub4e4\uc5b4\ubcf4\uc790. \ud589\uc704\uc790\ub294 2\ubc88 \ucc98\ub7fc \ud658\uacbd\uc758 \uc77c\ubd80\ubd84\uc744 observation \uc73c\ub85c \ubc1b\ub294\ub2e4. \ub9cc\uc57d $S_{t} = O_{t}$\ub97c \uc0ac\uc6a9\ud588\ub2e4\uba74 3\ubc88 \ucc98\ub7fc \ub450\uac1c\uc758 \ub2e4\ub978 observation\uc744 \uad6c\ubd84 \ud560 \ubc29\ubc95\uc774 \uc5c6\ub2e4. \uc989 \ud589\uc704\uc790\uc758 \uc0c1\ud0dc\uac00 Markov \uac00 \uc544\ub2cc \uc0c1\ud0dc\uac00 \ub418\uc5c8\ub2e4. \uc5b4\ub5bb\uac8c \ud558\uba74 \ud589\uc704\uc790\uc758 \uc0c1\ud0dc\ub97c Markov \ud558\uac8c \ud560 \uc218 \uc788\uc744\uae4c? \ud589\uc704\uc790\uac00 \uc5ed\uc0ac\ub97c \uc0ac\uc6a9\ud574 \uad6c\ubd84 \ud560 \uc218 \uc788\ub294 \uc0c1\ud0dc\ub97c \ub9cc\ub4e4\uba74 \ub41c\ub2e4.","title":"Example"},{"location":"rl/4_rl_introduction/#partially-observable-enviroments","text":"\ubd80\ubd84 \uad00\ucc30 \ud658\uacbd\uc5d0\uc11c \ud589\uc704\uc790\ub294 Markov \uc18d\uc131\uc744 \uac19\ub294 \uc0c1\ud0dc\ub97c \ub9cc\ub4e4\uc5b4\uc57c \ud55c\ub2e4. \ud589\uc704\uc790\uc758 \uc0c1\ud0dc \uc608\uc81c \ub9c8\uc9c0\ub9c9 \uad00\ucc30: $S_{t} = O_{t}$ (\uc704\uc758 \ubbf8\ub85c \uc608\uc81c\ucc98\ub7fc \ub9cc\uc871\ub418\uc9c0 \uc54a\uc744\uc218 \uc788\uc74c) \ubaa8\ub4e0 \uc5ed\uc0ac: $S_{t} = H_{t}$ (\uc591\uc774 \ub108\ubb34 \ub9ce\uc744 \uc218 \uc788\uc74c) \uc21c\ucc28\uc801\uc73c\ub85c \ubcc0\ud654\ud558\ub294 \uc0c1\ud0dc: $S_{t} = f(S_{t-1}, O_{t})$ \uc704\uc758 \ubbf8\ub85c\uc5d0\uc11c\ub294 \uc2dc\uc791\uc810\uc744 \uae30\uc900\uc73c\ub85c \ud558\ub294 \ud3c9\uba74 \uc88c\ud45c\uacc4\ub97c \ucd94\uac00\ud558\uba74 \ub428 recurrent nerual network \ub85c \uad6c\ud604 \ub420\uc218 \uc788\uc74c \uac00\ub054 \uba54\ubaa8\ub9ac \ub77c\uace0\ub3c4 \ubd88\ub9bc \ud589\uc704\uc790\uc758 \uc0c1\ud0dc\uac00 Markov \uc18d\uc131\uc744 \ub9cc\uc871\ud558\uac8c \ud558\uae30\uac00 \uc27d\uc9c0 \uc54a\uc740 \uacbd\uc6b0\uac00 \ub9ce\uc74c \uc0c1\ud0dc\ub294 \uc88b\uc740 police \uc640 \uc88b\uc740 value \uc744 \uc608\uce21\ud558\uae30 \uc704\ud55c \ucda9\ubd84\ud55c \uc815\ubcf4\ub97c \ud3ec\ud568 \ud574\uc57c\ud568.","title":"Partially Observable Enviroments"},{"location":"rl/4_rl_introduction/#policy","text":"Policy \ub294 \ud589\uc704\uc790\uc758 \ud589\ub3d9\uc591\uc2dd\uc744 \uc815\uc758 \ud55c\ub2e4. \ud589\uc704\uc790 \uc0c1\ud0dc\uc5d0\uc11c action \uc73c\ub85c \uc5f0\uacb0\ub418\ub294 \ud568\uc218\ub2e4. $f: \\text{state} \\to \\text{action}$ \uacb0\uc815\ub860\uc801 \uc815\ucc45: $A = \\pi(S)$ \ud655\ub960\uc801 \uc815\ucc45: $ \\pi(A|S) = p(A|S) $","title":"Policy"},{"location":"rl/4_rl_introduction/#value-function","text":"The value function is the expected return condition on state $$ \\begin{align} v_{\\pi}(s) = & \\mathbb{E} [ G_{t} | S_{t} = s, \\pi ] \\\\ = & \\mathbb{E} [ R_{t+1} + \\gamma R_{t+2} + \\gamma^{2} R_{t+3} + ... | S_{t} = s, \\pi ] \\end{align} $$ The discount factor. $ \\gamma \\in [0, 1]$ \uc989\uac01\uc801\uc778 \ubcf4\uc0c1\uacfc \uc7a5\uae30 \ubcf4\uc0c1\uc5d0 \ub300\ud55c trade-off \ub97c \uc8fc\ub294 \uc6a9\ub3c4\ub85c \uc0ac\uc6a9 trade-off: a balance achieved between two desirable but incompatible features \ubbf8\ub85c \ud0c8\ucd9c\uc5d0\uc11c \uc124\uc815 \ud558\uba74 \ud589\uc704\uc790\ub294 \ud560\uc778 \ub418\uc9c0 \uc54a\uc740\ucd5c\ub300 \ubcf4\uc0c1\uc744 \ubc1b\uae30 \uc704\ud574 \ube68\ub9ac \ud0c8\ucd9c \ud560\ub824\uace0 \uc2dc\ub3c4. Value \ub294 \uc815\ucc45\uc5d0 \uc758\uc874\ud55c\ub2e4. \ubc14\ub78c\uc9c1\ud55c \ub2e4\ub984 \uc0c1\ud0dc\ub97c \ud3c9\uac00\ud558\ub294\ub300 \uc0ac\uc6a9 \ud560 \uc218 \uc788\ub2e4. actions \ub97c \uc120\ud0dd\ud558\uae30 \uc704\ud574 \uc0ac\uc6a9 \ud560 \uc218 \uc788\ub2e4.","title":"Value function"},{"location":"rl/4_rl_introduction/#bellman-equation","text":"Return \uc740 \uc7ac\uadc0\uc801 \ud615\uc2dd\uc73c\ub85c \ud45c\ud604 \ud560 \uc218 \uc788\ub2e4. $G_{t} = R_{t+1} + \\gamma G_{t+1}$ \uadf8\ub7ec\ubbc0\ub85c \ub2e4\uc74c\uacfc \uac19\ub2e4. $ a \\sim \\pi(s) $ action \uc774 \uc0c1\ud0dc s \uc77c\ud0dc policy \uc5d0 \uc758\ud574 \uacb0\uc815\ub428\uc744 \uc758\ubbf8($\\pi$ \uac00 \uacb0\uc815\ub860\uc801\uc77c \ub54c\ub3c4 \ub3d9\uc77c) $$ \\begin{align} v_{\\pi}(S_{t+1}) = & \\mathbb{E} [ G_{t+1} \\mid S_{t+1} = s, \\pi ] \\\\ \\\\ v_{\\pi}(s) = & \\mathbb{E} [ G_{t} \\mid S_{t} = s, A_{t} \\sim \\pi(s) ] \\\\ = & \\mathbb{E} [ R_{t+1} + \\gamma G_{t+1} \\mid S_{t} = s, A_{t} \\sim \\pi(s) ] \\\\ = & \\mathbb{E} [ R_{t+1} + \\gamma v_{\\pi}(S_{t+1}) | S_{t} = s, A_{t} \\sim \\pi(s) ] \\\\ \\end{align} $$ \uc704\uc758 \ud568\uc218\uac00 \uc788\ub2e4\uba74 \ud2b9\uc815 \uc0c1\ud669\uc5d0\uc11c\uc758 \ucd5c\uc801 \ud589\ub3d9\uc744 \uc544\ub798\uc758 \uc2dd\uc73c\ub85c \uad6c \ud560 \uc218 \uc788\ub2e4. \uc544\ub798\uc2dd\uc740 policy \uc5d0 \uc758\uc874\uc131\uc774 \uc5c6\ub2e4. \ub9cc\uc57d \uc81c\ud55c \ub41c \uc0c1\ud0dc\uc640 \ud589\ub3d9\uc774\ub77c\uba74 \uc6b0\ub9ac\ub294 \uc544\ub798\uc758 \ubc29\uc815\uc2dd\uc744 \ud480 \uc218 \uc788\ub2e4. $$ v_{*}(s) = \\underset{a}{\\operatorname{argmax}} \\mathbb{E} [ R_{t+1} + \\gamma v_{*}(S_{t+1}) | S_{t} = s, A_{t} = a ] \\\\ $$","title":"Bellman equation"},{"location":"rl/4_rl_introduction/#value-function-approximations","text":"\ud589\uc704\uc790\ub294 \uc885\uc885 approxmate value \ud568\uc218\ub97c \uc0ac\uc6a9\ud55c\ub2e4. \uc774\ub7f0 \ud568\uc218\uac00 \uc788\ub2e4\uba74 \uc6b0\ub9ac\ub294 \ucd5c\uc801\ud654\ub294 \uc544\ub2c8\uc9c0\ub9cc \uc798 \ub3d9\uc791\ud558\ub294 \ud589\uc704\uc790\ub97c \ub9cc\ub4e4 \uc218 \uc788\ub2e4.","title":"Value Function approximations"},{"location":"rl/4_rl_introduction/#modeloptional","text":"\ubaa8\ub378\uc740 \ud658\uacbd\uc774 \ub2e4\uc74c\uc5d0 \ubb34\uc5c7\uc744 \ud560 \uac83\uc778\uac00\ub97c \uc608\uce21\ud558\ub294\ub300 \uc0ac\uc6a9\ub41c\ub2e4. \ub2e4\uc74c \ud658\uacbd \uc0c1\ud0dc\uc744 \uc608\uce21 \ud55c\ub2e4. $$ P(s, a, s') \\approx P(S_{t+1} = s^{\\prime} \\mid S_{t} = s, A_{t} = a) $$ \ub2e4\uc74c \ubcf4\uc0c1\uc744 \uc608\uce21 $$ R(s, a) \\approx \\mathbb{E} [ R_{t} \\mid S_{t} = s, A_{t} = a ]$$","title":"Model(optional)"},{"location":"rl/4_rl_introduction/#maze-example","text":"\uc704\uc5d0\uc11c \uc815\uc758\ud55c \uac1c\ub150\ub4e4\uc744 \ubbf8\ub85c\uc5d0 \uc801\uc6a9 \uc2dc\ucf1c\ubcf4\uc790. \uadf8\ub9bc1. \ud658\uacbd \uc804\uccb4\ub97c \ubcf4\uc5ec\uc900\ub2e4. action: up, down, left, right reward: \ud55c step \ub9c8\ub2e4 -1 state: agent location \uadf8\ub9bc2. \ud654\uc0b4\ud45c\ub294 Policy \ub97c \uc758\ubbf8\ud55c\ub2e4. policy: \uc0c1\ud0dc\uac00 \uc8fc\uc5b4\uc84c\uc744\ub54c\uc758 \ud589\ub3d9\uc591\uc2dd $ f: \\text{state} \\to \\text{action} $ \uadf8\ub9bc3. value \uac12 \uc22b\uc790\ub294 \uac01 \uc0c1\ud0dc\uc758 value \uac12 $ v_{\\pi}(s)$ \ub97c \uc758\ubbf8 \uadf8\ub9bc4. Model \uadf8\ub9ac\ub4dc\uc758 \uaca9\uc790\ub294 \ub2e4\uc74c \uc0c1\ud0dc\ub85c\uc758 \ubd80\ubd84 \uc804\uc774 \ubaa8\ub378$P_{ss^{\\prime}}^{a}$\uc744 \uc758\ubbf8 \uc22b\uc790\ub294 \uac01 \uc0c1\ud0dc\ubcc4 \uc989\uac01 \ubcf4\uc0c1 $R_{ss^{\\prime}}^{a}$\uc744 \uc758\ubbf8","title":"Maze Example"},{"location":"rl/4_rl_introduction/#agent_1","text":"Value based No policy(implcit) Value function Policy based Policy Value function Actor Critic Policy == actior Value function == critic","title":"Agent \uad6c\ubd84"},{"location":"rl/4_rl_introduction/#agent-2","text":"Model Free Policy and/or Value Fuction No Model Model Based Optionally Policy and/or Value Fuction Model","title":"Agent \uad6c\ubd842"},{"location":"rl/4_rl_introduction/#learing-and-planning","text":"\uac15\ud654\ud559\uc2b5\uc5d0\ub294 \ud06c\uac8c \ub450 \uc885\ub958\uc758 \ubb38\uc81c\uac00 \uc788\uc74c \ud559\uc2b5 \ud658\uacbd\uc744 \ubaa8\ub974\uace0 \uc2dc\uc791 \ud589\uc704\uc790\ub294 \ud658\uacbd\uacfc \uc0c1\ud638 \uc791\uc6a9 \ud568 \uacc4\ud68d \ud589\ub3d9\ud558\uc9c0 \uc54a\uace0 \uc0dd\uac01\ub9cc \ud558\ub294\uac83. \ud658\uacbd \ubaa8\ub378\uc774 \uc8fc\uc5b4\uc9d0 \ud589\uc704\uc790\ub294 \uc8fc\uc5b4\uc9c4 \ubaa8\ub378\uc744 \uac00\uc9c0\uace0 \uacc4\ud68d\uc744 \uc0dd\uc131(\uc0c1\ud638 \uc791\uc6a9 \uc5c6\uc774)","title":"Learing and Planning"},{"location":"rl/4_rl_introduction/#prediction-and-control","text":"Prediction: Policy \ub97c \uc8fc\uba74 \ubbf8\ub798\ub97c \ud3c9\uac00\ud568 \uc9c0\ub3c4\ud559\uc2b5\uc744 \uc774\uacf3\uc5d0 \uc0ac\uc6a9 \ud560 \uc218 \uc788\uc74c. Control: \ubbf8\ub798\ub97c \ucd5c\uc801\ud654\ud568 (\uac00\uc7a5 \uc88b\uc740 \ubbf8\ub798\ub97c \ucc3e\uc74c) \uc544\ub798\uc758 \uc2dd\uacfc \uc5f0\uad00\ub418\uc5b4 \uc788\uc74c $$ \\pi_{*}(s) = \\underset{\\pi}{\\operatorname{argmax}} v_{\\pi}(s) $$","title":"Prediction and Control"},{"location":"rl/4_rl_introduction/#_10","text":"\ubaa8\ub4e0 \uad6c\uc131\uc694\uc18c\ub294 \ud568\uc218\uc784 Policy: $$ \\pi: \\text{state} \\to \\text{action} $$ Value function: $$ v: \\text{state} \\to \\text{value} $$ Model: $$ P_{ss^{\\prime}}^{a}: \\text{state} \\to \\text{next state} \\\\ R_{ss^{\\prime}}^{a}: \\text{state} \\to \\text{reward} $$ Status updates: $$ f: \\text{state, observation} \\to \\text{new state} $$ \uc704\uc758 \ud568\uc218\ub4e4\uc744 nn \uc73c\ub85c \ud45c\ud604 \ud558\uace0 deep learning \ubc29\ubc95\uc744 \uc0ac\uc6a9\ud574\uc11c \ucd5c\uc801\ud654 \ud560 \uc218 \uc788\uc74c \uc6b0\ub9ac\ub294 \uc885\uc885 \uc9c0\ub3c4\ud559\uc2b5\uc758 \uac00\uc815\uc778 idd, \uc640 stationarity \ub97c \ubb34\uc2dc\ud558\ub294\uacbd\uc6b0\uac00 \ub9ce\uae30 \ub54c\ubb38\uc5d0 \uc8fc\uc758 \ud574\uc57c\ud568.","title":"\ud589\uc704\uc790\uc758 \uad6c\uc131 \uc694\uc18c\ub97c \ud559\uc2b5 \ud558\ub294 \ubc29\ubc95"},{"location":"rl/4_rl_introduction/#atari-game","text":"\uac8c\uc784\uc758 \uaddc\uce59\uc744 \uc54c\uc9c0 \ubabb\ud55c\ub2e4\uace0 \uac00\uc815. \uac8c\uc784\uc744 \ud558\uba74\uc11c \ud559\uc2b5\ud568(\uc0c1\ud638\uc791\uc6a9) \uc870\uc774\uc2a4\ud2f1\uc744 \ud1b5\ud574 \ud589\ub3d9\uc744 \ud558\uace0 \ud53d\uc140\uacfc \uc810\uc218\ub97c \ubc1b\uc74c. \ud658\uacbd == \uc544\ud0c0\ub9ac \uac8c\uc784 \uc561\uc158 == \uc870\uc774\uc2a4\ud2f1 Observation == \ud544\uc140 Reward == \uc810\uc218","title":"Atari game \uc758 \uac00\uc815"},{"location":"rl/4_rl_introduction/#exploration-and-exploitation","text":"Exploration: \uc815\ubcf4\ub97c \ub354 \ubaa8\uc73c\ub294\uac83 Exploitation: \uc54c\uace0\uc788\ub294 \uc815\ubcf4\ub97c \ud65c\uc6a9\ud574 \ubcf4\uc0c1\uc744 \ucd5c\ub300\ud558 \ud558\ub294\uac83. \ub450\uac1c\ub97c \uc798 \uc870\uc808\ud558\ub294\uac8c \uc911\uc694.","title":"Exploration and Exploitation"},{"location":"rl/4_rl_introduction/#reference","text":"\ucc38\uc870 code","title":"Reference"},{"location":"rl/5_rl_exploration/","text":"2. Exploration and Exploitatin What is RL \uacb0\uc815 \ud558\ub294 \uac83\uc744, \ud559\uc2b5 \uc2dc\ud0a4\ub294 \ubc29\ubc95\uc5d0 \ub300\ud55c \uacfc\ud559 \ud589\uc704\uc790\ub294 \uc815\ucc45, \uac00\uce58 \ud568\uc218 \uadf8\ub9ac\uace0/\ub610\ub294 \ubaa8\ub378\ub4e4\uc744 \ud559\uc2b5 \ud560 \uc218 \uc788\ub2e4. \uc77c\ubc18\uc801\uc73c\ub85c \uc2dc\uac04\uacfc \uacb0\uacfc\uc5d0 \ub300\ud574 \uace0\ub824\ud574\uc57c \ud55c\ub2e4. \uacb0\uc815\uc740 \ubcf4\uc0c1, \ud589\uc704\uc790\uc758 \uc0c1\ud0dc, \ud658\uacbd\uc758 \uc0c1\ud0dc\uc5d0 \uc601\ud5a5\uc744 \uc900\ub2e4. \ub2e8\uc21c\ud654 \ud589\uc704\uc640 \ubcf4\uc0c1\uc758 \uc0c1\uad00\uad00\uacc4\ub97c \ud0d0\uad6c\ud558\uae30 \uc704\ud574 \ub2e4\ub978 \ubd80\ubd84\ub4e4\uc744 \uace0\uc815 \uc2dc\ud0a4\uc790. \ud604\uc2e4 \uc5ec\ub7ec\uac1c\uc758 \uc0c1\ud0dc\uac00 \uc788\uace0 \uc5ec\ub7ec\uac1c\uc758 \ud589\uc704\uac00 \uc788\ub2e4. \ud558\ub098\uc758 \ud589\uc704\uac00 \ub2e4\ub978 \uc0c1\ud0dc\uc640 \ubcf4\uc0c1\uc5d0 \uc601\ud5a5\uc744 \uc900\ub2e4. \ud589\uc704\uc5d0 \ub300\ud55c \ubbf8\ub798\ub294 \ud655\ub960\uc801\uc73c\ub85c \uc8fc\uc5b4\uc9c0\uace0 \ud574\ub2f9 \ud655\ub960 \ubd84\ud3ec\ub294 \uc2dc\uac04\uc5d0 \uc758\ud574 \ubcc0\ud55c\ub2e4. \ud604\uc2e4\uc758 \uad6c\uc131\uc694\uc18c \uc5ec\ub7ec\uac1c\uc758 \uc0c1\ud0dc \uc5ec\ub7ec\uac1c\uc758 \ud589\uc704 \ud589\uc704\uac00 \ubbf8\ub798\uc5d0 \uc601\ud5a5\uc744 \uc90c \ubbf8\ub798 == \ubcf4\uc0c1 + \uc0c1\ud0dc \ud589\uc704\uc5d0 \ub300\ud55c \ubbf8\ub798\ub294 \ud655\ub960\uc801\uc73c\ub85c \uc8fc\uc5b4\uc9d0 \ubbf8\ub798\uc758 \ud655\ub960 \ubd84\ud3ec\ub294 \uc2dc\uac04\uc5d0 \uc758\ud574 \ubcc0\ub3d9 \ub420 \uc218 \uc788\uc74c \uc0c1\ud0dc\ub294 \uc2dc\uac04\uc5d0 \uc758\ud574 \ubcc0\uacbd \ub420 \uc218 \uc788\uc74c \ub2e8\uc21c\ud654 \ud55c \uac1c\uc758 \uc0c1\ud0dc\ub9cc \uc0dd\uac01\ud558\uc790. \uc0c1\ud0dc\ub294 \ud55c \uac1c. \uc5ec\ub7ec \uac1c\uc758 \uc561\uc158 \uacfc\uac70\uc758 \ud589\uc704\uac00 \ubbf8\ub798\uc5d0 \uc601\ud5a5\uc744 \uc8fc\uba74 \ubcf5\uc7a1\ud558\ub2e4. \ube44\uc5f0\uc18d\uc801 \uad6c\uc870 == \uacfc\uac70\uc758 \ud589\uc704\uac00 \ubbf8\ub798\uc5d0 \uc601\ud5a5\uc744 \uc8fc\uc9c0 \uc54a\uc74c. $A_{t}$\ub97c \uc870\uac74\uc73c\ub85c \uc8fc\uc5c8\uc744\ub54c $R_{t}$ \uc758 \ud655\ub960 \ubd84\ud3ec\ub294 \uace0\uc815\ub418\uc5b4 \uc788\uc74c \ub610\ud55c \uc2dc\uac04\uacfc \ub3c5\ub9bd\uc801\uc784 \uc608\uc81c \ud30c\ub791 \ub808\ubc84\uc640 \ube68\uac15 \ub808\ubc84\uac00 \uc788\ub2e4. \uccab \ubc88\uc9f8 \uc2dc\ub3c4\uc5d0\uc11c \ud30c\ub791 \ub808\ubc84\ub97c \ub2f9\uae30\uba74 \uce58\uc988\uac00 \ub098\uc654\ub2e4. \ub450 \ubc88\uc9f8 \uc2dc\ub3c4\uc5d0\uc11c \ube68\uac15 \ub808\ubc84\ub97c \ub2f9\uae30\uba74 \uc804\uae30 \uc1fc\ud06c\uac00 \ub098\uc654\ub2e4. \uc138 \ubc88\uc9f8 \uc2dc\ub3c4\uc5d0\uc11c \uce58\uc988\uc744 \ubc1b\uae30 \uc704\ud574\uc11c\ub294 \ubb34\uc5c7\uc744 \ub2f9\uaca8\uc57c \ud560\uae4c? \ud0d0\uc0c9 vs \ud65c\uc6a9 100 \uacf3\uc758 \uc74c\uc2dd\uc810\uc774 \uc788\ub2e4 10 \uacf3\uc758 \uc74c\uc2dd\uc810\ub9cc \uac00\ubcf4\uace0 \ud2b9\uc815\ud55c \uacf3\uc774 \ucd5c\uace0 \ub77c\uace0 \ud560 \uc218 \uc788\ub294\uac00? online \uacb0\uc815 \ubb38\uc81c\ub294 \uae30\ubcf8\uc801\uc73c\ub85c 2\uac1c\uc758 \uc120\ud0dd\uc774 \uc788\ub2e4. \ud0d0\uc0c9: \uc9c0\uc2dd\uc744 \uc99d\uac00 \uc2dc\ud0b4 \ud65c\uc6a9: \uc131\uacfc\ub97c \ucd5c\ub300\ud654 \ud558\uae30 \uc704\ud574 \uae30\uc874\uc758 \uc9c0\uc2dd\uc744 \uc774\uc6a9 \uc81c\uc77c \uc88b\uc740 \uc7a5\uae30 \uc804\ub7b5\uc740 \ub2e8\uae30\uc801 \uc774\uc775\uc744 \ud76c\uc0dd \uc2dc\ucf1c\uc57c \ud560 \uc218 \uc788\ub2e4. \uc6b0\ub9ac\ub294 \uc804\uccb4\uc801\uc73c\ub85c \ucd5c\uc801\ud654\ub41c \uacb0\uc815\ub4e4\uc744 \ucc3e\uae30 \uc704\ud574 \uc815\ubcf4\ub97c \ubaa8\uc544\uc57c \ud55c\ub2e4. One-Armed bandit \ud55c \uac1c\uc758 \ub808\ubc84\ub97c \uac00\uc9c4 \ube60\uc9d5\ucf54 \uae30\uacc4\uac00 \uc788\ub2e4. \ub808\ubc84\ub97c \ub2f9\uae30\uba74 \ud655\ub960\uc801\uc73c\ub85c \ud2b9\uc815 \uae08\uc561\uc774 \ub098\uc628\ub2e4. \ubbf8\ub798\ub294 \ud604\uc7ac\uc5d0 \ub3c5\ub9bd\uc801\uc774\ub2e4. Multi-Armed bandit \uc0c1\ud669 \uc5ec\ub7ec \uac1c\uc758 \ub808\ubc84\ub97c \uac00\uc9c4 \ube60\uc9d5\ucf54 \uae30\uacc4\uac00 \uc788\ub2e4. \ub808\ubc84\uac00 10\uac1c\uac00 \uc788\uace0 \ub808\ubc84\ub97c \ub2f9\uae38 \ub54c \ub9c8\ub2e4 \ud2b9\uc815 \uae08\uc561\uc774 \ub098\uc628\ub2e4. \uae08\uc561\uc740 \ud2b9\uc815 \ub808\ubc84\uc5d0 \uc758\uc874\uc801\uc774\uba70 \ud655\ub960\uc801\uc73c\ub85c \uc561\uc218\uac00 \uacb0\uc815\ub41c\ub2e4. \ud615\uc2dd\ud654(formalize) \uc0c1\ud0dc\ub294\ub2e8 \ud55c \uac1c\uc774\ub2e4. \uc5ec\ub7ec \uc561\uc158 \uc14b\uc744 $A$ \ub77c\uace0 \ud558\uc790. \ud589\uc704 == $0..N$ \ub808\ubc84 \uc911 \ud55c \uac1c\ub97c \ub2f9\uae30\ub294 \ud589\uc704 \uc561\uc158\uc14b == {\"0\ubc88 \ub2f9\uae30\uae30\",...,\"N \ubc88 \ub2f9\uae30\uae30\"} \uac01 \ub2e8\uacc4\uc5d0 \ud589\uc704\uc790\ub294 \ud589\uc704 $A_{t} \\in A $\ub97c \uc120\ud0dd\ud55c\ub2e4. \ud658\uacbd\uc740 \ubcf4\uc0c1 $R_{t}$\ub97c \uc0dd\uc0b0\ud55c\ub2e4. \ubcf4\uc0c1\uc740 $P(r \\mid a)$ \uc774\uba70 \uace0\uc815\ub418\uc5b4 \uc788\ub2e4. \ud558\uc9c0\ub9cc \ud574\ub2f9 \ud655\ub960 \ubd84\ud3ec\ub97c \uc54c\uc9c0 \ubabb\ud55c\ub2e4. \ubaa9\uc801\uc740 \ud2b9\uc815 \uc2dc\uac04 \ub3d9\uc548 \ub204\uc801 \ubcf4\uc0c1\uc744 \ucd5c\ub300\ud654 \ud558\ub294\uac83\uc774\ub2e4. $\\sum_{i=1}^{t}R_{i}$ \ubbf8\ub798(\ubcf4\uc0c1)\ub294 \ud604\uc7ac\uc758 \uc120\ud0dd\uacfc \ub3c5\ub9bd\uc801\uc774\ub2e4. \uc0dd\uac01 \ud560 \uac83 \ud2b9\uc815 \uc2dc\uac04 \uc989 100 \ud68c \ub3d9\uc548\uc758 \ub204\uc801 \ubcf4\uc0c1\uc744 \ucd5c\ub300\ud654 \ud560\ub824\uba74 \uba87 \ud68c\ub97c \ud0d0\uc0c9\uc5d0 \uc4f0\uace0 \uba87 \ud68c\ub97c \ud65c\uc6a9\uc5d0 \uc0ac\uc6a9\ud574\uc57c \ud560\uae4c? \uc9c0\ub3c4 \ud559\uc2b5\uc5d0\uc11c \ud3c9\uac00 \uae30\uc900\uc774 \ud14c\uc2a4\ud2b8 \uc14b\uc778\uac83\uacfc\ub294 \uc870\uae08 \ub2e4\ub974\ub2e4. \ud2b8\ub808\uc774\ub2dd \uacfc \ud14c\uc2a4\ud2b8 \uc14b\uc774 \ub3d9\uc2dc\uc5d0 \uc774\ub8e8\uc5b4 \uc9c0\ub294 \ub290\ub08c. \uc218\uc2dd\ud654 \ub204\uc801 \ubcf4\uc0c1\uc744 \ucd5c\ub300\ud654 \ud558\uae30 \uc704\ud574\uc11c\ub294 \uac01 \ub808\ubc84\uc758 \uac1c\ubcc4 \ubcf4\uc0c1 \uae30\ub300\uac12\uc744 \uc54c\uc544\uc57c \ud55c\ub2e4. \ud0d0\uc0c9\uacfc \ud65c\uc6a9\uc758 \uc804\ub7b5\uc744 \ud0dd\ud574\uc57c \ud55c\ub2e4. Action value - \ud55c \uac1c \ud55c \uac1c\uc758 \ud314\uc744 \uac00\uc9c4 \ube60\uc9d5\ucf54 \uae30\uacc4\uc758 \uac1c\ubcc4 \ubcf4\uc0c1\uc744 \uae30\ub300\uac12\uc73c\ub85c \ud45c\ud604\ud574 \ubcf4\uc790. \ud574\ub2f9 \ud314\uc744 $a_0$ \uc774\ub77c\uace0 \uce6d\ud558\uc790. \uc561\uc158\uc744 \ud589\ud55c \ud6c4 \ubc1b\ub294 \ubcf4\uc0c1\uc774 \uc815\ud574 \uc9c0\ub294 \ud568\uc218\ub97c q \ub77c\uace0 \uc815\uc758\ud558\uc790. $q: \\text{action} \\to \\text{reward}$ \uc544\ub798\ub294 \uc9c4\uc9dc \ubcf4\uc0c1 \ud568\uc218\uc774\uba70 \ud589\uc704\uc790\ub294 \uc54c\uc9c0 \ubabb\ud55c\ub2e4 \uadf8\ub7ec\ubbc0\ub85c \ucd94\uce21 \ud574\uc57c \ud55c\ub2e4. $$ q(a) = \\mathbb{E} [ R_{t} ] $$ \uc6b0\ub9ac\ub294 \uc0c1\ud638\uc791\uc6a9\uc744 \ud1b5\ud574 (\uc0d8\ud50c\ub9c1) \uc704\uc758 \uc9c4\uc9dc \ubcf4\uc0c1 \ud568\uc218\ub97c \ucd94\uce21 \ud574\uc57c \ud55c\ub2e4. \ud3c9\uade0 \uac12\uc744 \uc0ac\uc6a9\ud574 \ubcf4\uc790. $$ Q_{t}(a) = \\frac{\\sum_{n=1}^{T}R_{n}}{T} $$ Action value - \uc5ec\ub7ec \uac1c \uc704\uc758 \uc2dd\uc744 \ud655\uc7a5\ud574 \ubcf4\uc790. \uc5ec\ub7ec \uac1c\uc758 \uc561\uc158 \uc911 \ud55c \uac1c\ub97c \uc120\ud0dd \ud568\uc73c\ub85c \uc870\uac74\ubd80 \ud655\ub960\uc2dd\uc744 \uc138\uc6b0\uc790. \uc9c4\uc9dc q \ud568\uc218 $$ q(a) = \\mathbb{E} [ R_{t} \\mid A_{t} = a ] $$ \uc0d8\ud50c\ub9c1\uc744 \ud1b5\ud55c \ucd94\uce21 action totalReward \ub2f9\uae34 \ud69f\uc218 \ud3c9\uade0 \uc218\uc2dd 0 8 2 4 $Q_{t}(0) = \\frac{8}{2}$ 1 10 1 10 $Q_{t}(1) = \\frac{10}{1}$ $L$ \uc740 \uc870\uac74\uc774 True \uc77c \uacbd\uc6b0 1 \uc544\ub2c8\uba74 0\uc744 \ub9ac\ud134 \ud558\ub294 \ud568\uc218 \ub77c\uace0 \uc815\uc758 \ud558\uc790. \uadf8\ub7ec\uba74 \ucd94\uce21 \ubcf4\uc0c1 \ud568\uc218\ub294 \uc544\ub798\uc640 \uac19\uc774 \uc815\uc758 \ud560 \uc218 \uc788\ub2e4. $$ Q_{t}(a) = \\frac{ \\sum_{n=1}^{t}R_{n}L(A_{n}=a) }{ \\sum_{n=1}^{t}L(A_{n}=a) }$$ \uc810\uc9c4\uc801 Action value \ud3c9\uade0 \ud568\uc218\ub294 \uae30\uc874 \ud3c9\uade0 \uac12\uc5d0 \ubcc0\ud654\ub7c9\uc744 \uc801\uc6a9\ud574 \uc8fc\ub294 \ubc29\uc2dd\uc73c\ub85c \uac19\uc740 \uacb0\uacfc\ub97c \ubc1b\uc744 \uc218 \uc788\ub2e4. \uc704\uc758 \uadf8\ub9bc\uc740 $Q_{1} = 1$ \uc774\uace0 $R_{2} = 2$ \uc77c\ub54c \uae30\uc874 \ud3c9\uade0 \ub300\ube44 \ubcc0\ud654\ub7c9\uc744 $R_{2}$, $Q_{1}$ \uc73c\ub85c \uad6c\ud560 \uc218 \uc788\uc74c\uc744 \ub3c4\uc2dd\ud654 \ud588\ub2e4. $q$\ub294 \uc9c4\uc9dc action value \uc774\uace0 $Q_{t}$ \ub294 \ucd94\uce21 \uc774\ub2e4. $$ Q_{t}(A_{t}) = Q_{t-1}(A_{t}) + \\alpha_{t} \\left( R_{t} - Q_{t-1}(A_{t})\\right) $$ $$ \\alpha_{t} = \\frac{1}{N_{t}(A_{t})}, N_{t}(A_{t}) = N_{t-1}(A_{t}) + 1, \\text{ and }, N_{0} = 0, \\forall a $$ $\\alpha$ \ub97c \ub2e8\uacc4 \uc0ac\uc774\uc988\ub77c\uace0 \ud55c\ub2e4. \uc950 \uc608\uc81c1 \ubcf4\uc0c1 \uce58\uc988: $R = +1$ \ucda9\uaca9: $R = -1$ $Q_{2}$ \uc5d0\uc11c\uc758 action value $Q_{2}(\\text{Red}) = -1$ $Q_{2}(\\text{Blue}) = +1$ $Q_{3}$\uc5d0\uc11c \ube68\uac15\uc744 \ub2f9\uaca8\uc57c \ud560\uae4c \ud30c\ub791\uc744 \ub2f9\uaca8\uc57c \ud560\uae4c? \ud30c\ub791\uc744 \ub2f9\uaca8\uc57c \ud55c\ub2e4. \uc561\uc158 \uac12\uc774 \ub354 \ud06c\uae30 \ub54c\ubb38\uc774\ub2e4. \uc950 \uc608\uc81c2 \ubcf4\uc0c1 \uce58\uc988: $R = +1$ \ucda9\uaca9: $R = -1$ $Q_{5}$ \uc5d0\uc11c\uc758 action value $Q_{5}(\\text{Red}) = -1$ $Q_{5}(\\text{Blue}) = -0.75$ $Q_{6}$\uc5d0\uc11c \ube68\uac15\uc744 \ub2f9\uaca8\uc57c \ud560\uae4c \ud30c\ub791\uc744 \ub2f9\uaca8\uc57c \ud560\uae4c? \uc774\uc81c \ub2e4\ub978 \ub808\ubc84\ub97c \uc2e4\ud5d8\ud574 \ubd10\uc57c \ud558\uc9c0 \uc54a\uc744\uae4c? \uc5b8\uc81c greedy \ud558\uac8c action value \ub97c \uc0ac\uc6a9 \ud558\ub294\uac78 \uba48\ucdb0\uc57c \ud560\uae4c? Regret \uc5b4\ub5bb\uac8c \ud0d0\uc0c9\uacfc \ud65c\uc6a9\uc744 \ucd5c\uc801\ud654 \ud560 \uac83\uc778\uac00? \ud0d0\uc0c9\uacfc \ud65c\uc6a9\uc774 \ucd5c\uc801\ud654 \ub418\uc5c8\ub2e4\uace0 \ud560 \uc218 \uc788\ub294 \ud3c9\uac00 \uae30\uc900\uc774 \ubb34\uc5c7\uc778\uac00? \uc6b0\ub9ac\uac00 \ucd5c\uc801 value \uac12\uc744 \uc54c\uace0 \uc788\ub2e4\uba74 $$ v_{*} = \\underset{a \\in A}{\\operatorname{max}} q(a) = \\underset{a}{\\operatorname{max}} \\mathbb{E} [ R_{t} \\mid A_{t} = a ]$$ Regret \ub294 \ud2b9\uc815 \ub2e8\uc77c \uc2dc\uc810\uc5d0\uc11c \uc190\uc2e4\ub41c \uae30\ud68c\ub77c\uace0 \uc815\uc758 \ud558\uc790. \uc798\ubabb\ub41c \uc120\ud0dd\uc73c\ub85c \ud2b9\uc815 \uc2dc\uc810\uc5d0 \ucd5c\ub300\ub85c \ubc1b\uc744 \uc218 \uc788\ub294 \uc591\uc744 \ubc1b\uc9c0 \ubabb\ud558\uba74 \ub098\uc911\uc5d0 \uc6b0\ub9ac\ub294 \ud6c4\ud68c\ud55c\ub2e4. \ud574\ub2f9 \ub2e8\uacc4\uc5d0\uc11c \uc5bc\ub9cc\ud07c \uc190\uc2e4\uc744 \ubcf4\uc558\ub0d0\ub294 $\ucd5c\ub300\ub7c9 - \uc120\ud0dd\uc73c\ub85c\ubc1b\uc740\ub7c9$ \uc73c\ub85c \ud45c\ud604 \ud560 \uc218 \uc788\ub2e4. $$ \\text{regre}t_{t} = v_{*} - q(A_{t}) $$ \ud589\uc704\uc790\ub294 \ud559\uc2b5 \ub3c4\uc911 \ubcfc \uc218\ub3c4 \uc54c \uc218\ub3c4 \uc5c6\ub2e4. \ud558\uc9c0\ub9cc \uc6b0\ub9ac\uac00 \uc2e4\ud5d8\uc774 \ub05d\ub09c \ud6c4 \ub2e4\ub978 \uc54c\uace0\ub9ac\uc998\ub4e4\uc744 \ud3c9\uac00\ud558\ub294\ub300\ub294 \uc720\uc6a9\ud558\ub2e4. \ud0d0\uc0c9\uacfc \ud65c\uc6a9\uc758 \ucd5c\uc801\ud654\ub294 \ud6c4\ud68c\uc758 \ucd1d\ud569\uc744 \ucd5c\uc18c\ud654 \ud558\ub294\uac83\uacfc \uac19\ub2e4. $$ L_{t} = \\sum_{i=1}^{t}(v_{*} - q(a_{i}))$$ \ub204\uc801 \ubcf4\uc0c1 \ucd5c\ub300\ud654 $\\equiv$ \ud6c4\ud68c \ucd1d\ud569 \ucd5c\uc18c\ud654 \ubcf4\uc0c1 \ucd5c\ub300\ud654\ub294 \ubb34\ud55c\uc73c\ub85c \uac08 \uc218 \uc788\ub2e4. \ucd1d\ud569 \ucd5c\uc18c\ud654\ub294 \ucd5c\ub300\ud654 \ubcf4\ub2e4 \uc218\ub834 \ud560 \uac00\ub2a5\uc131\uc774 \ub192\ub2e4. \uc5b8\uc81c\ub098 0 \ubcf4\ub2e4 \ud070\uac12, \uc989 \uc591\uc218 0 \uc5d0 \uac00\uae4c\uc6b8 \uc218\ub85d \uc88b\uc74c \ub204\uc801 \ucd1d\ud569\uc740 \uc5ec\ub7ec \uc5d0\ud53c\uc18c\ub4dc \ub4e4\ub85c \ud655\uc7a5 \ub420 \uc218 \uc788\ub2e4. \ud55c \uac1c \uc5d0\ud53c\uc18c\ub4dc \ubcf4\ub2e4 \ud559\uc2b5 \uc804\uccb4\ub85c(\uc5ec\ub7ec \uac1c\uc758 \uc5d0\ud53c\uc18c\ub4dc) \uad00\uc810\uc744 \ud655\ub300 \ud558\uc790. Regret with greedy \ud0d0\uc695 \uc54c\uace0\ub9ac\uc998\uc744 \uc0ac\uc6a9 \ud558\uc5ec \uc544\ub798\uc640 \uac19\uc740 \uacb0\uacfc\ub97c \uc5bb\uc5c8\ub2e4\uace0 \uac00\uc815\ud574 \ubcf4\uc790. \ub808\ubc84 \ud655\ub960 \ubcf4\uc0c1 \ud655\ub960 * \ubcf4\uc0c1 $q(a) = \\mathbb{E}[R \\mid A] $ \ube68\uac15 $P(\\text{cheese} \\mid R) = 0.9$ +1 0.9 0.8 \ube68\uac15 $P(\\text{shock} \\mid R) = 0.1$ -1 -0.1 \ud30c\ub791 $P(\\text{cheese} \\mid B) = 0.1$ +1 0.1 -0.8 \ud30c\ub791 $P(\\text{shock} \\mid B) = 0.9$ +1 -0.9 \uc704\uc640 \uac19\uc740 \ud655\ub960\ud45c\uac00 $q(a)$ \uc77c\ub54c \ud0d0\uc695 \uc54c\uace0\ub9ac\uc998\uc744 \uc0ac\uc6a9\ud574\uc11c \ucc98\uc74c \ub450\ubc88\uc5d0 \ud30c\ub791->\uce58\uc988, \ube68\uac15-> \ubc88\uac1c\uac00 \ub098\uc624\uba74 \uc544\ub798\uc640 \uac19\uc774 \uc608\uce21 \ud568\uc218\uac00 \uc798\ubabb \uc124\uc815\ub418\uc5b4 \ud30c\ub791\ub9cc \uacc4\uc18d \ub2f9\uae30\uac8c \ub41c\ub2e4 (\ubb3c\ub860 \ud30c\ub791->\ubc88\uac1c, \ube68\uac15->\uce58\uc988\uac00 \ub098\uc624\uba74 \uc88b\uc740\uac83\ub9cc \ud55c\ub2e4.) $Q_{5}(\\text{Red}) = -1$ $Q_{5}(\\text{Blue}) = -0.75$ \uc774\ud6c4\uc758 regret \ub294 $\\text{regre}t_{t} = v_{*} - q(a_{t}) = 0.8 - (-0.8) = 1.6$ \uac00 \uc9c0\uc18d\uc801\uc73c\ub85c t \ub9c8\ub2e4 \ubc1c\uc0dd\ub41c\ub2e4. regret \uac00 \ubb34\ud55c\uc774 \ucee4\uc9c8\uc218 \uc788\ub2e4. \uc6b0\ub9ac\ub294 \uc5bc\ub9c8\ub098 \ube68\ub9ac \uc99d\uac00\ud558\ub294 \uac00\uc5d0 \uad00\uc2ec\uc774 \uc788\ub2e4. \ud0d0\uc695 \uc815\ucc45\uc740 \uc120\ud615 \ud6c4\ud68c\uc2dd\uc774 \ub9cc\ub4e4\uc5b4 \uc9c4\ub2e4. $1.6t$ Counting Regret \ud589\uc704 \ud6c4\ud68c$\\Delta_{a}$\ub97c \ucd5c\uc801\uac12\uacfc \ud589\uc704\uc758 \uc9c4\uc9dc\uac12\uacfc\uc758 \ucc28\uc774 \ub77c\uace0 \uc815\uc758\ud558\uc790. $$\\Delta_{a} = v_{*} - q(a)$$ \ud6c4\ud68c \ucd1d\ud569\uc740 \ud589\uc704\ub2f9 \uc120\ud0dd\ub41c \ud69f\uc218\uc640 \ud589\uc704 \ud6c4\ud68c\uac12\uc758 \uacf1\uc73c\ub85c \ub098\ud0c0\ub0bc \uc218 \uc788\ub2e4. $$L_{t} = \\sum_{i=1}^{t} v_{*} - q(a_{i}) = \\sum_{a \\in A} N_{t}(a)(v_{*} - q(a)) = \\sum_{a \\in A} N_{t}(a)\\Delta_{a}$$ \uc88b\uc740 \uc54c\uace0\ub9ac\uc998\uc740 \uc561\uc158 \ud6c4\ud68c \uac12\uc774 \ub192\uc740 \uc561\uc158\uc744 \uc801\uac8c \uc120\ud0dd\ud558\ub294 \uac83\uc774\ub2e4. \ud558\uc9c0\ub9cc \uc6b0\ub9ac\ub294 \uc561\uc158 \ud6c4\ud68c \uac12\uc744 \uc54c\uc9c0 \ubabb\ud55c\ub2e4. Exploration \uc6b0\ub9ac\ub294 \uac12\ub4e4\uc744 \ucc3e\uae30 \uc704\ud574 \ud0d0\uc0c9 \ud574\uc57c \ud55c\ub2e4. \ub9ce\uc774 \uc0ac\uc6a9\ub418\ub294 \ubc29\ubc95 $\\varepsilon\\text{-greedy}$ \uc774\ub2e4. \ud655\ub960\uc774 $1 - \\varepsilon)$ \uc774\uba74 greedy action \uc744 \uc120\ud0dd\ud55c\ub2e4. \ud655\ub960\uc774 $\\varepsilon$ \uc774\uba74 random action \uc744 \uc120\ud0dd\ud55c\ub2e4. \ucda9\ubd84 \ud560\uae4c? $\\varepsilon$\uc744 \uc5b4\ub5bb\uac8c \uc120\ud0dd\ud574\uc57c \ud560\uae4c? $\\varepsilon\\text{-greedy}$ \uc54c\uace0\ub9ac\uc998 \ud0d0\uc695 \uc54c\uace0\ub9ac\uc998\uc740 \uc798\ubabb\ub41c \ucd5c\uc801\uac12\uc744 \uc601\uc6d0\uc774 \uc120\ud0dd \ud560 \uc218 \uc788\ub2e4. \ud0d0\uc695 \uc54c\uace0\ub9ac\uc998\uc740 \uc120\ud615\uc801\uc778 \ud6c4\ud68c \uae30\ub300\uac12\uc744 \uac00\uc9c4\ub2e4. $\\varepsilon\\text{-greedy}$ \uc54c\uace0\ub9ac\uc998\uc740 \ud0d0\uc0c9\uc744 \uacc4\uc18d\ud55c\ub2e4. \ud655\ub960\uc774 $1 - \\varepsilon$ \uc774\uba74 $a = \\underset{a \\in A}{\\operatorname{argmax}} Q_{t}(a) $\uc744 \uc120\ud0dd\ud55c\ub2e4. \ud655\ub960\uc774 $\\varepsilon$ \uc774\uba74 random action \uc744 \uc120\ud0dd\ud55c\ub2e4. $\\frac{\\varepsilon}{|A|}$ \uc758 \ud655\ub960\ub85c \uacc4\uc18d \ucd5c\uc801\uac12\uc774 \uc544\ub2cc \uac12\uc744 \uc120\ud0dd\ud55c\ub2e4. $\\varepsilon\\text{-greedy}$ \uc54c\uace0\ub9ac\uc998\ub3c4 $\\varepsilon$\uac00 \uc0c1\uc218\ub77c\uba74 \uc120\ud615\uc801\uc778 \ud6c4\ud68c \ud568\uc218\ub97c \uac00\uc9c4\ub2e4. Lower Bound \ucd5c\uace0\ub85c \uc88b\uc740 \uc54c\uace0\ub9ac\uc998\uc774 \ucd5c\uc18c\ud55c\uc73c\ub85c \uac00\uc9c8\uc218 \ubc16\uc5d0 \uc5c6\ub294 \uc5d0\ub7ec\uac12\uc740 \uc5bc\ub9c8\uc77c\uae4c? \uc989 \uc5d0\ub7ec\ub294 \ucd5c\uc18c\ud55c \uc5bc\ub9c8\ubcf4\ub2e4 \ud074\uae4c? \uc54c\uace0\ub9ac\uc998\uc758 \uc810\uc218\ub294 \ucd5c\uc801 \uc561\uc158\uacfc \ub2e4\ub978 \uc561\uc158\ub4e4\uacfc\uc758 \uc720\uc0ac\ub3c4\ub85c \uacb0\uc815\ub41c\ub2e4. \uac00\uc7a5 \uc5b4\ub824\uc6b4 \uc561\uc158 \ucd5c\uc801\ud654 \ubb38\uc81c\ub294 \ube44\uc2b7\ud55c \ubcf4\uc0c1 \ud655\ub960 \ubd84\ud3ec\ub97c \uac00\uc9c0\ub098 \ud3c9\uade0\uac12\uc774 \ub2e4\ub978\uac83 \uc774\ub2e4. \uc704\uc758 \uc18d\uc131\uc744 gap $\\Delta_{a}$ \uadf8\ub9ac\uace0 \ud655\ub960\ubd84\ud3ec\uc758 \uc720\uc0ac\ub3c4 $KL(P(r \\mid a) \\mid \\mid p(r \\mid a_{*}))$\ub85c \ud45c\ud604 \uac00\ub2a5\ud558\ub2e4. $KL(A \\mid B)$ \uc5d0\uc11c A\uc640 B\uc758 \ud655\ub960 \ubd84\ud3ec\uac00 \ub611\uac19\ub2e4\uba74 0, \ub2e4\ub974\ub2e4\uba74 0 \ubcf4\ub2e4 \ud070\uac12\uc744 \uac00\uc9c4\ub2e4. \ub2e4\ub97c \uc218\ub85d \uac12\uc774 \ucee4\uc9c4\ub2e4. $\\frac{\\Delta_{a}}{KL( p(r \\mid a) \\mid \\mid p(r \\mid a_{*}))}$ \ub85c \uc815\uc758 \ud558\uba74 \ud655\ub960 \ubd84\ud3ec\uac00 \uc720\uc0ac \ud560 \uc218\ub85d \uc561\uc158 \ud6c4\ud68c \uac12\uacfc\uc758 \ube44\uac00 \ucee4\uc9c4\ub2e4. \uc989 \uc5b4\ub824\uc6b4 \ubb38\uc81c\uac00 \ub41c\ub2e4. \uacf5\ub9ac(Lai and Robbins) \uc704\uc758 \uc544\uc800\uc528\ub4e4\uc774 \uc99d\uba85\ud588\ub2e4. \ud6c4\ud68c \ucd1d\ud569 \uac12\uc740 \ub85c\uadf8\uac12\uc744 \ucde8\ud55c \ub2e8\uacc4\ubcf4\ub2e4\ub294 \ud06c\ub2e4. $$ \\lim_{t \\to \\infty } L_{t} \\geq \\log t \\sum_{a \\mid \\Delta_{a} \\gt 0 } \\frac{\\Delta_{a}}{KL( p(r \\mid a) \\mid \\mid p(r \\mid a_{*}))}$$ \uc561\uc158 \ud6c4\ud68c$\\Delta_{a}$\uac00 0 \ubcf4\ub2e4 \ud070 \ubaa8\ub4e0 \uc561\uc158\uc5d0 \ub300\ud574\uc11c KL \uc720\uc0ac\ub3c4\uc640 \uc561\uc158 \ud6c4\ud68c\uc758 \ube44\ub97c \ub354\ud55c \uac12 * t \ub85c\uadf8\ub294 \uc120\ud615\ubcf4\ub2e4 \ud6e8\uc52c \uc791\ub2e4. \ucd5c\uc120\uc758 \uac12\uc744 \uc815\uc758 \ud588\uc73c\ub2c8 \ucd5c\uc120\uc758 \uac12\uc5d0 \uadfc\uc811 \ud560 \uc218 \uc788\ub294 \uc54c\uace0\ub9ac\uc998\ub4e4\uc5d0 \ub300\ud574 \ub17c\uc758\ud574 \ubcf4\uc790. \uc608\uc81c \uc544\ub798\uc758 1\ubc88\uacfc \uac19\uc740 \ud655\ub960 \ubd84\ud3ec\ub97c \ucd94\uce21 \ud588\uc77c\ub54c \uc6b0\ub9ac\ub294 \uc5b4\ub514\ub97c \ub354 \ud0d0\uc0c9\ud574\uc57c \ud560\uae4c? \uac12\uc774 \ucd94\uce21\uc774 \uc548 \ub420\uc218\ub85d \ud574\ub2f9 \uc561\uc158\uc744 \ub354 \ud0d0\ud5d8\ud574\uc57c \ud55c\ub2e4. $a_{1}$ \uc744 \uc120\ud0dd \ud588\uc744\ub54c \ubcf4\uc0c1 \uac12 \ud3c9\uade0\uc774 0 \ubd84\uc0b0\uc774 0.1 \uc774 \uacc4\uc18d \ub098\uc624\uba74 \uc6b0\ub9ac\uc758 $a_{1}$ \ucd94\uce21 \ud655\ub960 \ubd84\ud3ec\ub294 2\ubc88\ucc98\ub7fc \uc62e\uaca8 \uac08\uac83\uc774\ub2e4. 3\ubc88\ucc98\ub7fc $a_{3}$ \uc744 \uc120\ud0dd \ud588\uc744\ub54c \ubcf4\uc0c1 \uac12 \ud3c9\uade0\uc774 1.7 \ubd84\uc0b0\uc774 1.7 \uc774 \uacc4\uc18d \ub098\uc624\uba74 \uc6b0\ub9ac\uc758 $a_{3}$ \ucd94\uce21 \ud655\ub960 \ubd84\ud3ec\ub294 4\ubc88\ucc98\ub7fc \uc62e\uaca8 \uac08\uac83\uc774\ub2e4. Upper Confidence Bounds \uc880\uc804\uc5d0\ub294 \ucd5c\uc18c \uc5d0\ub7ec\uac12\uc744 \uc0ac\uc6a9\ud588\ub2e4. \ubc94\uc704\ub97c \uc9c0\uc815\ud558\uae30 \uc704\ud574 \uc774\ubc88\uc5d0\ub294 \ucd5c\ub300 \uc2e0\ub8b0 \ubc94\uc704 \uac12\uc744 \uace0\ub824\ud574 \ubcf4\uc790. \uac01\uac01\uc758 \uc561\uc158 \uac12 \ub9c8\ub2e4 UCB \ub97c \uce21\uc815\ud558\uc790. UCB $U_{t}(a)$ \ub294 \ub192\uc740 \ud655\ub960\ub85c $q(a) \\leq Q_{t}(a) + U_{t}(a)$\ub97c \ub9cc\uc871 \uc2dc\ucf1c\uc57c \ud55c\ub2e4. \uc561\uc158\uc744 \uc120\ud0dd \ud560 \ub54c UCB \uac00 \ucd5c\ub300\uac00 \ub418\ub294 \uc561\uc158\uc744 \uc120\ud0dd\ud558\uc790. $$ a_{t} = \\underset{a \\in A}{\\operatorname{argmax}} \\left( Q_{t}(a) + U_{t}(a) \\right)$$ \uc561\uc158\uc758 \ucd94\uce21 \uac12\uc774 \ubd88\ud655\uc2e4 \ud560 \uc218\ub85d \ub354 \ub9ce\uc774 \uc120\ud0dd\ub418\uc5b4\uc57c \ud55c\ub2e4. \uc989 \uc561\uc158\uc758 \uc120\ud0dd \ud69f\uc218 $N(a)$ \uac00 \uc911\uc694\ud558\ub2e4. $N_{t}(a)$\uac00 \uc801\uac8c \uc120\ud0dd \ub418\uc5c8\ub2e4\uba74 $\\to$ $U_{t}(a)$ \ub294 \ucee4\uc57c \ud55c\ub2e4.(\ucd94\uce21 \ub41c \uac12\uc758 \ubd88\ud655\uc2e4\uc131\uc774 \ub192\ub2e4.) $N_{t}(a)$\uac00 \ub9ce\uc774 \uc120\ud0dd \ub418\uc5c8\ub2e4\uba74 $\\to$ $U_{t}(a)$ \ub294 \uc791\uc544\uc57c \ud55c\ub2e4.(\ucd94\uce21 \ub41c \uac12\uc758 \ubd88\ud655\uc2e4\uc131\uc774 \uc801\ub2e4.) \uc911\uc2ec\uadf9\ud55c \uc815\ub9ac\uc5d0 \uc758\ud574\uc11c \ubd88\ud655\uc2e4\uc131\uc740 $\\sqrt{N_{t}(a)}$ \ub85c \ud3c9\uade0\uc801\uc73c\ub85c \uac10\uc18c\ud55c\ub2e4. \uc6b0\ub9ac\ub294 \uc5ec\uae30\uc11c \ucd5c\uc801 \uc54c\uace0\ub9ac\uc998\uc744 \uc774\ub04c\uc5b4 \ub0bc\uc218 \uc788\ub294\uac00? \uc54c\uace0\ub9ac\uc998 \uc544\uc774\ub514\uc5b4 \uc6b0\ub9ac\ub294 \ud6c4\ud68c \ucd1d\ud569\uc744 \ucd5c\uc18c\ud654 \ud560\ub824\uace0 \ud55c\ub2e4. $\\sum_{a}N_{t}(a) \\Delta_{a}$ \ub9cc\uc57d $\\Delta_{a}$ \uac00 \ud06c\ub2e4\uba74 $N_{t}(a)$ \uac00 \uc801\uc5b4\uc57c \ud55c\ub2e4. \ub9cc\uc57d $\\Delta_{a}$ \uac00 \uc791\ub2e4\uba74 $N_{t}(a)$ \uac00 \ucee4\uc57c \ud55c\ub2e4. \ubaa8\ub4e0 $N_{t}(a)$\uac00 \uc791\uc744 \uc218 \ub294 \uc5c6\ub2e4.(\ucd1d\ud569\uc774 t\uac00 \ub418\uc5b4\uc57c \ud558\uae30 \ub54c\ubb38\uc5d0) \uc6b0\ub9ac\ub294$N_{t}(a)$ \uc5d0 \ub300\ud574 \uc54c\uace0 \uc788\ub2e4. $\\Delta_{a}$ \uc5d0 \ub300\ud574 \uc54c\uace0 \uc788\ub294\uac74 \uc5c6\uc744\uae4c? Hoeffding's Inequality \uacf5\ub9ac $X_{1},...,X_{n}$ \uc774 i.i.d \uc5d0\uc11c \ucd94\ucd9c\ub41c \ud655\ub960 \ubcc0\uc218\uc774\uace0 $[0, 1]$ \uc0ac\uc774\uc774\ub2e4. $\\bar X_{t} = \\frac{1}{n} \\sum_{i=1}^{n}X_{i}$ \ub97c \uc0d8\ud50c \ud3c9\uade0\uc774\ub77c\uace0 \ud558\uc790. \uadf8\ub7ec\uba74 \uc544\ub798\uc758 \uc2dd\uc774 \uc131\ub9bd\ud55c\ub2e4. $$ p(\\mathbb{E} [ X] \\geq \\bar X_{n} + u) \\leq e^{-nu^{2}}$$ \ud655\ub960 \ubcc0\uc218 X \uc758 \uae30\ub300\uac12\uc774 \uc0d8\ud50c \ud3c9\uade0 + \ubcf4\ub108\uc2a4 \ubcf4\ub2e4 \ud074 \ud655\ub960\uc740 \ucd5c\ub300 $e^{-nu^{2}}$ \uc774\ub2e4. \uc704 \uacf5\ub9ac\ub97c \uc544\ub798\uc758 \uc2dd\uc73c\ub85c \uc6b0\ub9ac\uc758 q \uac12\uc5d0 \uc801\uc6a9 \ud560 \uc218 \uc788\ub2e4. \ub9cc\uc57d $R_{t} \\in [0, 1]$ \uc774\ub77c\uba74 $$ p(q(a) \\geq Q_{t}(a) + U_{t}(a)) \\leq e^{-N_{t}(a)U_{t}(a)^{2}}$$ \uc6b0\ub9ac\uac00UCB\ub97c \ud2b9\uc815 \ud655\ub960 p \uae4c\uc9c0 \ub77c\uace0 \uc815\uc758\ud55c\ub2e4\uba74 $U_{t}(a)$ \ub97c \uc544\ub798\uc640 \uac19\uc774 \uad6c\ud560 \uc218 \uc788\ub2e4. $$e^{-N_{t}(a)U_{t}(a)^{2}} = p$$ $$U_{t}(a) = \\sqrt{ \\frac{-\\log p}{2N_{t}(a)}}$$ \uc6b0\ub9ac\uac00 \ub9ce\uc740 \ubcf4\uc0c1\uc744 \uad00\ucc30 \ud560 \uc218\ub85d p\ub97c \uc904\uc778\ub2e4\uba74 e.g $p = 1/t = t^{-1}$ $$U_{t}(a) = \\sqrt{ \\frac{\\log t}{2N_{t}(a)}}$$ \uc704\uc2dd\uc740 \uc9c0\uc18d\uc801\uc73c\ub85c \ud0d0\uc0c9 \ud560\uac83\uc774\ub2e4. \ud558\uc9c0\ub9cc $t \\to \\infty$ \ub85c \uac08\uc218\ub85d \ucd5c\uc801 \uc561\uc158\uc744 \ub354 \ub9ce\uc774 \uc120\ud0dd \ud560 \uac83\uc774\ub2e4. \ubd84\ubaa8\ub294 \uc120\ud615\uc73c\ub85c \uc99d\uac00\ud558\uace0 \ubd84\uc790\ub294 \ub85c\uadf8\ub85c \uc99d\uac00\ud558\uae30 \ub54c\ubb38\uc5d0 \uc810\uc810 \uc791\uc544 \uc9c4\ub2e4. P with Upper Confidence Bounds \ubcc0\uc218\ub97c \uc544\ub798\uc640 \uac19\uc774 \uc815\uc758\ud558\uace0 \uace0\uc815 \ud558\uc790 $q(a)$ \ub294 i.i.d \uc774\uba70 $[0, 1]$ \uc0ac\uc774\uc758 \uac12 $Q_t(a) = 0.5$ $N_t(a) = 10$ P\uc758 \uac12\uc744 \uc9c0\uc18d\uc801\uc73c\ub85c \uc904\uc5ec\uac00\uba74$U_{t}(a)$ \ub294 \ucee4\uc9c0\uace0 \ud574\ub2f9 \uc561\uc158\uc744 \ud0d0\uc0c9\ud558\uac8c \ub41c\ub2e4. $ N_{t} $ with Upper Confidence Bounds \ubcc0\uc218\ub97c \uc544\ub798\uc640 \uac19\uc774 \uc815\uc758\ud558\uace0 \uace0\uc815 \ud558\uc790 $q(a)$ \ub294 i.i.d \uc774\uba70 $[0, 1]$ \uc0ac\uc774\uc758 \uac12 $Q_{t}(a) = 0.5$ $U_{t}(a) = 1E-9$ \ub9ce\uc774 \ud0d0\uc0c9\ud55c \uc561\uc158\uc77c\uc218\ub85d \uac12\uc774 \ud655\uc2e4\ud558\uae30 \ub54c\ubb38\uc5d0 \uc801\uac8c \ud0d0\uc0c9 \ud574\uc57c \ud55c\ub2e4. $N_{t}(a)$\uac00 \uc801\uac8c \uc120\ud0dd \ub418\uc5c8\ub2e4\uba74 $\\to$ $U_{t}(a)$ \ub294 \ucee4\uc57c \ud55c\ub2e4. $N_{t}(a)$\uac00 \ub9ce\uc774 \uc120\ud0dd \ub418\uc5c8\ub2e4\uba74 $\\to$ $U_{t}(a)$ \ub294 \uc791\uc544\uc57c \ud55c\ub2e4. \uc544\ub798\ucc98\ub7fc \ubcc0\uc218\ub97c \uace0\uc815\ud55c \ud6c4 $N_{t}(a)$ \uc744 \uc99d\uac00\uc2dc\ud0a4\uba74 $U_{t}(a)$ \ub294 \uc810\uc810 \uac10\uc18c \ud558\uc9c0\ub9cc \uc644\uc804\uc774 0 \uc774 \ub418\uc9c0 \uc54a\ub294\ub2e4. \uacf5\ub9ac (Auer et al. 2002) UCB \uc54c\uace0\ub9ac\uc998 ($c = \\sqrt 2$) \ub294 \ud6c4\ud68c \ucd1d\ud569 \uae30\ub300\uac12\uc744 \ub85c\uadf8\uac12\uc73c\ub85c \uac19\ub294\ub2e4. $$ L_{t} \\leq 8 \\sum_{a \\mid \\Delta_{a} > 0} \\frac{\\log t}{\\Delta_{a}} + O(\\sum_{a}\\Delta_{a}), \\forall t$$ \uacb0\ub860 UCB \ub97c \uc0ac\uc6a9\ud558\uba74 \ud6c4\ud68c \ucd1d\ud569\uc740 \ub85c\uadf8\uac12\uc774\ub2e4. $$O(\\log t) \\leq L_{t} \\leq O(\\log t)$$ UCB $$ a_{t} = \\underset{a \\in A}{\\operatorname{argmax}} Q_{t}(a) + c \\sqrt{ \\frac{\\log t}{N_{t}(a)}}$$ - C\ub294 \ud558\uc774\ud37c \ud30c\ub77c\ubbf8\ud130\ub85c \uc0ac\uc6a9\ub418\uae30\ub3c4 \ud568. (\uc0c1\uc218 \ucde8\uae09) - \uc5bc\ub9c8\ub098 \ube68\ub9ac \ubc30\uc6b8\uae4c \uc815\ub3c4\uc758 \ub290\ub08c - \ubcf4\ud1b5 1\ub85c \uc2dc\uc791\ud574 0,2,3 \ub97c \ud14c\uc2a4\ud2b8 \ud568 - \ud2b9\uc815 \uc561\uc158\uc774 \uc624\ub798\ub3d9\uc548 \uc120\ud0dd\uc774 \uc548\ub418\uba74 \ubcf4\ub108\uc2a4 \uac12\uc774 \ucee4\uc9d0 - \ub2e4\ub978 \ubaa8\ub4e0 \uc561\uc158 \uac12\ub4e4\ubcf4\ub2e4 \uacb0\uad6d\uc5d4 \ucee4\uc9d0 \uadf8\ub798\uc11c \uc120\ud0dd\ub418\uba74 \ubcf4\ub108\uc2a4 \uac12\uc774 \ud655 \uc791\uc544\uc9d0 - \uc9c1\uac10 - $\\Delta_{a}$ \uac00 \ud06c\ub2e4\uace0 \uac00\uc815\ud574\ubcf4\uc790 \uadf8\ub807\ub2e4\uba74 - $N_{t}(a)$ \uac00 \uc801\uc744\uac83\uc774\ub2e4. \uc65c\ub0d0\ud558\uba74 $U_{t}(a)$\uc560 \uc758\ud574\uc11c\ub294 \uc544\uc8fc \uac00\ub054\uc529 \uc804\uccb4 gap\uc744 \ud3c9\uac00 \ud558\uae30 \ub54c\ubb38\uc774\ub2e4. - \uadf8\ub807\ub2e4\uba74 $\\Delta_{a}$ \uac00 \uc791\uac70\ub098 \ub610\ub294 $N_{t}(a)$ \uac00 \uc791\uac70\ub098 \uc774\ub2e4. Bayesian Bandits \ubcf4\uc0c1\uc758 \ud655\ub960 \ubd84\ud3ec\ub97c \ud30c\ub77c\ubbf8\ud130\uc640 \uc561\uc158\uc744 \uc0ac\uc6a9\ud574 \ucd94\uce21\ud574\ubcf4\uc790. \uc561\uc158\uc758 \ubcf4\uc0c1 \ud655\ub960 \ubd84\ud3ec\ub97c \uc870\uc815\ud558\ub294 \ud30c\ub77c\ubbf8\ud130\ub4e4\uc744 $\\theta$ \ub77c\uace0 \ud558\uc790. \uc6b0\ub9ac\ub294 $q(a) = p(R \\mid \\theta, a)$ \ub97c \uc54c\uace0 \uc2f6\ub2e4. \uacfc\uac70\uc758 \ud655\ub960\uc744 \ubc1c\uacac\ub41c \uc99d\uac70 \ucabd\uc73c\ub85c \uc870\uae08 \ubcc0\uacbd\ud558\ub294 \ubca0\uc774\uc9c0\uc548 \ucd94\ub860\uc744 \uc0ac\uc6a9\ud574 \ubcf4\uc790. $$p(R \\mid \\theta, a) \\propto p(R_{t} \\mid \\theta, a)p_{t-1}(\\theta \\mid a)$$ \uc0ac\ud6c4 \ud655\ub960\uc740 $p(R \\mid \\theta, a)$\uc0c8\ub85c\uc6b4 \ubcf4\uc0c1\uc758 \ud655\ub960\uacfc $p(R_{t} \\mid \\theta, a)$ \uc0ac\uc804 \ud655\ub960\uc758 $p_{t-1}(\\theta \\mid a)$ \uacf1\uc5d0 \ube44\ub840\ud55c\ub2e4. \ub9ce\uc740 \uc0ac\uc804 \uc815\ubcf4\ub97c \uc778\ucf54\ub529 \ud560 \uc218 \uc788\uac8c \ud574\uc900\ub2e4. $p_{0}(\\theta \\mid a)$ \uc608\uc81c \uc2ac\ub86f\uba38\uc2e0\uc774 \ubca0\ub974\ub204\uc774 \ubd84\ud3ec\ub97c \uac00\uc9c0\uace0 \uc788\ub2e4\uace0 \ud558\uc790. \ubcf4\uc0c1\uc740 0 \uc544\ub2c8\uba74 1\uc774\ub2e4. \ubaa8\ub4e0 \uc561\uc158\uc758 \uc774\uc804 \ubd84\ud3ec\ub294 $[0, 1]$ \uc0ac\uc774\uc5d0 \uade0\ub4f1\ubd84\ud3ec \ud55c\ub2e4 \ubca0\ud0c0 \ubd84\ud3ec\ub85c \uc0ac\ud6c4 \ud655\ub960\ubd84\ud3ec\ub97c \ubaa8\ub378\ub9c1\ud558\uc790$Beta(\\alpha_{a}, \\beta_{a})$ \ucd5c\ucd08 $\\alpha_{a}=1, \\beta_{a}=1$ \ub85c \uade0\ub4f1\ud558\uac8c \uc2dc\uc791\ud55c\ub2e4. \uc774\ud6c4 \ubcf4\uc0c1\uc5d0 \ub530\ub77c \ud30c\ub77c\ubbf8\ud130\ub97c \ubcc0\uacbd\ud55c\ub2e4. $\\alpha_{a_{t}} \\leftarrow \\alpha_{a_{t}} + 1 \\text{ when } R_{t} = 0$ $\\beta_{a_{t}} \\leftarrow \\beta_{a_{t}} + 1 \\text{ when } R_{t} = 1$ TODO \ubcf4\uc0c1 0\uc5d0 \uc54c\ud30c\uac00 +1, \ubcf4\uc0c1 1\uc5d0 \ubca0\ud0c0 +1 \ub418\ub294 \ubd80\ubd84\uc774 \uc774\uc0c1\ud558\ub2e4 \ud655\uc778 \ud574\ubcf4\uc790. \ubcf4\uc0c1\uc774 $R_{1} = 1, R_{2} = 1, R_{3} = 0, R_{4} = 0$ \uc73c\ub85c \ubc1c\uc0dd\ub41c\ub2e4\uba74 \uc704\uc758 \uc2dd\uc5d0 \uc758\ud574 \uc544\ub798\uc640 \uac19\uc774 \ubca0\ud0c0 \ubd84\ud3ec\uac00 \ubcc0\uacbd\ub41c\ub2e4. code \ucd5c\ucd08\uc5d0 q \uac00 0 \uc778\uc9c0 1\uc778\uc9c0 \uc54c\uc9c0 \ubabb\ud55c\ub2e4. \ubcf4\uc0c1\uc774 1\uc774 \ub450\ubc88 \uc5f0\uc18d \ub098\uc624\uba74\uc11c 3)\ubc88 \uadf8\ub9bc q \ub294 1 \uc77c\uac00\ub2a5\uc131\uc774 \ub192\uc544\uc9c4\ub2e4. \ubcf4\uc0c1\uc774 0\uc774 \ud55c\ubc88 \ub098\uc624\uba74\uc11c 4)\ubc88 \uadf8\ub9bc q \ub294 1 \uc77c\uac00\ub2a5\uc131\uc774 \uc5c6\ub2e4. \ubcf4\uc0c1\uc774 0\uc774 \ud55c\ubc88 \ub354 \ub098\uc624\uba74\uc11c 5)\ubc88 \uadf8\ub9bc q \ub294 0.5 \uc77c \uac00\ub2a5\uc131\uc774 \uac00\uc7a5 \ub192\uc544\uc9c4\ub2e4. Bayesian with UCB \uc561\uc158 \ud568\uc218\uc758 \uc0ac\ud6c4 \ud655\ub960 \ubd84\ud3ec\ub97c \uacc4\uc0b0\ud558\uba74 \uc704\ucc98\ub7fc \ud45c\ud604 \ud560 \uc218 \uc788\ub2e4. \uc0ac\ud6c4 \ud655\ub960\uc744 \uc0ac\uc6a9\ud574\uc11c UCB \ub97c \uc0ac\uc6a9 \ud560 \uc218 \uc788\ub2e4. $$U_{t}(a) = c\\sigma(a)$$ $Q_{t}(a) + c\\sigma(a)$\uc744 \ucd5c\ub300\ud654 \ud558\ub294 \uc561\uc158\uc744 \uc120\ud0dd Policy Policy $\\pi(a)$ \ub97c \ubc14\ub85c \ubc30\uc6b0\ub294\uac74 \uc5b4\ub5a8\uae4c? policy \ub294 $f: state \\to action$ \ud568\uc218 \uc774\ub2e4. \ud558\uc9c0\ub9cc \uc5ec\uae30\uc11c state \ub294 \ud55c \uac1c \uc774\uae30 \ub54c\ubb38\uc5d0 action \ub9cc \ud45c\ud604 $\\pi(a)$ \ub294 \ud574\ub2f9 \uc561\uc158\uc774 \uc2e4\ud589\ub420 \ud655\ub960\ub85c \uc815\uc758 \ud560 \uc218 \uc788\ub2e4. \uc815\ucc45\uc744 value \ud568\uc218 \uc5c6\uc774 \ud559\uc2b5 \ud560 \uc218 \uc788\uc744\uae4c? $H_{t}(a)$ \ub97c preference \ub77c\uace0 \uc815\uc758 \ud558\uc790. $\\pi(a): [0, 1] \\text{ and } \\sum_{a} \\pi(a) = 1$ $$ \\pi(a) = \\frac{e^{H_{t}(a)}}{ \\sum_{b} e^{H_{t}(b)}}$$ \uc120\ud638\ub3c4\ub294 value \ud568\uc218\uc640 \uaf2d \uc5f0\uad00\ub418\uc9c0 \uc54a\uc544\ub3c4 \ub41c\ub2e4. \uc120\ud638\ub3c4\ub97c \ud559\uc2b5 \uac00\ub2a5\ud55c \ud30c\ub77c\ubbf8\ud130\ub85c \ubcf4\uc790. \uc5b4\ub5bb\uac8c \uc120\ud638\ub3c4\ub97c \ud559\uc2b5 \ud560 \uac74\uc778\uac00? Policy gradients Idea: \uc88b\uc740 \uc561\uc158\uc774\ub780 \ubcf4\uc0c1\uc758 \uae30\ub300\uac12\uc774 \uc99d\uac00\ud558\ub294 \uac83\uc774\ub2e4. \uae30\ub300\uac12\uc758 \uc99d\uac00\ub97c \uacbd\uc0ac\ub3c4 \uc0c1\uc2b9\uc73c\ub85c \uc0dd\uac01 \ud560 \uc218 \uc788\ub2e4. \uc2ac\ub86f\uba38\uc2e0\uc5d0\uc11c\ub294 $$ \\theta = \\theta + \\alpha \\nabla_{\\theta}\\mathbb{E}[ R_{t} \\mid \\theta ]$$ $\\theta$ \ub294 \uc815\ucc45\uc758 \ud30c\ub77c\ubbf8\ud130\uc774\uba70 \uc120\ud638\ub3c4\uc5d0 \uc601\ud5a5\uc744 \uc900\ub2e4\uace0 \uc815\uc758\ud558\uc790. $\\theta$ \ub97c \ubcc0\uacbd\ud558\uba74 \uc815\ucc45\uc774 \ubcc0\uacbd\ub418\uace0 \uadf8\ub7ec\uba74 \ubcf4\uc0c1\uc774 \ubcc0\uacbd\ub41c\ub2e4. \uacbd\uc0ac\ub3c4\ub97c \uad6c \ud560 \uc218 \uc788\uc744\uae4c? Gradient bandits \uc704\uc758 \uc2dd\uc744 \uc218\ud559\uc744 \uc0ac\uc6a9\ud574 \uacc4\uc0b0 \uac00\ub2a5\ud55c \uc2dd\uc73c\ub85c \uc7ac \ud45c\ud604\ud574 \ubcf4\uc790. $\\theta$\ub97c \uc8fc\uc5c8\uc744\ub54c \uae30\ub300\uac12\uc740 $\\theta$ \uc815\ucc45\uc744 \uc0ac\uc6a9 \ud560\ub54c\uc758 \uc561\uc158 \ubcc4 \ubcf4\uc0c1 \uae30\ub300\uac12\uacfc \uac19\ub2e4. $$\\nabla_{\\theta} \\mathbb{E} [ R_{t} \\mid \\theta ] = \\nabla_{\\theta} \\sum_{a} \\pi_{\\theta}(a) \\mathbb{E} [ R_{t} \\mid A_{t} = a ]$$ \uc561\uc158\ubcc4 \uae30\ub300 \ubcf4\uc0c1\uc740 $q(a)$ $$ = \\nabla_{\\theta} \\sum_{a} \\pi_{\\theta}(a) q(a)$$ $q(a)$ \ub294 $\\theta$ \uc640 \uc0c1\uad00\uc5c6\uc74c\uc73c\ub85c \uc815\ucc45\ub9cc \ubbf8\ubd84\ud558\uba74 \ub41c\ub2e4. $$ = \\sum_{a} q(a) \\nabla_{\\theta} \\pi_{\\theta}(a) $$ 1 \uc744 \uacf1\ud574\ub3c4 \uc0c1\uad00\uc5c6\ub2e4. $\\frac{\\pi_{\\theta}(a)}{\\pi_{\\theta}(a)} = 1$ $$ = \\sum_{a} q(a) \\frac{\\pi_{\\theta}(a)}{\\pi_{\\theta}(a)} \\nabla_{\\theta} \\pi_{\\theta}(a) $$ \uc2dd\uc744 \uc815\ub9ac $$ = \\sum_{a} \\pi_{\\theta}(a) q(a) \\frac{\\nabla_{\\theta} \\pi_{\\theta}(a)}{\\pi_{\\theta}(a)} $$ \uae30\ub300\uac12\uc73c\ub85c \ub2e4\uc2dc \ubcc0\uacbd $a \\to A_{t}$ \ub85c \ubcc0\uacbd\ub428 $$ = \\mathbb{E} \\left[ R_{t} \\frac{\\nabla_{\\theta} \\pi_{\\theta}(A_{t})}{\\pi_{\\theta}(A_{t})} \\right] $$ \ubbf8\ubd84 \ud568\uc218\ub97c \uc6d0\ub798 \ud568\uc218\ub85c \ub098\ub204\uba74 \uc6d0\ub798 \ud568\uc218\uc758 \ub85c\uadf8 \ubbf8\ubd84\uacfc \uac19\ub2e4. $$ = \\mathbb{E} \\left[ R_{t} \\nabla_{\\theta} \\log \\pi_{\\theta}(A_{t}) \\right] $$ Reference \ucc38\uc870 logarithm","title":"2. Exploration and Exploitatin"},{"location":"rl/5_rl_exploration/#2-exploration-and-exploitatin","text":"","title":"2. Exploration and Exploitatin"},{"location":"rl/5_rl_exploration/#what-is-rl","text":"\uacb0\uc815 \ud558\ub294 \uac83\uc744, \ud559\uc2b5 \uc2dc\ud0a4\ub294 \ubc29\ubc95\uc5d0 \ub300\ud55c \uacfc\ud559 \ud589\uc704\uc790\ub294 \uc815\ucc45, \uac00\uce58 \ud568\uc218 \uadf8\ub9ac\uace0/\ub610\ub294 \ubaa8\ub378\ub4e4\uc744 \ud559\uc2b5 \ud560 \uc218 \uc788\ub2e4. \uc77c\ubc18\uc801\uc73c\ub85c \uc2dc\uac04\uacfc \uacb0\uacfc\uc5d0 \ub300\ud574 \uace0\ub824\ud574\uc57c \ud55c\ub2e4. \uacb0\uc815\uc740 \ubcf4\uc0c1, \ud589\uc704\uc790\uc758 \uc0c1\ud0dc, \ud658\uacbd\uc758 \uc0c1\ud0dc\uc5d0 \uc601\ud5a5\uc744 \uc900\ub2e4.","title":"What is RL"},{"location":"rl/5_rl_exploration/#_1","text":"\ud589\uc704\uc640 \ubcf4\uc0c1\uc758 \uc0c1\uad00\uad00\uacc4\ub97c \ud0d0\uad6c\ud558\uae30 \uc704\ud574 \ub2e4\ub978 \ubd80\ubd84\ub4e4\uc744 \uace0\uc815 \uc2dc\ud0a4\uc790.","title":"\ub2e8\uc21c\ud654"},{"location":"rl/5_rl_exploration/#_2","text":"\uc5ec\ub7ec\uac1c\uc758 \uc0c1\ud0dc\uac00 \uc788\uace0 \uc5ec\ub7ec\uac1c\uc758 \ud589\uc704\uac00 \uc788\ub2e4. \ud558\ub098\uc758 \ud589\uc704\uac00 \ub2e4\ub978 \uc0c1\ud0dc\uc640 \ubcf4\uc0c1\uc5d0 \uc601\ud5a5\uc744 \uc900\ub2e4. \ud589\uc704\uc5d0 \ub300\ud55c \ubbf8\ub798\ub294 \ud655\ub960\uc801\uc73c\ub85c \uc8fc\uc5b4\uc9c0\uace0 \ud574\ub2f9 \ud655\ub960 \ubd84\ud3ec\ub294 \uc2dc\uac04\uc5d0 \uc758\ud574 \ubcc0\ud55c\ub2e4.","title":"\ud604\uc2e4"},{"location":"rl/5_rl_exploration/#_3","text":"\uc5ec\ub7ec\uac1c\uc758 \uc0c1\ud0dc \uc5ec\ub7ec\uac1c\uc758 \ud589\uc704 \ud589\uc704\uac00 \ubbf8\ub798\uc5d0 \uc601\ud5a5\uc744 \uc90c \ubbf8\ub798 == \ubcf4\uc0c1 + \uc0c1\ud0dc \ud589\uc704\uc5d0 \ub300\ud55c \ubbf8\ub798\ub294 \ud655\ub960\uc801\uc73c\ub85c \uc8fc\uc5b4\uc9d0 \ubbf8\ub798\uc758 \ud655\ub960 \ubd84\ud3ec\ub294 \uc2dc\uac04\uc5d0 \uc758\ud574 \ubcc0\ub3d9 \ub420 \uc218 \uc788\uc74c \uc0c1\ud0dc\ub294 \uc2dc\uac04\uc5d0 \uc758\ud574 \ubcc0\uacbd \ub420 \uc218 \uc788\uc74c","title":"\ud604\uc2e4\uc758 \uad6c\uc131\uc694\uc18c"},{"location":"rl/5_rl_exploration/#_4","text":"\ud55c \uac1c\uc758 \uc0c1\ud0dc\ub9cc \uc0dd\uac01\ud558\uc790. \uc0c1\ud0dc\ub294 \ud55c \uac1c. \uc5ec\ub7ec \uac1c\uc758 \uc561\uc158 \uacfc\uac70\uc758 \ud589\uc704\uac00 \ubbf8\ub798\uc5d0 \uc601\ud5a5\uc744 \uc8fc\uba74 \ubcf5\uc7a1\ud558\ub2e4. \ube44\uc5f0\uc18d\uc801 \uad6c\uc870 == \uacfc\uac70\uc758 \ud589\uc704\uac00 \ubbf8\ub798\uc5d0 \uc601\ud5a5\uc744 \uc8fc\uc9c0 \uc54a\uc74c. $A_{t}$\ub97c \uc870\uac74\uc73c\ub85c \uc8fc\uc5c8\uc744\ub54c $R_{t}$ \uc758 \ud655\ub960 \ubd84\ud3ec\ub294 \uace0\uc815\ub418\uc5b4 \uc788\uc74c \ub610\ud55c \uc2dc\uac04\uacfc \ub3c5\ub9bd\uc801\uc784","title":"\ub2e8\uc21c\ud654"},{"location":"rl/5_rl_exploration/#_5","text":"\ud30c\ub791 \ub808\ubc84\uc640 \ube68\uac15 \ub808\ubc84\uac00 \uc788\ub2e4. \uccab \ubc88\uc9f8 \uc2dc\ub3c4\uc5d0\uc11c \ud30c\ub791 \ub808\ubc84\ub97c \ub2f9\uae30\uba74 \uce58\uc988\uac00 \ub098\uc654\ub2e4. \ub450 \ubc88\uc9f8 \uc2dc\ub3c4\uc5d0\uc11c \ube68\uac15 \ub808\ubc84\ub97c \ub2f9\uae30\uba74 \uc804\uae30 \uc1fc\ud06c\uac00 \ub098\uc654\ub2e4. \uc138 \ubc88\uc9f8 \uc2dc\ub3c4\uc5d0\uc11c \uce58\uc988\uc744 \ubc1b\uae30 \uc704\ud574\uc11c\ub294 \ubb34\uc5c7\uc744 \ub2f9\uaca8\uc57c \ud560\uae4c?","title":"\uc608\uc81c"},{"location":"rl/5_rl_exploration/#vs","text":"100 \uacf3\uc758 \uc74c\uc2dd\uc810\uc774 \uc788\ub2e4 10 \uacf3\uc758 \uc74c\uc2dd\uc810\ub9cc \uac00\ubcf4\uace0 \ud2b9\uc815\ud55c \uacf3\uc774 \ucd5c\uace0 \ub77c\uace0 \ud560 \uc218 \uc788\ub294\uac00? online \uacb0\uc815 \ubb38\uc81c\ub294 \uae30\ubcf8\uc801\uc73c\ub85c 2\uac1c\uc758 \uc120\ud0dd\uc774 \uc788\ub2e4. \ud0d0\uc0c9: \uc9c0\uc2dd\uc744 \uc99d\uac00 \uc2dc\ud0b4 \ud65c\uc6a9: \uc131\uacfc\ub97c \ucd5c\ub300\ud654 \ud558\uae30 \uc704\ud574 \uae30\uc874\uc758 \uc9c0\uc2dd\uc744 \uc774\uc6a9 \uc81c\uc77c \uc88b\uc740 \uc7a5\uae30 \uc804\ub7b5\uc740 \ub2e8\uae30\uc801 \uc774\uc775\uc744 \ud76c\uc0dd \uc2dc\ucf1c\uc57c \ud560 \uc218 \uc788\ub2e4. \uc6b0\ub9ac\ub294 \uc804\uccb4\uc801\uc73c\ub85c \ucd5c\uc801\ud654\ub41c \uacb0\uc815\ub4e4\uc744 \ucc3e\uae30 \uc704\ud574 \uc815\ubcf4\ub97c \ubaa8\uc544\uc57c \ud55c\ub2e4.","title":"\ud0d0\uc0c9 vs \ud65c\uc6a9"},{"location":"rl/5_rl_exploration/#one-armed-bandit","text":"\ud55c \uac1c\uc758 \ub808\ubc84\ub97c \uac00\uc9c4 \ube60\uc9d5\ucf54 \uae30\uacc4\uac00 \uc788\ub2e4. \ub808\ubc84\ub97c \ub2f9\uae30\uba74 \ud655\ub960\uc801\uc73c\ub85c \ud2b9\uc815 \uae08\uc561\uc774 \ub098\uc628\ub2e4. \ubbf8\ub798\ub294 \ud604\uc7ac\uc5d0 \ub3c5\ub9bd\uc801\uc774\ub2e4.","title":"One-Armed bandit"},{"location":"rl/5_rl_exploration/#multi-armed-bandit","text":"","title":"Multi-Armed bandit"},{"location":"rl/5_rl_exploration/#_6","text":"\uc5ec\ub7ec \uac1c\uc758 \ub808\ubc84\ub97c \uac00\uc9c4 \ube60\uc9d5\ucf54 \uae30\uacc4\uac00 \uc788\ub2e4. \ub808\ubc84\uac00 10\uac1c\uac00 \uc788\uace0 \ub808\ubc84\ub97c \ub2f9\uae38 \ub54c \ub9c8\ub2e4 \ud2b9\uc815 \uae08\uc561\uc774 \ub098\uc628\ub2e4. \uae08\uc561\uc740 \ud2b9\uc815 \ub808\ubc84\uc5d0 \uc758\uc874\uc801\uc774\uba70 \ud655\ub960\uc801\uc73c\ub85c \uc561\uc218\uac00 \uacb0\uc815\ub41c\ub2e4.","title":"\uc0c1\ud669"},{"location":"rl/5_rl_exploration/#formalize","text":"\uc0c1\ud0dc\ub294\ub2e8 \ud55c \uac1c\uc774\ub2e4. \uc5ec\ub7ec \uc561\uc158 \uc14b\uc744 $A$ \ub77c\uace0 \ud558\uc790. \ud589\uc704 == $0..N$ \ub808\ubc84 \uc911 \ud55c \uac1c\ub97c \ub2f9\uae30\ub294 \ud589\uc704 \uc561\uc158\uc14b == {\"0\ubc88 \ub2f9\uae30\uae30\",...,\"N \ubc88 \ub2f9\uae30\uae30\"} \uac01 \ub2e8\uacc4\uc5d0 \ud589\uc704\uc790\ub294 \ud589\uc704 $A_{t} \\in A $\ub97c \uc120\ud0dd\ud55c\ub2e4. \ud658\uacbd\uc740 \ubcf4\uc0c1 $R_{t}$\ub97c \uc0dd\uc0b0\ud55c\ub2e4. \ubcf4\uc0c1\uc740 $P(r \\mid a)$ \uc774\uba70 \uace0\uc815\ub418\uc5b4 \uc788\ub2e4. \ud558\uc9c0\ub9cc \ud574\ub2f9 \ud655\ub960 \ubd84\ud3ec\ub97c \uc54c\uc9c0 \ubabb\ud55c\ub2e4. \ubaa9\uc801\uc740 \ud2b9\uc815 \uc2dc\uac04 \ub3d9\uc548 \ub204\uc801 \ubcf4\uc0c1\uc744 \ucd5c\ub300\ud654 \ud558\ub294\uac83\uc774\ub2e4. $\\sum_{i=1}^{t}R_{i}$ \ubbf8\ub798(\ubcf4\uc0c1)\ub294 \ud604\uc7ac\uc758 \uc120\ud0dd\uacfc \ub3c5\ub9bd\uc801\uc774\ub2e4.","title":"\ud615\uc2dd\ud654(formalize)"},{"location":"rl/5_rl_exploration/#_7","text":"\ud2b9\uc815 \uc2dc\uac04 \uc989 100 \ud68c \ub3d9\uc548\uc758 \ub204\uc801 \ubcf4\uc0c1\uc744 \ucd5c\ub300\ud654 \ud560\ub824\uba74 \uba87 \ud68c\ub97c \ud0d0\uc0c9\uc5d0 \uc4f0\uace0 \uba87 \ud68c\ub97c \ud65c\uc6a9\uc5d0 \uc0ac\uc6a9\ud574\uc57c \ud560\uae4c? \uc9c0\ub3c4 \ud559\uc2b5\uc5d0\uc11c \ud3c9\uac00 \uae30\uc900\uc774 \ud14c\uc2a4\ud2b8 \uc14b\uc778\uac83\uacfc\ub294 \uc870\uae08 \ub2e4\ub974\ub2e4. \ud2b8\ub808\uc774\ub2dd \uacfc \ud14c\uc2a4\ud2b8 \uc14b\uc774 \ub3d9\uc2dc\uc5d0 \uc774\ub8e8\uc5b4 \uc9c0\ub294 \ub290\ub08c.","title":"\uc0dd\uac01 \ud560 \uac83"},{"location":"rl/5_rl_exploration/#_8","text":"\ub204\uc801 \ubcf4\uc0c1\uc744 \ucd5c\ub300\ud654 \ud558\uae30 \uc704\ud574\uc11c\ub294 \uac01 \ub808\ubc84\uc758 \uac1c\ubcc4 \ubcf4\uc0c1 \uae30\ub300\uac12\uc744 \uc54c\uc544\uc57c \ud55c\ub2e4. \ud0d0\uc0c9\uacfc \ud65c\uc6a9\uc758 \uc804\ub7b5\uc744 \ud0dd\ud574\uc57c \ud55c\ub2e4.","title":"\uc218\uc2dd\ud654"},{"location":"rl/5_rl_exploration/#action-value-","text":"\ud55c \uac1c\uc758 \ud314\uc744 \uac00\uc9c4 \ube60\uc9d5\ucf54 \uae30\uacc4\uc758 \uac1c\ubcc4 \ubcf4\uc0c1\uc744 \uae30\ub300\uac12\uc73c\ub85c \ud45c\ud604\ud574 \ubcf4\uc790. \ud574\ub2f9 \ud314\uc744 $a_0$ \uc774\ub77c\uace0 \uce6d\ud558\uc790. \uc561\uc158\uc744 \ud589\ud55c \ud6c4 \ubc1b\ub294 \ubcf4\uc0c1\uc774 \uc815\ud574 \uc9c0\ub294 \ud568\uc218\ub97c q \ub77c\uace0 \uc815\uc758\ud558\uc790. $q: \\text{action} \\to \\text{reward}$ \uc544\ub798\ub294 \uc9c4\uc9dc \ubcf4\uc0c1 \ud568\uc218\uc774\uba70 \ud589\uc704\uc790\ub294 \uc54c\uc9c0 \ubabb\ud55c\ub2e4 \uadf8\ub7ec\ubbc0\ub85c \ucd94\uce21 \ud574\uc57c \ud55c\ub2e4. $$ q(a) = \\mathbb{E} [ R_{t} ] $$ \uc6b0\ub9ac\ub294 \uc0c1\ud638\uc791\uc6a9\uc744 \ud1b5\ud574 (\uc0d8\ud50c\ub9c1) \uc704\uc758 \uc9c4\uc9dc \ubcf4\uc0c1 \ud568\uc218\ub97c \ucd94\uce21 \ud574\uc57c \ud55c\ub2e4. \ud3c9\uade0 \uac12\uc744 \uc0ac\uc6a9\ud574 \ubcf4\uc790. $$ Q_{t}(a) = \\frac{\\sum_{n=1}^{T}R_{n}}{T} $$","title":"Action value - \ud55c \uac1c"},{"location":"rl/5_rl_exploration/#action-value-_1","text":"\uc704\uc758 \uc2dd\uc744 \ud655\uc7a5\ud574 \ubcf4\uc790. \uc5ec\ub7ec \uac1c\uc758 \uc561\uc158 \uc911 \ud55c \uac1c\ub97c \uc120\ud0dd \ud568\uc73c\ub85c \uc870\uac74\ubd80 \ud655\ub960\uc2dd\uc744 \uc138\uc6b0\uc790. \uc9c4\uc9dc q \ud568\uc218 $$ q(a) = \\mathbb{E} [ R_{t} \\mid A_{t} = a ] $$ \uc0d8\ud50c\ub9c1\uc744 \ud1b5\ud55c \ucd94\uce21 action totalReward \ub2f9\uae34 \ud69f\uc218 \ud3c9\uade0 \uc218\uc2dd 0 8 2 4 $Q_{t}(0) = \\frac{8}{2}$ 1 10 1 10 $Q_{t}(1) = \\frac{10}{1}$ $L$ \uc740 \uc870\uac74\uc774 True \uc77c \uacbd\uc6b0 1 \uc544\ub2c8\uba74 0\uc744 \ub9ac\ud134 \ud558\ub294 \ud568\uc218 \ub77c\uace0 \uc815\uc758 \ud558\uc790. \uadf8\ub7ec\uba74 \ucd94\uce21 \ubcf4\uc0c1 \ud568\uc218\ub294 \uc544\ub798\uc640 \uac19\uc774 \uc815\uc758 \ud560 \uc218 \uc788\ub2e4. $$ Q_{t}(a) = \\frac{ \\sum_{n=1}^{t}R_{n}L(A_{n}=a) }{ \\sum_{n=1}^{t}L(A_{n}=a) }$$","title":"Action value - \uc5ec\ub7ec \uac1c"},{"location":"rl/5_rl_exploration/#action-value","text":"\ud3c9\uade0 \ud568\uc218\ub294 \uae30\uc874 \ud3c9\uade0 \uac12\uc5d0 \ubcc0\ud654\ub7c9\uc744 \uc801\uc6a9\ud574 \uc8fc\ub294 \ubc29\uc2dd\uc73c\ub85c \uac19\uc740 \uacb0\uacfc\ub97c \ubc1b\uc744 \uc218 \uc788\ub2e4. \uc704\uc758 \uadf8\ub9bc\uc740 $Q_{1} = 1$ \uc774\uace0 $R_{2} = 2$ \uc77c\ub54c \uae30\uc874 \ud3c9\uade0 \ub300\ube44 \ubcc0\ud654\ub7c9\uc744 $R_{2}$, $Q_{1}$ \uc73c\ub85c \uad6c\ud560 \uc218 \uc788\uc74c\uc744 \ub3c4\uc2dd\ud654 \ud588\ub2e4. $q$\ub294 \uc9c4\uc9dc action value \uc774\uace0 $Q_{t}$ \ub294 \ucd94\uce21 \uc774\ub2e4. $$ Q_{t}(A_{t}) = Q_{t-1}(A_{t}) + \\alpha_{t} \\left( R_{t} - Q_{t-1}(A_{t})\\right) $$ $$ \\alpha_{t} = \\frac{1}{N_{t}(A_{t})}, N_{t}(A_{t}) = N_{t-1}(A_{t}) + 1, \\text{ and }, N_{0} = 0, \\forall a $$ $\\alpha$ \ub97c \ub2e8\uacc4 \uc0ac\uc774\uc988\ub77c\uace0 \ud55c\ub2e4.","title":"\uc810\uc9c4\uc801 Action value"},{"location":"rl/5_rl_exploration/#1","text":"\ubcf4\uc0c1 \uce58\uc988: $R = +1$ \ucda9\uaca9: $R = -1$ $Q_{2}$ \uc5d0\uc11c\uc758 action value $Q_{2}(\\text{Red}) = -1$ $Q_{2}(\\text{Blue}) = +1$ $Q_{3}$\uc5d0\uc11c \ube68\uac15\uc744 \ub2f9\uaca8\uc57c \ud560\uae4c \ud30c\ub791\uc744 \ub2f9\uaca8\uc57c \ud560\uae4c? \ud30c\ub791\uc744 \ub2f9\uaca8\uc57c \ud55c\ub2e4. \uc561\uc158 \uac12\uc774 \ub354 \ud06c\uae30 \ub54c\ubb38\uc774\ub2e4.","title":"\uc950 \uc608\uc81c1"},{"location":"rl/5_rl_exploration/#2","text":"\ubcf4\uc0c1 \uce58\uc988: $R = +1$ \ucda9\uaca9: $R = -1$ $Q_{5}$ \uc5d0\uc11c\uc758 action value $Q_{5}(\\text{Red}) = -1$ $Q_{5}(\\text{Blue}) = -0.75$ $Q_{6}$\uc5d0\uc11c \ube68\uac15\uc744 \ub2f9\uaca8\uc57c \ud560\uae4c \ud30c\ub791\uc744 \ub2f9\uaca8\uc57c \ud560\uae4c? \uc774\uc81c \ub2e4\ub978 \ub808\ubc84\ub97c \uc2e4\ud5d8\ud574 \ubd10\uc57c \ud558\uc9c0 \uc54a\uc744\uae4c? \uc5b8\uc81c greedy \ud558\uac8c action value \ub97c \uc0ac\uc6a9 \ud558\ub294\uac78 \uba48\ucdb0\uc57c \ud560\uae4c?","title":"\uc950 \uc608\uc81c2"},{"location":"rl/5_rl_exploration/#regret","text":"\uc5b4\ub5bb\uac8c \ud0d0\uc0c9\uacfc \ud65c\uc6a9\uc744 \ucd5c\uc801\ud654 \ud560 \uac83\uc778\uac00? \ud0d0\uc0c9\uacfc \ud65c\uc6a9\uc774 \ucd5c\uc801\ud654 \ub418\uc5c8\ub2e4\uace0 \ud560 \uc218 \uc788\ub294 \ud3c9\uac00 \uae30\uc900\uc774 \ubb34\uc5c7\uc778\uac00? \uc6b0\ub9ac\uac00 \ucd5c\uc801 value \uac12\uc744 \uc54c\uace0 \uc788\ub2e4\uba74 $$ v_{*} = \\underset{a \\in A}{\\operatorname{max}} q(a) = \\underset{a}{\\operatorname{max}} \\mathbb{E} [ R_{t} \\mid A_{t} = a ]$$ Regret \ub294 \ud2b9\uc815 \ub2e8\uc77c \uc2dc\uc810\uc5d0\uc11c \uc190\uc2e4\ub41c \uae30\ud68c\ub77c\uace0 \uc815\uc758 \ud558\uc790. \uc798\ubabb\ub41c \uc120\ud0dd\uc73c\ub85c \ud2b9\uc815 \uc2dc\uc810\uc5d0 \ucd5c\ub300\ub85c \ubc1b\uc744 \uc218 \uc788\ub294 \uc591\uc744 \ubc1b\uc9c0 \ubabb\ud558\uba74 \ub098\uc911\uc5d0 \uc6b0\ub9ac\ub294 \ud6c4\ud68c\ud55c\ub2e4. \ud574\ub2f9 \ub2e8\uacc4\uc5d0\uc11c \uc5bc\ub9cc\ud07c \uc190\uc2e4\uc744 \ubcf4\uc558\ub0d0\ub294 $\ucd5c\ub300\ub7c9 - \uc120\ud0dd\uc73c\ub85c\ubc1b\uc740\ub7c9$ \uc73c\ub85c \ud45c\ud604 \ud560 \uc218 \uc788\ub2e4. $$ \\text{regre}t_{t} = v_{*} - q(A_{t}) $$ \ud589\uc704\uc790\ub294 \ud559\uc2b5 \ub3c4\uc911 \ubcfc \uc218\ub3c4 \uc54c \uc218\ub3c4 \uc5c6\ub2e4. \ud558\uc9c0\ub9cc \uc6b0\ub9ac\uac00 \uc2e4\ud5d8\uc774 \ub05d\ub09c \ud6c4 \ub2e4\ub978 \uc54c\uace0\ub9ac\uc998\ub4e4\uc744 \ud3c9\uac00\ud558\ub294\ub300\ub294 \uc720\uc6a9\ud558\ub2e4. \ud0d0\uc0c9\uacfc \ud65c\uc6a9\uc758 \ucd5c\uc801\ud654\ub294 \ud6c4\ud68c\uc758 \ucd1d\ud569\uc744 \ucd5c\uc18c\ud654 \ud558\ub294\uac83\uacfc \uac19\ub2e4. $$ L_{t} = \\sum_{i=1}^{t}(v_{*} - q(a_{i}))$$ \ub204\uc801 \ubcf4\uc0c1 \ucd5c\ub300\ud654 $\\equiv$ \ud6c4\ud68c \ucd1d\ud569 \ucd5c\uc18c\ud654 \ubcf4\uc0c1 \ucd5c\ub300\ud654\ub294 \ubb34\ud55c\uc73c\ub85c \uac08 \uc218 \uc788\ub2e4. \ucd1d\ud569 \ucd5c\uc18c\ud654\ub294 \ucd5c\ub300\ud654 \ubcf4\ub2e4 \uc218\ub834 \ud560 \uac00\ub2a5\uc131\uc774 \ub192\ub2e4. \uc5b8\uc81c\ub098 0 \ubcf4\ub2e4 \ud070\uac12, \uc989 \uc591\uc218 0 \uc5d0 \uac00\uae4c\uc6b8 \uc218\ub85d \uc88b\uc74c \ub204\uc801 \ucd1d\ud569\uc740 \uc5ec\ub7ec \uc5d0\ud53c\uc18c\ub4dc \ub4e4\ub85c \ud655\uc7a5 \ub420 \uc218 \uc788\ub2e4. \ud55c \uac1c \uc5d0\ud53c\uc18c\ub4dc \ubcf4\ub2e4 \ud559\uc2b5 \uc804\uccb4\ub85c(\uc5ec\ub7ec \uac1c\uc758 \uc5d0\ud53c\uc18c\ub4dc) \uad00\uc810\uc744 \ud655\ub300 \ud558\uc790.","title":"Regret"},{"location":"rl/5_rl_exploration/#regret-with-greedy","text":"\ud0d0\uc695 \uc54c\uace0\ub9ac\uc998\uc744 \uc0ac\uc6a9 \ud558\uc5ec \uc544\ub798\uc640 \uac19\uc740 \uacb0\uacfc\ub97c \uc5bb\uc5c8\ub2e4\uace0 \uac00\uc815\ud574 \ubcf4\uc790. \ub808\ubc84 \ud655\ub960 \ubcf4\uc0c1 \ud655\ub960 * \ubcf4\uc0c1 $q(a) = \\mathbb{E}[R \\mid A] $ \ube68\uac15 $P(\\text{cheese} \\mid R) = 0.9$ +1 0.9 0.8 \ube68\uac15 $P(\\text{shock} \\mid R) = 0.1$ -1 -0.1 \ud30c\ub791 $P(\\text{cheese} \\mid B) = 0.1$ +1 0.1 -0.8 \ud30c\ub791 $P(\\text{shock} \\mid B) = 0.9$ +1 -0.9 \uc704\uc640 \uac19\uc740 \ud655\ub960\ud45c\uac00 $q(a)$ \uc77c\ub54c \ud0d0\uc695 \uc54c\uace0\ub9ac\uc998\uc744 \uc0ac\uc6a9\ud574\uc11c \ucc98\uc74c \ub450\ubc88\uc5d0 \ud30c\ub791->\uce58\uc988, \ube68\uac15-> \ubc88\uac1c\uac00 \ub098\uc624\uba74 \uc544\ub798\uc640 \uac19\uc774 \uc608\uce21 \ud568\uc218\uac00 \uc798\ubabb \uc124\uc815\ub418\uc5b4 \ud30c\ub791\ub9cc \uacc4\uc18d \ub2f9\uae30\uac8c \ub41c\ub2e4 (\ubb3c\ub860 \ud30c\ub791->\ubc88\uac1c, \ube68\uac15->\uce58\uc988\uac00 \ub098\uc624\uba74 \uc88b\uc740\uac83\ub9cc \ud55c\ub2e4.) $Q_{5}(\\text{Red}) = -1$ $Q_{5}(\\text{Blue}) = -0.75$ \uc774\ud6c4\uc758 regret \ub294 $\\text{regre}t_{t} = v_{*} - q(a_{t}) = 0.8 - (-0.8) = 1.6$ \uac00 \uc9c0\uc18d\uc801\uc73c\ub85c t \ub9c8\ub2e4 \ubc1c\uc0dd\ub41c\ub2e4. regret \uac00 \ubb34\ud55c\uc774 \ucee4\uc9c8\uc218 \uc788\ub2e4. \uc6b0\ub9ac\ub294 \uc5bc\ub9c8\ub098 \ube68\ub9ac \uc99d\uac00\ud558\ub294 \uac00\uc5d0 \uad00\uc2ec\uc774 \uc788\ub2e4. \ud0d0\uc695 \uc815\ucc45\uc740 \uc120\ud615 \ud6c4\ud68c\uc2dd\uc774 \ub9cc\ub4e4\uc5b4 \uc9c4\ub2e4. $1.6t$","title":"Regret with greedy"},{"location":"rl/5_rl_exploration/#counting-regret","text":"\ud589\uc704 \ud6c4\ud68c$\\Delta_{a}$\ub97c \ucd5c\uc801\uac12\uacfc \ud589\uc704\uc758 \uc9c4\uc9dc\uac12\uacfc\uc758 \ucc28\uc774 \ub77c\uace0 \uc815\uc758\ud558\uc790. $$\\Delta_{a} = v_{*} - q(a)$$ \ud6c4\ud68c \ucd1d\ud569\uc740 \ud589\uc704\ub2f9 \uc120\ud0dd\ub41c \ud69f\uc218\uc640 \ud589\uc704 \ud6c4\ud68c\uac12\uc758 \uacf1\uc73c\ub85c \ub098\ud0c0\ub0bc \uc218 \uc788\ub2e4. $$L_{t} = \\sum_{i=1}^{t} v_{*} - q(a_{i}) = \\sum_{a \\in A} N_{t}(a)(v_{*} - q(a)) = \\sum_{a \\in A} N_{t}(a)\\Delta_{a}$$ \uc88b\uc740 \uc54c\uace0\ub9ac\uc998\uc740 \uc561\uc158 \ud6c4\ud68c \uac12\uc774 \ub192\uc740 \uc561\uc158\uc744 \uc801\uac8c \uc120\ud0dd\ud558\ub294 \uac83\uc774\ub2e4. \ud558\uc9c0\ub9cc \uc6b0\ub9ac\ub294 \uc561\uc158 \ud6c4\ud68c \uac12\uc744 \uc54c\uc9c0 \ubabb\ud55c\ub2e4.","title":"Counting Regret"},{"location":"rl/5_rl_exploration/#exploration","text":"\uc6b0\ub9ac\ub294 \uac12\ub4e4\uc744 \ucc3e\uae30 \uc704\ud574 \ud0d0\uc0c9 \ud574\uc57c \ud55c\ub2e4. \ub9ce\uc774 \uc0ac\uc6a9\ub418\ub294 \ubc29\ubc95 $\\varepsilon\\text{-greedy}$ \uc774\ub2e4. \ud655\ub960\uc774 $1 - \\varepsilon)$ \uc774\uba74 greedy action \uc744 \uc120\ud0dd\ud55c\ub2e4. \ud655\ub960\uc774 $\\varepsilon$ \uc774\uba74 random action \uc744 \uc120\ud0dd\ud55c\ub2e4. \ucda9\ubd84 \ud560\uae4c? $\\varepsilon$\uc744 \uc5b4\ub5bb\uac8c \uc120\ud0dd\ud574\uc57c \ud560\uae4c?","title":"Exploration"},{"location":"rl/5_rl_exploration/#varepsilontext-greedy","text":"\ud0d0\uc695 \uc54c\uace0\ub9ac\uc998\uc740 \uc798\ubabb\ub41c \ucd5c\uc801\uac12\uc744 \uc601\uc6d0\uc774 \uc120\ud0dd \ud560 \uc218 \uc788\ub2e4. \ud0d0\uc695 \uc54c\uace0\ub9ac\uc998\uc740 \uc120\ud615\uc801\uc778 \ud6c4\ud68c \uae30\ub300\uac12\uc744 \uac00\uc9c4\ub2e4. $\\varepsilon\\text{-greedy}$ \uc54c\uace0\ub9ac\uc998\uc740 \ud0d0\uc0c9\uc744 \uacc4\uc18d\ud55c\ub2e4. \ud655\ub960\uc774 $1 - \\varepsilon$ \uc774\uba74 $a = \\underset{a \\in A}{\\operatorname{argmax}} Q_{t}(a) $\uc744 \uc120\ud0dd\ud55c\ub2e4. \ud655\ub960\uc774 $\\varepsilon$ \uc774\uba74 random action \uc744 \uc120\ud0dd\ud55c\ub2e4. $\\frac{\\varepsilon}{|A|}$ \uc758 \ud655\ub960\ub85c \uacc4\uc18d \ucd5c\uc801\uac12\uc774 \uc544\ub2cc \uac12\uc744 \uc120\ud0dd\ud55c\ub2e4. $\\varepsilon\\text{-greedy}$ \uc54c\uace0\ub9ac\uc998\ub3c4 $\\varepsilon$\uac00 \uc0c1\uc218\ub77c\uba74 \uc120\ud615\uc801\uc778 \ud6c4\ud68c \ud568\uc218\ub97c \uac00\uc9c4\ub2e4.","title":"$\\varepsilon\\text{-greedy}$ \uc54c\uace0\ub9ac\uc998"},{"location":"rl/5_rl_exploration/#lower-bound","text":"\ucd5c\uace0\ub85c \uc88b\uc740 \uc54c\uace0\ub9ac\uc998\uc774 \ucd5c\uc18c\ud55c\uc73c\ub85c \uac00\uc9c8\uc218 \ubc16\uc5d0 \uc5c6\ub294 \uc5d0\ub7ec\uac12\uc740 \uc5bc\ub9c8\uc77c\uae4c? \uc989 \uc5d0\ub7ec\ub294 \ucd5c\uc18c\ud55c \uc5bc\ub9c8\ubcf4\ub2e4 \ud074\uae4c? \uc54c\uace0\ub9ac\uc998\uc758 \uc810\uc218\ub294 \ucd5c\uc801 \uc561\uc158\uacfc \ub2e4\ub978 \uc561\uc158\ub4e4\uacfc\uc758 \uc720\uc0ac\ub3c4\ub85c \uacb0\uc815\ub41c\ub2e4. \uac00\uc7a5 \uc5b4\ub824\uc6b4 \uc561\uc158 \ucd5c\uc801\ud654 \ubb38\uc81c\ub294 \ube44\uc2b7\ud55c \ubcf4\uc0c1 \ud655\ub960 \ubd84\ud3ec\ub97c \uac00\uc9c0\ub098 \ud3c9\uade0\uac12\uc774 \ub2e4\ub978\uac83 \uc774\ub2e4. \uc704\uc758 \uc18d\uc131\uc744 gap $\\Delta_{a}$ \uadf8\ub9ac\uace0 \ud655\ub960\ubd84\ud3ec\uc758 \uc720\uc0ac\ub3c4 $KL(P(r \\mid a) \\mid \\mid p(r \\mid a_{*}))$\ub85c \ud45c\ud604 \uac00\ub2a5\ud558\ub2e4. $KL(A \\mid B)$ \uc5d0\uc11c A\uc640 B\uc758 \ud655\ub960 \ubd84\ud3ec\uac00 \ub611\uac19\ub2e4\uba74 0, \ub2e4\ub974\ub2e4\uba74 0 \ubcf4\ub2e4 \ud070\uac12\uc744 \uac00\uc9c4\ub2e4. \ub2e4\ub97c \uc218\ub85d \uac12\uc774 \ucee4\uc9c4\ub2e4. $\\frac{\\Delta_{a}}{KL( p(r \\mid a) \\mid \\mid p(r \\mid a_{*}))}$ \ub85c \uc815\uc758 \ud558\uba74 \ud655\ub960 \ubd84\ud3ec\uac00 \uc720\uc0ac \ud560 \uc218\ub85d \uc561\uc158 \ud6c4\ud68c \uac12\uacfc\uc758 \ube44\uac00 \ucee4\uc9c4\ub2e4. \uc989 \uc5b4\ub824\uc6b4 \ubb38\uc81c\uac00 \ub41c\ub2e4.","title":"Lower Bound"},{"location":"rl/5_rl_exploration/#lai-and-robbins","text":"\uc704\uc758 \uc544\uc800\uc528\ub4e4\uc774 \uc99d\uba85\ud588\ub2e4. \ud6c4\ud68c \ucd1d\ud569 \uac12\uc740 \ub85c\uadf8\uac12\uc744 \ucde8\ud55c \ub2e8\uacc4\ubcf4\ub2e4\ub294 \ud06c\ub2e4. $$ \\lim_{t \\to \\infty } L_{t} \\geq \\log t \\sum_{a \\mid \\Delta_{a} \\gt 0 } \\frac{\\Delta_{a}}{KL( p(r \\mid a) \\mid \\mid p(r \\mid a_{*}))}$$ \uc561\uc158 \ud6c4\ud68c$\\Delta_{a}$\uac00 0 \ubcf4\ub2e4 \ud070 \ubaa8\ub4e0 \uc561\uc158\uc5d0 \ub300\ud574\uc11c KL \uc720\uc0ac\ub3c4\uc640 \uc561\uc158 \ud6c4\ud68c\uc758 \ube44\ub97c \ub354\ud55c \uac12 * t \ub85c\uadf8\ub294 \uc120\ud615\ubcf4\ub2e4 \ud6e8\uc52c \uc791\ub2e4. \ucd5c\uc120\uc758 \uac12\uc744 \uc815\uc758 \ud588\uc73c\ub2c8 \ucd5c\uc120\uc758 \uac12\uc5d0 \uadfc\uc811 \ud560 \uc218 \uc788\ub294 \uc54c\uace0\ub9ac\uc998\ub4e4\uc5d0 \ub300\ud574 \ub17c\uc758\ud574 \ubcf4\uc790.","title":"\uacf5\ub9ac(Lai and Robbins)"},{"location":"rl/5_rl_exploration/#_9","text":"\uc544\ub798\uc758 1\ubc88\uacfc \uac19\uc740 \ud655\ub960 \ubd84\ud3ec\ub97c \ucd94\uce21 \ud588\uc77c\ub54c \uc6b0\ub9ac\ub294 \uc5b4\ub514\ub97c \ub354 \ud0d0\uc0c9\ud574\uc57c \ud560\uae4c? \uac12\uc774 \ucd94\uce21\uc774 \uc548 \ub420\uc218\ub85d \ud574\ub2f9 \uc561\uc158\uc744 \ub354 \ud0d0\ud5d8\ud574\uc57c \ud55c\ub2e4. $a_{1}$ \uc744 \uc120\ud0dd \ud588\uc744\ub54c \ubcf4\uc0c1 \uac12 \ud3c9\uade0\uc774 0 \ubd84\uc0b0\uc774 0.1 \uc774 \uacc4\uc18d \ub098\uc624\uba74 \uc6b0\ub9ac\uc758 $a_{1}$ \ucd94\uce21 \ud655\ub960 \ubd84\ud3ec\ub294 2\ubc88\ucc98\ub7fc \uc62e\uaca8 \uac08\uac83\uc774\ub2e4. 3\ubc88\ucc98\ub7fc $a_{3}$ \uc744 \uc120\ud0dd \ud588\uc744\ub54c \ubcf4\uc0c1 \uac12 \ud3c9\uade0\uc774 1.7 \ubd84\uc0b0\uc774 1.7 \uc774 \uacc4\uc18d \ub098\uc624\uba74 \uc6b0\ub9ac\uc758 $a_{3}$ \ucd94\uce21 \ud655\ub960 \ubd84\ud3ec\ub294 4\ubc88\ucc98\ub7fc \uc62e\uaca8 \uac08\uac83\uc774\ub2e4.","title":"\uc608\uc81c"},{"location":"rl/5_rl_exploration/#upper-confidence-bounds","text":"\uc880\uc804\uc5d0\ub294 \ucd5c\uc18c \uc5d0\ub7ec\uac12\uc744 \uc0ac\uc6a9\ud588\ub2e4. \ubc94\uc704\ub97c \uc9c0\uc815\ud558\uae30 \uc704\ud574 \uc774\ubc88\uc5d0\ub294 \ucd5c\ub300 \uc2e0\ub8b0 \ubc94\uc704 \uac12\uc744 \uace0\ub824\ud574 \ubcf4\uc790. \uac01\uac01\uc758 \uc561\uc158 \uac12 \ub9c8\ub2e4 UCB \ub97c \uce21\uc815\ud558\uc790. UCB $U_{t}(a)$ \ub294 \ub192\uc740 \ud655\ub960\ub85c $q(a) \\leq Q_{t}(a) + U_{t}(a)$\ub97c \ub9cc\uc871 \uc2dc\ucf1c\uc57c \ud55c\ub2e4. \uc561\uc158\uc744 \uc120\ud0dd \ud560 \ub54c UCB \uac00 \ucd5c\ub300\uac00 \ub418\ub294 \uc561\uc158\uc744 \uc120\ud0dd\ud558\uc790. $$ a_{t} = \\underset{a \\in A}{\\operatorname{argmax}} \\left( Q_{t}(a) + U_{t}(a) \\right)$$ \uc561\uc158\uc758 \ucd94\uce21 \uac12\uc774 \ubd88\ud655\uc2e4 \ud560 \uc218\ub85d \ub354 \ub9ce\uc774 \uc120\ud0dd\ub418\uc5b4\uc57c \ud55c\ub2e4. \uc989 \uc561\uc158\uc758 \uc120\ud0dd \ud69f\uc218 $N(a)$ \uac00 \uc911\uc694\ud558\ub2e4. $N_{t}(a)$\uac00 \uc801\uac8c \uc120\ud0dd \ub418\uc5c8\ub2e4\uba74 $\\to$ $U_{t}(a)$ \ub294 \ucee4\uc57c \ud55c\ub2e4.(\ucd94\uce21 \ub41c \uac12\uc758 \ubd88\ud655\uc2e4\uc131\uc774 \ub192\ub2e4.) $N_{t}(a)$\uac00 \ub9ce\uc774 \uc120\ud0dd \ub418\uc5c8\ub2e4\uba74 $\\to$ $U_{t}(a)$ \ub294 \uc791\uc544\uc57c \ud55c\ub2e4.(\ucd94\uce21 \ub41c \uac12\uc758 \ubd88\ud655\uc2e4\uc131\uc774 \uc801\ub2e4.) \uc911\uc2ec\uadf9\ud55c \uc815\ub9ac\uc5d0 \uc758\ud574\uc11c \ubd88\ud655\uc2e4\uc131\uc740 $\\sqrt{N_{t}(a)}$ \ub85c \ud3c9\uade0\uc801\uc73c\ub85c \uac10\uc18c\ud55c\ub2e4. \uc6b0\ub9ac\ub294 \uc5ec\uae30\uc11c \ucd5c\uc801 \uc54c\uace0\ub9ac\uc998\uc744 \uc774\ub04c\uc5b4 \ub0bc\uc218 \uc788\ub294\uac00?","title":"Upper Confidence Bounds"},{"location":"rl/5_rl_exploration/#_10","text":"\uc6b0\ub9ac\ub294 \ud6c4\ud68c \ucd1d\ud569\uc744 \ucd5c\uc18c\ud654 \ud560\ub824\uace0 \ud55c\ub2e4. $\\sum_{a}N_{t}(a) \\Delta_{a}$ \ub9cc\uc57d $\\Delta_{a}$ \uac00 \ud06c\ub2e4\uba74 $N_{t}(a)$ \uac00 \uc801\uc5b4\uc57c \ud55c\ub2e4. \ub9cc\uc57d $\\Delta_{a}$ \uac00 \uc791\ub2e4\uba74 $N_{t}(a)$ \uac00 \ucee4\uc57c \ud55c\ub2e4. \ubaa8\ub4e0 $N_{t}(a)$\uac00 \uc791\uc744 \uc218 \ub294 \uc5c6\ub2e4.(\ucd1d\ud569\uc774 t\uac00 \ub418\uc5b4\uc57c \ud558\uae30 \ub54c\ubb38\uc5d0) \uc6b0\ub9ac\ub294$N_{t}(a)$ \uc5d0 \ub300\ud574 \uc54c\uace0 \uc788\ub2e4. $\\Delta_{a}$ \uc5d0 \ub300\ud574 \uc54c\uace0 \uc788\ub294\uac74 \uc5c6\uc744\uae4c?","title":"\uc54c\uace0\ub9ac\uc998 \uc544\uc774\ub514\uc5b4"},{"location":"rl/5_rl_exploration/#hoeffdings-inequality","text":"","title":"Hoeffding's Inequality"},{"location":"rl/5_rl_exploration/#_11","text":"$X_{1},...,X_{n}$ \uc774 i.i.d \uc5d0\uc11c \ucd94\ucd9c\ub41c \ud655\ub960 \ubcc0\uc218\uc774\uace0 $[0, 1]$ \uc0ac\uc774\uc774\ub2e4. $\\bar X_{t} = \\frac{1}{n} \\sum_{i=1}^{n}X_{i}$ \ub97c \uc0d8\ud50c \ud3c9\uade0\uc774\ub77c\uace0 \ud558\uc790. \uadf8\ub7ec\uba74 \uc544\ub798\uc758 \uc2dd\uc774 \uc131\ub9bd\ud55c\ub2e4. $$ p(\\mathbb{E} [ X] \\geq \\bar X_{n} + u) \\leq e^{-nu^{2}}$$ \ud655\ub960 \ubcc0\uc218 X \uc758 \uae30\ub300\uac12\uc774 \uc0d8\ud50c \ud3c9\uade0 + \ubcf4\ub108\uc2a4 \ubcf4\ub2e4 \ud074 \ud655\ub960\uc740 \ucd5c\ub300 $e^{-nu^{2}}$ \uc774\ub2e4. \uc704 \uacf5\ub9ac\ub97c \uc544\ub798\uc758 \uc2dd\uc73c\ub85c \uc6b0\ub9ac\uc758 q \uac12\uc5d0 \uc801\uc6a9 \ud560 \uc218 \uc788\ub2e4. \ub9cc\uc57d $R_{t} \\in [0, 1]$ \uc774\ub77c\uba74 $$ p(q(a) \\geq Q_{t}(a) + U_{t}(a)) \\leq e^{-N_{t}(a)U_{t}(a)^{2}}$$ \uc6b0\ub9ac\uac00UCB\ub97c \ud2b9\uc815 \ud655\ub960 p \uae4c\uc9c0 \ub77c\uace0 \uc815\uc758\ud55c\ub2e4\uba74 $U_{t}(a)$ \ub97c \uc544\ub798\uc640 \uac19\uc774 \uad6c\ud560 \uc218 \uc788\ub2e4. $$e^{-N_{t}(a)U_{t}(a)^{2}} = p$$ $$U_{t}(a) = \\sqrt{ \\frac{-\\log p}{2N_{t}(a)}}$$ \uc6b0\ub9ac\uac00 \ub9ce\uc740 \ubcf4\uc0c1\uc744 \uad00\ucc30 \ud560 \uc218\ub85d p\ub97c \uc904\uc778\ub2e4\uba74 e.g $p = 1/t = t^{-1}$ $$U_{t}(a) = \\sqrt{ \\frac{\\log t}{2N_{t}(a)}}$$ \uc704\uc2dd\uc740 \uc9c0\uc18d\uc801\uc73c\ub85c \ud0d0\uc0c9 \ud560\uac83\uc774\ub2e4. \ud558\uc9c0\ub9cc $t \\to \\infty$ \ub85c \uac08\uc218\ub85d \ucd5c\uc801 \uc561\uc158\uc744 \ub354 \ub9ce\uc774 \uc120\ud0dd \ud560 \uac83\uc774\ub2e4. \ubd84\ubaa8\ub294 \uc120\ud615\uc73c\ub85c \uc99d\uac00\ud558\uace0 \ubd84\uc790\ub294 \ub85c\uadf8\ub85c \uc99d\uac00\ud558\uae30 \ub54c\ubb38\uc5d0 \uc810\uc810 \uc791\uc544 \uc9c4\ub2e4.","title":"\uacf5\ub9ac"},{"location":"rl/5_rl_exploration/#p-with-upper-confidence-bounds","text":"\ubcc0\uc218\ub97c \uc544\ub798\uc640 \uac19\uc774 \uc815\uc758\ud558\uace0 \uace0\uc815 \ud558\uc790 $q(a)$ \ub294 i.i.d \uc774\uba70 $[0, 1]$ \uc0ac\uc774\uc758 \uac12 $Q_t(a) = 0.5$ $N_t(a) = 10$ P\uc758 \uac12\uc744 \uc9c0\uc18d\uc801\uc73c\ub85c \uc904\uc5ec\uac00\uba74$U_{t}(a)$ \ub294 \ucee4\uc9c0\uace0 \ud574\ub2f9 \uc561\uc158\uc744 \ud0d0\uc0c9\ud558\uac8c \ub41c\ub2e4.","title":"P with Upper Confidence Bounds"},{"location":"rl/5_rl_exploration/#n_t-with-upper-confidence-bounds","text":"\ubcc0\uc218\ub97c \uc544\ub798\uc640 \uac19\uc774 \uc815\uc758\ud558\uace0 \uace0\uc815 \ud558\uc790 $q(a)$ \ub294 i.i.d \uc774\uba70 $[0, 1]$ \uc0ac\uc774\uc758 \uac12 $Q_{t}(a) = 0.5$ $U_{t}(a) = 1E-9$ \ub9ce\uc774 \ud0d0\uc0c9\ud55c \uc561\uc158\uc77c\uc218\ub85d \uac12\uc774 \ud655\uc2e4\ud558\uae30 \ub54c\ubb38\uc5d0 \uc801\uac8c \ud0d0\uc0c9 \ud574\uc57c \ud55c\ub2e4. $N_{t}(a)$\uac00 \uc801\uac8c \uc120\ud0dd \ub418\uc5c8\ub2e4\uba74 $\\to$ $U_{t}(a)$ \ub294 \ucee4\uc57c \ud55c\ub2e4. $N_{t}(a)$\uac00 \ub9ce\uc774 \uc120\ud0dd \ub418\uc5c8\ub2e4\uba74 $\\to$ $U_{t}(a)$ \ub294 \uc791\uc544\uc57c \ud55c\ub2e4. \uc544\ub798\ucc98\ub7fc \ubcc0\uc218\ub97c \uace0\uc815\ud55c \ud6c4 $N_{t}(a)$ \uc744 \uc99d\uac00\uc2dc\ud0a4\uba74 $U_{t}(a)$ \ub294 \uc810\uc810 \uac10\uc18c \ud558\uc9c0\ub9cc \uc644\uc804\uc774 0 \uc774 \ub418\uc9c0 \uc54a\ub294\ub2e4.","title":"$ N_{t} $ with Upper Confidence Bounds"},{"location":"rl/5_rl_exploration/#auer-et-al-2002","text":"UCB \uc54c\uace0\ub9ac\uc998 ($c = \\sqrt 2$) \ub294 \ud6c4\ud68c \ucd1d\ud569 \uae30\ub300\uac12\uc744 \ub85c\uadf8\uac12\uc73c\ub85c \uac19\ub294\ub2e4. $$ L_{t} \\leq 8 \\sum_{a \\mid \\Delta_{a} > 0} \\frac{\\log t}{\\Delta_{a}} + O(\\sum_{a}\\Delta_{a}), \\forall t$$","title":"\uacf5\ub9ac (Auer et al. 2002)"},{"location":"rl/5_rl_exploration/#_12","text":"UCB \ub97c \uc0ac\uc6a9\ud558\uba74 \ud6c4\ud68c \ucd1d\ud569\uc740 \ub85c\uadf8\uac12\uc774\ub2e4. $$O(\\log t) \\leq L_{t} \\leq O(\\log t)$$","title":"\uacb0\ub860"},{"location":"rl/5_rl_exploration/#ucb","text":"$$ a_{t} = \\underset{a \\in A}{\\operatorname{argmax}} Q_{t}(a) + c \\sqrt{ \\frac{\\log t}{N_{t}(a)}}$$ - C\ub294 \ud558\uc774\ud37c \ud30c\ub77c\ubbf8\ud130\ub85c \uc0ac\uc6a9\ub418\uae30\ub3c4 \ud568. (\uc0c1\uc218 \ucde8\uae09) - \uc5bc\ub9c8\ub098 \ube68\ub9ac \ubc30\uc6b8\uae4c \uc815\ub3c4\uc758 \ub290\ub08c - \ubcf4\ud1b5 1\ub85c \uc2dc\uc791\ud574 0,2,3 \ub97c \ud14c\uc2a4\ud2b8 \ud568 - \ud2b9\uc815 \uc561\uc158\uc774 \uc624\ub798\ub3d9\uc548 \uc120\ud0dd\uc774 \uc548\ub418\uba74 \ubcf4\ub108\uc2a4 \uac12\uc774 \ucee4\uc9d0 - \ub2e4\ub978 \ubaa8\ub4e0 \uc561\uc158 \uac12\ub4e4\ubcf4\ub2e4 \uacb0\uad6d\uc5d4 \ucee4\uc9d0 \uadf8\ub798\uc11c \uc120\ud0dd\ub418\uba74 \ubcf4\ub108\uc2a4 \uac12\uc774 \ud655 \uc791\uc544\uc9d0 - \uc9c1\uac10 - $\\Delta_{a}$ \uac00 \ud06c\ub2e4\uace0 \uac00\uc815\ud574\ubcf4\uc790 \uadf8\ub807\ub2e4\uba74 - $N_{t}(a)$ \uac00 \uc801\uc744\uac83\uc774\ub2e4. \uc65c\ub0d0\ud558\uba74 $U_{t}(a)$\uc560 \uc758\ud574\uc11c\ub294 \uc544\uc8fc \uac00\ub054\uc529 \uc804\uccb4 gap\uc744 \ud3c9\uac00 \ud558\uae30 \ub54c\ubb38\uc774\ub2e4. - \uadf8\ub807\ub2e4\uba74 $\\Delta_{a}$ \uac00 \uc791\uac70\ub098 \ub610\ub294 $N_{t}(a)$ \uac00 \uc791\uac70\ub098 \uc774\ub2e4.","title":"UCB"},{"location":"rl/5_rl_exploration/#bayesian-bandits","text":"\ubcf4\uc0c1\uc758 \ud655\ub960 \ubd84\ud3ec\ub97c \ud30c\ub77c\ubbf8\ud130\uc640 \uc561\uc158\uc744 \uc0ac\uc6a9\ud574 \ucd94\uce21\ud574\ubcf4\uc790. \uc561\uc158\uc758 \ubcf4\uc0c1 \ud655\ub960 \ubd84\ud3ec\ub97c \uc870\uc815\ud558\ub294 \ud30c\ub77c\ubbf8\ud130\ub4e4\uc744 $\\theta$ \ub77c\uace0 \ud558\uc790. \uc6b0\ub9ac\ub294 $q(a) = p(R \\mid \\theta, a)$ \ub97c \uc54c\uace0 \uc2f6\ub2e4. \uacfc\uac70\uc758 \ud655\ub960\uc744 \ubc1c\uacac\ub41c \uc99d\uac70 \ucabd\uc73c\ub85c \uc870\uae08 \ubcc0\uacbd\ud558\ub294 \ubca0\uc774\uc9c0\uc548 \ucd94\ub860\uc744 \uc0ac\uc6a9\ud574 \ubcf4\uc790. $$p(R \\mid \\theta, a) \\propto p(R_{t} \\mid \\theta, a)p_{t-1}(\\theta \\mid a)$$ \uc0ac\ud6c4 \ud655\ub960\uc740 $p(R \\mid \\theta, a)$\uc0c8\ub85c\uc6b4 \ubcf4\uc0c1\uc758 \ud655\ub960\uacfc $p(R_{t} \\mid \\theta, a)$ \uc0ac\uc804 \ud655\ub960\uc758 $p_{t-1}(\\theta \\mid a)$ \uacf1\uc5d0 \ube44\ub840\ud55c\ub2e4. \ub9ce\uc740 \uc0ac\uc804 \uc815\ubcf4\ub97c \uc778\ucf54\ub529 \ud560 \uc218 \uc788\uac8c \ud574\uc900\ub2e4. $p_{0}(\\theta \\mid a)$","title":"Bayesian Bandits"},{"location":"rl/5_rl_exploration/#_13","text":"\uc2ac\ub86f\uba38\uc2e0\uc774 \ubca0\ub974\ub204\uc774 \ubd84\ud3ec\ub97c \uac00\uc9c0\uace0 \uc788\ub2e4\uace0 \ud558\uc790. \ubcf4\uc0c1\uc740 0 \uc544\ub2c8\uba74 1\uc774\ub2e4. \ubaa8\ub4e0 \uc561\uc158\uc758 \uc774\uc804 \ubd84\ud3ec\ub294 $[0, 1]$ \uc0ac\uc774\uc5d0 \uade0\ub4f1\ubd84\ud3ec \ud55c\ub2e4 \ubca0\ud0c0 \ubd84\ud3ec\ub85c \uc0ac\ud6c4 \ud655\ub960\ubd84\ud3ec\ub97c \ubaa8\ub378\ub9c1\ud558\uc790$Beta(\\alpha_{a}, \\beta_{a})$ \ucd5c\ucd08 $\\alpha_{a}=1, \\beta_{a}=1$ \ub85c \uade0\ub4f1\ud558\uac8c \uc2dc\uc791\ud55c\ub2e4. \uc774\ud6c4 \ubcf4\uc0c1\uc5d0 \ub530\ub77c \ud30c\ub77c\ubbf8\ud130\ub97c \ubcc0\uacbd\ud55c\ub2e4. $\\alpha_{a_{t}} \\leftarrow \\alpha_{a_{t}} + 1 \\text{ when } R_{t} = 0$ $\\beta_{a_{t}} \\leftarrow \\beta_{a_{t}} + 1 \\text{ when } R_{t} = 1$ TODO \ubcf4\uc0c1 0\uc5d0 \uc54c\ud30c\uac00 +1, \ubcf4\uc0c1 1\uc5d0 \ubca0\ud0c0 +1 \ub418\ub294 \ubd80\ubd84\uc774 \uc774\uc0c1\ud558\ub2e4 \ud655\uc778 \ud574\ubcf4\uc790. \ubcf4\uc0c1\uc774 $R_{1} = 1, R_{2} = 1, R_{3} = 0, R_{4} = 0$ \uc73c\ub85c \ubc1c\uc0dd\ub41c\ub2e4\uba74 \uc704\uc758 \uc2dd\uc5d0 \uc758\ud574 \uc544\ub798\uc640 \uac19\uc774 \ubca0\ud0c0 \ubd84\ud3ec\uac00 \ubcc0\uacbd\ub41c\ub2e4. code \ucd5c\ucd08\uc5d0 q \uac00 0 \uc778\uc9c0 1\uc778\uc9c0 \uc54c\uc9c0 \ubabb\ud55c\ub2e4. \ubcf4\uc0c1\uc774 1\uc774 \ub450\ubc88 \uc5f0\uc18d \ub098\uc624\uba74\uc11c 3)\ubc88 \uadf8\ub9bc q \ub294 1 \uc77c\uac00\ub2a5\uc131\uc774 \ub192\uc544\uc9c4\ub2e4. \ubcf4\uc0c1\uc774 0\uc774 \ud55c\ubc88 \ub098\uc624\uba74\uc11c 4)\ubc88 \uadf8\ub9bc q \ub294 1 \uc77c\uac00\ub2a5\uc131\uc774 \uc5c6\ub2e4. \ubcf4\uc0c1\uc774 0\uc774 \ud55c\ubc88 \ub354 \ub098\uc624\uba74\uc11c 5)\ubc88 \uadf8\ub9bc q \ub294 0.5 \uc77c \uac00\ub2a5\uc131\uc774 \uac00\uc7a5 \ub192\uc544\uc9c4\ub2e4.","title":"\uc608\uc81c"},{"location":"rl/5_rl_exploration/#bayesian-with-ucb","text":"\uc561\uc158 \ud568\uc218\uc758 \uc0ac\ud6c4 \ud655\ub960 \ubd84\ud3ec\ub97c \uacc4\uc0b0\ud558\uba74 \uc704\ucc98\ub7fc \ud45c\ud604 \ud560 \uc218 \uc788\ub2e4. \uc0ac\ud6c4 \ud655\ub960\uc744 \uc0ac\uc6a9\ud574\uc11c UCB \ub97c \uc0ac\uc6a9 \ud560 \uc218 \uc788\ub2e4. $$U_{t}(a) = c\\sigma(a)$$ $Q_{t}(a) + c\\sigma(a)$\uc744 \ucd5c\ub300\ud654 \ud558\ub294 \uc561\uc158\uc744 \uc120\ud0dd","title":"Bayesian with UCB"},{"location":"rl/5_rl_exploration/#policy","text":"Policy $\\pi(a)$ \ub97c \ubc14\ub85c \ubc30\uc6b0\ub294\uac74 \uc5b4\ub5a8\uae4c? policy \ub294 $f: state \\to action$ \ud568\uc218 \uc774\ub2e4. \ud558\uc9c0\ub9cc \uc5ec\uae30\uc11c state \ub294 \ud55c \uac1c \uc774\uae30 \ub54c\ubb38\uc5d0 action \ub9cc \ud45c\ud604 $\\pi(a)$ \ub294 \ud574\ub2f9 \uc561\uc158\uc774 \uc2e4\ud589\ub420 \ud655\ub960\ub85c \uc815\uc758 \ud560 \uc218 \uc788\ub2e4. \uc815\ucc45\uc744 value \ud568\uc218 \uc5c6\uc774 \ud559\uc2b5 \ud560 \uc218 \uc788\uc744\uae4c? $H_{t}(a)$ \ub97c preference \ub77c\uace0 \uc815\uc758 \ud558\uc790. $\\pi(a): [0, 1] \\text{ and } \\sum_{a} \\pi(a) = 1$ $$ \\pi(a) = \\frac{e^{H_{t}(a)}}{ \\sum_{b} e^{H_{t}(b)}}$$ \uc120\ud638\ub3c4\ub294 value \ud568\uc218\uc640 \uaf2d \uc5f0\uad00\ub418\uc9c0 \uc54a\uc544\ub3c4 \ub41c\ub2e4. \uc120\ud638\ub3c4\ub97c \ud559\uc2b5 \uac00\ub2a5\ud55c \ud30c\ub77c\ubbf8\ud130\ub85c \ubcf4\uc790. \uc5b4\ub5bb\uac8c \uc120\ud638\ub3c4\ub97c \ud559\uc2b5 \ud560 \uac74\uc778\uac00?","title":"Policy"},{"location":"rl/5_rl_exploration/#policy-gradients","text":"Idea: \uc88b\uc740 \uc561\uc158\uc774\ub780 \ubcf4\uc0c1\uc758 \uae30\ub300\uac12\uc774 \uc99d\uac00\ud558\ub294 \uac83\uc774\ub2e4. \uae30\ub300\uac12\uc758 \uc99d\uac00\ub97c \uacbd\uc0ac\ub3c4 \uc0c1\uc2b9\uc73c\ub85c \uc0dd\uac01 \ud560 \uc218 \uc788\ub2e4. \uc2ac\ub86f\uba38\uc2e0\uc5d0\uc11c\ub294 $$ \\theta = \\theta + \\alpha \\nabla_{\\theta}\\mathbb{E}[ R_{t} \\mid \\theta ]$$ $\\theta$ \ub294 \uc815\ucc45\uc758 \ud30c\ub77c\ubbf8\ud130\uc774\uba70 \uc120\ud638\ub3c4\uc5d0 \uc601\ud5a5\uc744 \uc900\ub2e4\uace0 \uc815\uc758\ud558\uc790. $\\theta$ \ub97c \ubcc0\uacbd\ud558\uba74 \uc815\ucc45\uc774 \ubcc0\uacbd\ub418\uace0 \uadf8\ub7ec\uba74 \ubcf4\uc0c1\uc774 \ubcc0\uacbd\ub41c\ub2e4. \uacbd\uc0ac\ub3c4\ub97c \uad6c \ud560 \uc218 \uc788\uc744\uae4c?","title":"Policy gradients"},{"location":"rl/5_rl_exploration/#gradient-bandits","text":"\uc704\uc758 \uc2dd\uc744 \uc218\ud559\uc744 \uc0ac\uc6a9\ud574 \uacc4\uc0b0 \uac00\ub2a5\ud55c \uc2dd\uc73c\ub85c \uc7ac \ud45c\ud604\ud574 \ubcf4\uc790. $\\theta$\ub97c \uc8fc\uc5c8\uc744\ub54c \uae30\ub300\uac12\uc740 $\\theta$ \uc815\ucc45\uc744 \uc0ac\uc6a9 \ud560\ub54c\uc758 \uc561\uc158 \ubcc4 \ubcf4\uc0c1 \uae30\ub300\uac12\uacfc \uac19\ub2e4. $$\\nabla_{\\theta} \\mathbb{E} [ R_{t} \\mid \\theta ] = \\nabla_{\\theta} \\sum_{a} \\pi_{\\theta}(a) \\mathbb{E} [ R_{t} \\mid A_{t} = a ]$$ \uc561\uc158\ubcc4 \uae30\ub300 \ubcf4\uc0c1\uc740 $q(a)$ $$ = \\nabla_{\\theta} \\sum_{a} \\pi_{\\theta}(a) q(a)$$ $q(a)$ \ub294 $\\theta$ \uc640 \uc0c1\uad00\uc5c6\uc74c\uc73c\ub85c \uc815\ucc45\ub9cc \ubbf8\ubd84\ud558\uba74 \ub41c\ub2e4. $$ = \\sum_{a} q(a) \\nabla_{\\theta} \\pi_{\\theta}(a) $$ 1 \uc744 \uacf1\ud574\ub3c4 \uc0c1\uad00\uc5c6\ub2e4. $\\frac{\\pi_{\\theta}(a)}{\\pi_{\\theta}(a)} = 1$ $$ = \\sum_{a} q(a) \\frac{\\pi_{\\theta}(a)}{\\pi_{\\theta}(a)} \\nabla_{\\theta} \\pi_{\\theta}(a) $$ \uc2dd\uc744 \uc815\ub9ac $$ = \\sum_{a} \\pi_{\\theta}(a) q(a) \\frac{\\nabla_{\\theta} \\pi_{\\theta}(a)}{\\pi_{\\theta}(a)} $$ \uae30\ub300\uac12\uc73c\ub85c \ub2e4\uc2dc \ubcc0\uacbd $a \\to A_{t}$ \ub85c \ubcc0\uacbd\ub428 $$ = \\mathbb{E} \\left[ R_{t} \\frac{\\nabla_{\\theta} \\pi_{\\theta}(A_{t})}{\\pi_{\\theta}(A_{t})} \\right] $$ \ubbf8\ubd84 \ud568\uc218\ub97c \uc6d0\ub798 \ud568\uc218\ub85c \ub098\ub204\uba74 \uc6d0\ub798 \ud568\uc218\uc758 \ub85c\uadf8 \ubbf8\ubd84\uacfc \uac19\ub2e4. $$ = \\mathbb{E} \\left[ R_{t} \\nabla_{\\theta} \\log \\pi_{\\theta}(A_{t}) \\right] $$","title":"Gradient bandits"},{"location":"rl/5_rl_exploration/#reference","text":"\ucc38\uc870 logarithm","title":"Reference"}]}