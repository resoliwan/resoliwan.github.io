<!DOCTYPE html>
<html lang="en">
    <head>
        <meta charset="utf-8">
        <meta http-equiv="X-UA-Compatible" content="IE=edge">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        
        
        
        <link rel="shortcut icon" href="../../img/favicon.ico">
        <title>3. Neural Networks Foundations - Logic's home</title>
        <link href="../../css/bootstrap.min.css" rel="stylesheet">
        <link href="../../css/font-awesome.min.css" rel="stylesheet">
        <link href="../../css/base.css" rel="stylesheet">
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/github.min.css">

        <script src="../../js/jquery-1.10.2.min.js" defer></script>
        <script src="../../js/bootstrap.min.js" defer></script>
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/highlight.min.js"></script>
        <script>hljs.initHighlightingOnLoad();</script>
        <script>
            (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
            (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
            m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
            })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

            ga('create', 'UA-135539521-1', 'resoliwan.github.io');
            ga('send', 'pageview');
        </script> 
    </head>

    <body>
        <div class="navbar fixed-top navbar-expand-lg navbar-dark bg-primary">
            <div class="container">
                <a class="navbar-brand" href="../..">Logic's home</a>
                <!-- Expander button -->
                <button type="button" class="navbar-toggler" data-toggle="collapse" data-target="#navbar-collapse">
                    <span class="navbar-toggler-icon"></span>
                </button>

                <!-- Expanded navigation -->
                <div id="navbar-collapse" class="navbar-collapse collapse">
                        <!-- Main navigation -->
                        <ul class="nav navbar-nav">
                            <li class="navitem">
                                <a href="../.." class="nav-link">README.md</a>
                            </li>
                            <li class="dropdown">
                                <a href="#" class="nav-link dropdown-toggle" data-toggle="dropdown">Agile <b class="caret"></b></a>
                                <ul class="dropdown-menu">
                                    
<li>
    <a href="../../agile/scrum_1/" class="dropdown-item">1. 스크럼을 사용한 애자일 소프트웨어 개발 방법론</a>
</li>
                                    
<li>
    <a href="../../agile/scrum_2/" class="dropdown-item">2. 스크럼 준비</a>
</li>
                                    
<li>
    <a href="../../agile/scrum_3/" class="dropdown-item">3. 스크럼 실천</a>
</li>
                                    
<li>
    <a href="../../agile/scrum_4/" class="dropdown-item">4. 스크럼 적용</a>
</li>
                                </ul>
                            </li>
                            <li class="dropdown active">
                                <a href="#" class="nav-link dropdown-toggle" data-toggle="dropdown">Dl <b class="caret"></b></a>
                                <ul class="dropdown-menu">
                                    
<li>
    <a href="../1_dl_introduction/" class="dropdown-item">1. Introduction to Introduction to Machine Learning Based AI</a>
</li>
                                    
<li>
    <a href="../2_dl_tensorflow/" class="dropdown-item">2. Introduction to TensorFlow</a>
</li>
                                    
<li>
    <a href="../3_dl_1_mnist/" class="dropdown-item">3.1 MNIST</a>
</li>
                                    
<li>
    <a href="./" class="dropdown-item active">3. Neural Networks Foundations</a>
</li>
                                    
<li>
    <a href="../4_dl_beyond_image/" class="dropdown-item">4. Beyond Image Recognition, End-to-End Learning, Embeddings</a>
</li>
                                </ul>
                            </li>
                            <li class="dropdown">
                                <a href="#" class="nav-link dropdown-toggle" data-toggle="dropdown">Etc <b class="caret"></b></a>
                                <ul class="dropdown-menu">
                                    
  <li class="dropdown-submenu">
    <a href="#" class="dropdown-item">Algorithm</a>
    <ul class="dropdown-menu">
            
<li>
    <a href="../../etc/algorithm/en_2_getting_started/" class="dropdown-item">2.Getting Started</a>
</li>
    </ul>
  </li>
                                    
  <li class="dropdown-submenu">
    <a href="#" class="dropdown-item">Android</a>
    <ul class="dropdown-menu">
            
  <li class="dropdown-submenu">
    <a href="#" class="dropdown-item">Googleplay</a>
    <ul class="dropdown-menu">
            
<li>
    <a href="../../etc/android/googleplay/googleplay_billing/" class="dropdown-item">Google Play Billing</a>
</li>
            
<li>
    <a href="../../etc/android/googleplay/googleplay_billing_library/" class="dropdown-item">Google Play Billing Library</a>
</li>
            
<li>
    <a href="../../etc/android/googleplay/overview/" class="dropdown-item">Overview</a>
</li>
    </ul>
  </li>
            
  <li class="dropdown-submenu">
    <a href="#" class="dropdown-item">Publish</a>
    <ul class="dropdown-menu">
            
<li>
    <a href="../../etc/android/publish/1_publish_overview/" class="dropdown-item">Publish your app</a>
</li>
            
<li>
    <a href="../../etc/android/publish/2_prepare_for_release/" class="dropdown-item">Prepare for release</a>
</li>
            
<li>
    <a href="../../etc/android/publish/3_version/" class="dropdown-item">Version your app</a>
</li>
            
<li>
    <a href="../../etc/android/publish/4_sign/" class="dropdown-item">Sign your app</a>
</li>
    </ul>
  </li>
    </ul>
  </li>
                                    
  <li class="dropdown-submenu">
    <a href="#" class="dropdown-item">Books</a>
    <ul class="dropdown-menu">
            
<li>
    <a href="../../etc/books/2018_12_lovethatdog/" class="dropdown-item">Love that dog</a>
</li>
    </ul>
  </li>
                                    
  <li class="dropdown-submenu">
    <a href="#" class="dropdown-item">Idea</a>
    <ul class="dropdown-menu">
            
<li>
    <a href="../../etc/idea/launcher/" class="dropdown-item">Luncher App</a>
</li>
            
<li>
    <a href="../../etc/idea/memo/" class="dropdown-item">Memo App</a>
</li>
    </ul>
  </li>
                                    
  <li class="dropdown-submenu">
    <a href="#" class="dropdown-item">Language</a>
    <ul class="dropdown-menu">
            
  <li class="dropdown-submenu">
    <a href="#" class="dropdown-item">Cpp</a>
    <ul class="dropdown-menu">
            
<li>
    <a href="../../etc/language/cpp/new_cpp/" class="dropdown-item">New c++11 standard</a>
</li>
    </ul>
  </li>
            
  <li class="dropdown-submenu">
    <a href="#" class="dropdown-item">Golang</a>
    <ul class="dropdown-menu">
            
<li>
    <a href="../../etc/language/golang/1_tuto/" class="dropdown-item">1. Package, variables and functions.</a>
</li>
            
<li>
    <a href="../../etc/language/golang/2_for/" class="dropdown-item">2. Flow control statement</a>
</li>
            
<li>
    <a href="../../etc/language/golang/3_types/" class="dropdown-item">More types: structs slices and maps</a>
</li>
            
<li>
    <a href="../../etc/language/golang/4_go_design/" class="dropdown-item">고 디자인</a>
</li>
    </ul>
  </li>
            
  <li class="dropdown-submenu">
    <a href="#" class="dropdown-item">Javascript</a>
    <ul class="dropdown-menu">
            
<li>
    <a href="../../etc/language/javascript/chain/" class="dropdown-item">메서드 체인잉</a>
</li>
    </ul>
  </li>
    </ul>
  </li>
                                    
  <li class="dropdown-submenu">
    <a href="#" class="dropdown-item">Mkdocs</a>
    <ul class="dropdown-menu">
            
<li>
    <a href="../../etc/mkdocs/usage/" class="dropdown-item">HowTo</a>
</li>
    </ul>
  </li>
                                    
  <li class="dropdown-submenu">
    <a href="#" class="dropdown-item">Ml</a>
    <ul class="dropdown-menu">
            
<li>
    <a href="../../etc/ml/MNIST/" class="dropdown-item">MNIST</a>
</li>
            
<li>
    <a href="../../etc/ml/clustering/" class="dropdown-item">목적</a>
</li>
            
<li>
    <a href="../../etc/ml/huber_loss/" class="dropdown-item">Huber loss</a>
</li>
            
<li>
    <a href="../../etc/ml/linear_regression/" class="dropdown-item">Linear regression</a>
</li>
            
<li>
    <a href="../../etc/ml/softmax/" class="dropdown-item">Softmax</a>
</li>
            
<li>
    <a href="../../etc/ml/tensorflow_dataset/" class="dropdown-item">tenserflow data</a>
</li>
    </ul>
  </li>
                                    
  <li class="dropdown-submenu">
    <a href="#" class="dropdown-item">Permutation</a>
    <ul class="dropdown-menu">
            
<li>
    <a href="../../etc/permutation/rule_of_sum_and_product/" class="dropdown-item">사건의 경우의 수</a>
</li>
    </ul>
  </li>
                                    
  <li class="dropdown-submenu">
    <a href="#" class="dropdown-item">Probability</a>
    <ul class="dropdown-menu">
            
<li>
    <a href="../../etc/probability/probability/" class="dropdown-item">확률</a>
</li>
    </ul>
  </li>
                                    
  <li class="dropdown-submenu">
    <a href="#" class="dropdown-item">Seminar</a>
    <ul class="dropdown-menu">
            
<li>
    <a href="../../etc/seminar/learn_to_learn/" class="dropdown-item">How to learn to learn?</a>
</li>
    </ul>
  </li>
                                    
  <li class="dropdown-submenu">
    <a href="#" class="dropdown-item">Simpleai</a>
    <ul class="dropdown-menu">
            
<li>
    <a href="../../etc/simpleai/private/" class="dropdown-item">심플AI 개인정보 처리방침</a>
</li>
            
  <li class="dropdown-submenu">
    <a href="#" class="dropdown-item">Kingofcal</a>
    <ul class="dropdown-menu">
            
<li>
    <a href="../../etc/simpleai/kingofcal/1_intro/" class="dropdown-item">1 intro</a>
</li>
            
<li>
    <a href="../../etc/simpleai/kingofcal/1_intro_raw/" class="dropdown-item">버전3</a>
</li>
    </ul>
  </li>
    </ul>
  </li>
                                    
  <li class="dropdown-submenu">
    <a href="#" class="dropdown-item">Speaking</a>
    <ul class="dropdown-menu">
            
<li>
    <a href="../../etc/speaking/toolbox/" class="dropdown-item">대화의 기술</a>
</li>
    </ul>
  </li>
                                    
  <li class="dropdown-submenu">
    <a href="#" class="dropdown-item">Vi</a>
    <ul class="dropdown-menu">
            
<li>
    <a href="../../etc/vi/etc/" class="dropdown-item">Tips</a>
</li>
            
<li>
    <a href="../../etc/vi/multi_lang/" class="dropdown-item">Multi language</a>
</li>
    </ul>
  </li>
                                </ul>
                            </li>
                            <li class="dropdown">
                                <a href="#" class="nav-link dropdown-toggle" data-toggle="dropdown">Framework <b class="caret"></b></a>
                                <ul class="dropdown-menu">
                                    
  <li class="dropdown-submenu">
    <a href="#" class="dropdown-item">Grpc</a>
    <ul class="dropdown-menu">
            
<li>
    <a href="../../framework/grpc/introduction/" class="dropdown-item">Introduction</a>
</li>
            
<li>
    <a href="../../framework/grpc/protocolbuffer/" class="dropdown-item">Protocol Buffers</a>
</li>
    </ul>
  </li>
                                    
  <li class="dropdown-submenu">
    <a href="#" class="dropdown-item">Http2</a>
    <ul class="dropdown-menu">
            
<li>
    <a href="../../framework/http2/introduction/" class="dropdown-item">Introduction</a>
</li>
    </ul>
  </li>
                                    
  <li class="dropdown-submenu">
    <a href="#" class="dropdown-item">K8s</a>
    <ul class="dropdown-menu">
            
<li>
    <a href="../../framework/k8s/0_introduction/" class="dropdown-item">쿠버네티스</a>
</li>
            
<li>
    <a href="../../framework/k8s/1_container/" class="dropdown-item">Overview</a>
</li>
            
<li>
    <a href="../../framework/k8s/2_k8s/" class="dropdown-item">서비스 소개</a>
</li>
            
<li>
    <a href="../../framework/k8s/3_master_node/" class="dropdown-item">마스터, 노드</a>
</li>
            
<li>
    <a href="../../framework/k8s/4_objects/" class="dropdown-item">k8s 오브젝트들</a>
</li>
            
<li>
    <a href="../../framework/k8s/5_names/" class="dropdown-item">Identifer</a>
</li>
            
<li>
    <a href="../../framework/k8s/6_labels/" class="dropdown-item">레이블 그리고 셀렉터</a>
</li>
            
<li>
    <a href="../../framework/k8s/7_annotation/" class="dropdown-item">어노테이션</a>
</li>
            
<li>
    <a href="../../framework/k8s/8_field_selectors/" class="dropdown-item">필드 셀렉터</a>
</li>
            
<li>
    <a href="../../framework/k8s/9_managements/" class="dropdown-item">k8s 객체 관리</a>
</li>
            
<li>
    <a href="../../framework/k8s/_10_nodes/" class="dropdown-item">Node</a>
</li>
            
<li>
    <a href="../../framework/k8s/_11_master_node_communication/" class="dropdown-item">Master-Node 통신</a>
</li>
    </ul>
  </li>
                                    
  <li class="dropdown-submenu">
    <a href="#" class="dropdown-item">Mobile</a>
    <ul class="dropdown-menu">
            
<li>
    <a href="../../framework/mobile/golssary/" class="dropdown-item">A mobile advertising glossary</a>
</li>
    </ul>
  </li>
                                    
  <li class="dropdown-submenu">
    <a href="#" class="dropdown-item">React</a>
    <ul class="dropdown-menu">
            
<li>
    <a href="../../framework/react/reactive_introduction/" class="dropdown-item">Introduction to Reactive Programming</a>
</li>
            
<li>
    <a href="../../framework/react/reactive_stream_introduction/" class="dropdown-item">Reactive streams</a>
</li>
    </ul>
  </li>
                                    
  <li class="dropdown-submenu">
    <a href="#" class="dropdown-item">Spring</a>
    <ul class="dropdown-menu">
            
<li>
    <a href="../../framework/spring/spring_overview/" class="dropdown-item">Spring Overview.</a>
</li>
            
<li>
    <a href="../../framework/spring/spring_overview2/" class="dropdown-item">Spring Overview 2</a>
</li>
            
<li>
    <a href="../../framework/spring/spring_webflux/" class="dropdown-item">Spring WebFlux.</a>
</li>
    </ul>
  </li>
                                    
  <li class="dropdown-submenu">
    <a href="#" class="dropdown-item">Unity</a>
    <ul class="dropdown-menu">
            
<li>
    <a href="../../framework/unity/key/" class="dropdown-item">Short Cut</a>
</li>
            
  <li class="dropdown-submenu">
    <a href="#" class="dropdown-item">Script</a>
    <ul class="dropdown-menu">
            
<li>
    <a href="../../framework/unity/script/built_in_serialization/" class="dropdown-item">Build-in seriallization</a>
</li>
            
<li>
    <a href="../../framework/unity/script/script_serialization/" class="dropdown-item">Script Serialization</a>
</li>
    </ul>
  </li>
    </ul>
  </li>
                                </ul>
                            </li>
                            <li class="dropdown">
                                <a href="#" class="nav-link dropdown-toggle" data-toggle="dropdown">K8s <b class="caret"></b></a>
                                <ul class="dropdown-menu">
                                    
<li>
    <a href="../../k8s/0_introduction/" class="dropdown-item">쿠버네티스</a>
</li>
                                    
<li>
    <a href="../../k8s/1_container/" class="dropdown-item">Overview</a>
</li>
                                    
<li>
    <a href="../../k8s/2_k8s/" class="dropdown-item">서비스 소개</a>
</li>
                                    
<li>
    <a href="../../k8s/3_master_node/" class="dropdown-item">마스터, 노드</a>
</li>
                                    
<li>
    <a href="../../k8s/4_objects/" class="dropdown-item">k8s 오브젝트들</a>
</li>
                                    
<li>
    <a href="../../k8s/5_names/" class="dropdown-item">Identifer</a>
</li>
                                    
<li>
    <a href="../../k8s/6_labels/" class="dropdown-item">레이블 그리고 셀렉터</a>
</li>
                                    
<li>
    <a href="../../k8s/7_annotation/" class="dropdown-item">어노테이션</a>
</li>
                                    
<li>
    <a href="../../k8s/8_field_selectors/" class="dropdown-item">필드 셀렉터</a>
</li>
                                    
<li>
    <a href="../../k8s/90_managements/" class="dropdown-item">k8s 객체 관리</a>
</li>
                                    
<li>
    <a href="../../k8s/91_master_node_communication/" class="dropdown-item">Master-Node 통신</a>
</li>
                                    
<li>
    <a href="../../k8s/92_nodes/" class="dropdown-item">Node</a>
</li>
                                </ul>
                            </li>
                            <li class="dropdown">
                                <a href="#" class="nav-link dropdown-toggle" data-toggle="dropdown">Rl <b class="caret"></b></a>
                                <ul class="dropdown-menu">
                                    
  <li class="dropdown-submenu">
    <a href="#" class="dropdown-item">Deep</a>
    <ul class="dropdown-menu">
            
<li>
    <a href="../../rl/deep/4_rl_introduction/" class="dropdown-item">1. Introduction to Reinforcement Learning</a>
</li>
            
<li>
    <a href="../../rl/deep/5_rl_exploration/" class="dropdown-item">2. Exploration and Exploitatin</a>
</li>
    </ul>
  </li>
                                    
  <li class="dropdown-submenu">
    <a href="#" class="dropdown-item">Intro</a>
    <ul class="dropdown-menu">
            
<li>
    <a href="../../rl/intro/4_dp/" class="dropdown-item">Iterative policy Evaluation, for estimating $V \approx v_{\pi}$</a>
</li>
    </ul>
  </li>
                                </ul>
                            </li>
                            <li class="dropdown">
                                <a href="#" class="nav-link dropdown-toggle" data-toggle="dropdown">Unix <b class="caret"></b></a>
                                <ul class="dropdown-menu">
                                    
<li>
    <a href="../../unix/regex/" class="dropdown-item">정규 표현식</a>
</li>
                                    
<li>
    <a href="../../unix/sed/" class="dropdown-item">Sed</a>
</li>
                                    
<li>
    <a href="../../unix/shell_1/" class="dropdown-item">1. 쉘 정의</a>
</li>
                                    
<li>
    <a href="../../unix/shell_2/" class="dropdown-item">2. 쉘의 변수</a>
</li>
                                    
<li>
    <a href="../../unix/shell_3/" class="dropdown-item">3. 쉘의 옵션</a>
</li>
                                    
<li>
    <a href="../../unix/shell_4/" class="dropdown-item">4. 쉘 문법</a>
</li>
                                </ul>
                            </li>
                        </ul>

                    <ul class="nav navbar-nav ml-auto">
                        <li class="nav-item">
                            <a href="#" class="nav-link" data-toggle="modal" data-target="#mkdocs_search_modal">
                                <i class="fa fa-search"></i> Search
                            </a>
                        </li>
                            <li class="nav-item">
                                <a rel="prev" href="../3_dl_1_mnist/" class="nav-link">
                                    <i class="fa fa-arrow-left"></i> Previous
                                </a>
                            </li>
                            <li class="nav-item">
                                <a rel="next" href="../4_dl_beyond_image/" class="nav-link">
                                    Next <i class="fa fa-arrow-right"></i>
                                </a>
                            </li>
                    </ul>
                </div>
            </div>
        </div>

        <div class="container">
            <div class="row">
                    <div class="col-md-3"><div class="navbar-light navbar-expand-md bs-sidebar hidden-print affix" role="complementary">
    <div class="navbar-header">
        <button type="button" class="navbar-toggler collapsed" data-toggle="collapse" data-target="#toc-collapse" title="Table of Contents">
            <span class="fa fa-angle-down"></span>
        </button>
    </div>

    
    <div id="toc-collapse" class="navbar-collapse collapse card bg-secondary">
        <ul class="nav flex-column">
            
            <li class="nav-item" data-level="1"><a href="#3-neural-networks-foundations" class="nav-link">3. Neural Networks Foundations</a>
              <ul class="nav flex-column">
              </ul>
            </li>
            
            <li class="nav-item" data-level="1"><a href="#overview" class="nav-link">Overview.</a>
              <ul class="nav flex-column">
              </ul>
            </li>
            
            <li class="nav-item" data-level="1"><a href="#single-layer-networks" class="nav-link">Single layer networks</a>
              <ul class="nav flex-column">
            <li class="nav-item" data-level="2"><a href="#linear-layer" class="nav-link">Linear layer</a>
              <ul class="nav flex-column">
              </ul>
            </li>
            <li class="nav-item" data-level="2"><a href="#sigmoid-layer" class="nav-link">Sigmoid layer</a>
              <ul class="nav flex-column">
              </ul>
            </li>
            <li class="nav-item" data-level="2"><a href="#_3" class="nav-link">인공 뉴론</a>
              <ul class="nav flex-column">
              </ul>
            </li>
            <li class="nav-item" data-level="2"><a href="#softmax-layer" class="nav-link">Softmax layer</a>
              <ul class="nav flex-column">
              </ul>
            </li>
            <li class="nav-item" data-level="2"><a href="#softmax-and-cross-entropy-nll-loss" class="nav-link">Softmax and cross-entropy / NLL loss</a>
              <ul class="nav flex-column">
              </ul>
            </li>
            <li class="nav-item" data-level="2"><a href="#rectified-linear-layer" class="nav-link">Rectified-linear layer</a>
              <ul class="nav flex-column">
              </ul>
            </li>
              </ul>
            </li>
            
            <li class="nav-item" data-level="1"><a href="#networks-with-one-hidden-layer" class="nav-link">Networks with one hidden layer</a>
              <ul class="nav flex-column">
            <li class="nav-item" data-level="2"><a href="#hidden-layers" class="nav-link">Hidden Layers</a>
              <ul class="nav flex-column">
              </ul>
            </li>
              </ul>
            </li>
            
            <li class="nav-item" data-level="1"><a href="#modern-deep-net" class="nav-link">Modern deep net</a>
              <ul class="nav flex-column">
            <li class="nav-item" data-level="2"><a href="#_6" class="nav-link">네트워크의 깊이가 끼치는 좋은 영향</a>
              <ul class="nav flex-column">
              </ul>
            </li>
            <li class="nav-item" data-level="2"><a href="#nn" class="nav-link">NN을 표현 하는 여러가지 방식</a>
              <ul class="nav flex-column">
              </ul>
            </li>
              </ul>
            </li>
            
            <li class="nav-item" data-level="1"><a href="#learning" class="nav-link">Learning</a>
              <ul class="nav flex-column">
            <li class="nav-item" data-level="2"><a href="#linear-algebra-recap-notation" class="nav-link">Linear algebra recap / notation</a>
              <ul class="nav flex-column">
              </ul>
            </li>
            <li class="nav-item" data-level="2"><a href="#_7" class="nav-link">경사 하강법을 사용한 최적화</a>
              <ul class="nav flex-column">
              </ul>
            </li>
            <li class="nav-item" data-level="2"><a href="#chain-rule-backprop-and-automatic-differentiation" class="nav-link">Chain rule, backprop and automatic differentiation</a>
              <ul class="nav flex-column">
              </ul>
            </li>
            <li class="nav-item" data-level="2"><a href="#modular-backprop-with-vector-inputoutputs" class="nav-link">Modular backprop with vector input/outputs</a>
              <ul class="nav flex-column">
              </ul>
            </li>
            <li class="nav-item" data-level="2"><a href="#_9" class="nav-link">모듈화</a>
              <ul class="nav flex-column">
              </ul>
            </li>
              </ul>
            </li>
            
            <li class="nav-item" data-level="1"><a href="#module-zoo" class="nav-link">Module Zoo</a>
              <ul class="nav flex-column">
            <li class="nav-item" data-level="2"><a href="#elementwise-ops" class="nav-link">Elementwise ops</a>
              <ul class="nav flex-column">
              </ul>
            </li>
            <li class="nav-item" data-level="2"><a href="#groupwise-ops" class="nav-link">Groupwise ops</a>
              <ul class="nav flex-column">
              </ul>
            </li>
            <li class="nav-item" data-level="2"><a href="#loss-ops" class="nav-link">Loss ops</a>
              <ul class="nav flex-column">
              </ul>
            </li>
            <li class="nav-item" data-level="2"><a href="#activation-functions" class="nav-link">Activation functions</a>
              <ul class="nav flex-column">
              </ul>
            </li>
              </ul>
            </li>
            
            <li class="nav-item" data-level="1"><a href="#practical-tips" class="nav-link">Practical tips</a>
              <ul class="nav flex-column">
            <li class="nav-item" data-level="2"><a href="#overfitting-regularization_1" class="nav-link">Overfitting &amp; regularization</a>
              <ul class="nav flex-column">
              </ul>
            </li>
            <li class="nav-item" data-level="2"><a href="#the-importance-of-good-initialization" class="nav-link">The importance of good initialization</a>
              <ul class="nav flex-column">
              </ul>
            </li>
            <li class="nav-item" data-level="2"><a href="#hyperparameter-search" class="nav-link">Hyperparameter search</a>
              <ul class="nav flex-column">
              </ul>
            </li>
            <li class="nav-item" data-level="2"><a href="#simple-debugging-and-performance-diagnostics" class="nav-link">Simple debugging and performance diagnostics</a>
              <ul class="nav flex-column">
              </ul>
            </li>
              </ul>
            </li>
            
            <li class="nav-item" data-level="1"><a href="#reference" class="nav-link">Reference</a>
              <ul class="nav flex-column">
              </ul>
            </li>
        </ul>
    </div>
</div></div>
                    <div class="col-md-9" role="main">

<h1 id="3-neural-networks-foundations">3. Neural Networks Foundations</h1>
<h1 id="overview">Overview.</h1>
<p><img alt="overview" src="../img/3_nn_overview.svg" /></p>
<p>NN 은 선형 변환들과 + 비 선형 함수들의 조합 이다.
- NN의 장점과 유연함은 위의 간단한 모듈들을 대규모로 구성하여 사용 함에 있다.
- 학습이란? 
    - loss function 을 데이터에 맞게 최적화 시키는걸 의미한다.
    - 보통 미분의 연쇄 법칙 그리고 SGD 를 사용해 최적화 한다. </p>
<h3 id="_1">사용처</h3>
<ul>
<li>컴퓨터 비전</li>
<li>음성인식, 기계번역</li>
<li>text to speech</li>
<li>RL (DQN/A3C)</li>
<li>자율주행차 </li>
<li>등.</li>
</ul>
<p><img alt="nn" src="../img/3_nn_equation.svg" /></p>
<p>우리가 만들려고 하는 nn 은 위의 식으로 표현 할 수 있다.</p>
<h3 id="road-map">Road map</h3>
<ul>
<li>Single layer networks</li>
<li>Networks with one hidden layer</li>
<li>Modern deep nets<ul>
<li>nn 을 컴퓨터 그래프 표현으로.</li>
</ul>
</li>
<li>Learing<ul>
<li>Chain rule</li>
<li>Modualr backprop &amp; automatic differentiation</li>
</ul>
</li>
<li>Module zoo: layers and losses</li>
<li>현업에서 사용하는 팁</li>
</ul>
<h3 id="_2">명칭관련 주의</h3>
<ul>
<li>neuron == unit</li>
<li>비선형 == activation function</li>
<li>(선형 변환 + 비 선형) 을 합쳐서 layer 라고 부른다.</li>
<li>소프트웨어에서는 atomic ops 를 layer 라고 부른다.</li>
</ul>
<h1 id="single-layer-networks">Single layer networks</h1>
<ul>
<li>Linear layer</li>
<li>Sigmoid activiation function layer</li>
<li>Binary classification / logistic regression 리뷰</li>
<li>Multi-way descisions: softmax layer</li>
<li>Rectified(put currect) linear layers (relu)</li>
</ul>
<h2 id="linear-layer">Linear layer</h2>
<p>동의어"fully connecnted" 또는 "dense" layers</p>
<p><img alt="neuron" src="../img/neuron.png" title="opt title" /></p>
<p>인간의 뇌를 구성하고 있는 신경 세포를 보면 수상돌기를 통해
여러개의 인풋을 받아 축삭말단을 통해 여러개의 아웃풋을 생성한다.
- 위의 현상을 모델링 해보자.</p>
<h3 id="input-ouptput">input ouptput 정의</h3>
<p>2개의 인풋을 받아 하나의 아웃풋을 생성한다.</p>
<p><img alt="1" src="../img/3_nn_liner_1.svg" title="opt title" /></p>
<p>우리는 $x_{1}$과 $x_{2}$ 를 받아. $y_{1}$ 을 만들려고 한다.
우리는 아래와 같이 정의 할 것 이다.</p>
<p><img alt="2" src="../img/3_nn_liner_2.svg" title="opt title" /></p>
<p>아웃풋 하나에 대해 아래와 같이 정의 하자.
$$
f: R^{n} \to R \\
y = \sum_{i}^{n}w_{i}x_{i} + b
$$</p>
<p>그렇다면 신경 세포는 아래와 같이 행렬과 벡터의 내적으로 정의 할 수 있다.
$$
f: R^{n} \to R^{m} \\
y = Wx + b
$$</p>
<h2 id="sigmoid-layer">Sigmoid layer</h2>
<p>Activation function 중 하나.
$f: R \to R$ 함수 이며 $-\infty \leq x \leq +\infty$ 를 input  으로 받아 $0 \leq y \leq 1$ 의 값을 리턴한다.
$$\sigma = \frac{1}{1 + e^{-x}}$$</p>
<p><img alt="sigmoid" src="../img/3_sigmoid.svg" /></p>
<p>선형 변환이 아니기 때문에 비선형 함수라고 한다.</p>
<h2 id="_3">인공 뉴론</h2>
<p>이제 위의 linear layer 와 activation layer(sigmoid) 를 합치면 인공 뉴론이 된다.
- 지금은 한개의 x vector 에 대해 feed forwarding 하는 부분만 고려하기 때문에 x, y 는 1차원 벡터이다.</p>
<p><img alt="3" src="../img/3_nn_liner_3.svg" title="opt title" /></p>
<p>$$
y = \sigma \left( \sum_{i}w_{i}x_{i}+b\right) \\
y = \sigma (Wx + B)
$$</p>
<p>input X 를 받아 output Y 로 변형(transformation)하는 함수(인공 뉴론) 은 아래 그림에서 $\to$ 로 표현되었다.
아래 그림은 1단 레이어를 도식화 한 것이다.</p>
<p><img alt="single" src="../img/single_layer.svg" title="opt title" /></p>
<ul>
<li>위의 뉴론을 구현하고 W 값을 구하면 우리는 binary classification을 할 수 있다.</li>
<li>아래는 $x_{1}, x_{2}$ 로 구성된 점들을 주고 훈련을 시킨다. 그러면 이후 새로운 $x_{1}, x_{2}$ 을 주면 답을 예측 할 수 있다.</li>
</ul>
<pre><code>X = [(-1, -4),...,(4, 4)] //training data 그림에서는 X[i][0] 을 x 축 값, X[i][1] 을 y 축 값 으로 사용해서 표기
y = [(yellow),...,(blue)] // X 에 대응하는 label
model = train(X, y)  // w를 구함 아래에서 설명함.
model.predict((5, 5)) // 구해진 w에 위에 정의한 인공 뉴론을 사용해 답을 예측. blue
</code></pre>

<p><img alt="binary" src="../img/binary.png" title="opt title" /></p>
<p><a href="http://playground.tensorflow.org/#activation=sigmoid&amp;batchSize=10&amp;dataset=gauss&amp;regDataset=reg-plane&amp;learningRate=0.03&amp;regularizationRate=0&amp;noise=10&amp;networkShape=1,1&amp;seed=0.43716&amp;showTestData=false&amp;discretize=false&amp;percTrainData=50&amp;x=true&amp;y=true&amp;xTimesY=false&amp;xSquared=false&amp;ySquared=false&amp;cosX=false&amp;sinX=false&amp;cosY=false&amp;sinY=false&amp;collectStats=false&amp;problem=classification&amp;initZero=false&amp;hideText=false">Playground.tensorflow</a></p>
<h2 id="softmax-layer">Softmax layer</h2>
<p>Multi-classs classificaion 에서 유용함.
$$
y = \text{softmax}(x), \text{where: } y_{i} = \frac{e^{x_{i}}}{\sum_{j=1}^{K}e^{x_{j}}}
\tag{3.1}
$$</p>
<h3 id="argmax">argmax 함수</h3>
<ul>
<li>input array 을 주면 input 과 같은 크기의 array 를 리턴</li>
<li>y 값은 x 값 중 가장 큰 값만 1, 나머지는 0 으로 돌려줌</li>
<li>모든 y 값을 합하면 1</li>
</ul>
<pre><code>y = argmax([1, 1, 8])
// y = [0, 0, 1]
sum(y) // 1
</code></pre>

<h3 id="softmax">softmax</h3>
<ul>
<li>soft argmax 함수라고 생각해도 됨.</li>
<li>input array 을 주면 input 과 같은 크기의 array 를 리턴</li>
<li>y 값은 x 값 중  가장 큰 값은 1에 가깝게 , 나머지는 0 에 가깝게 돌려줌</li>
<li>모든 y 값을 합하면 1</li>
<li>합하면 1이 되기 때문에 확률로 생각 할 수 있음</li>
</ul>
<pre><code>y = softmax([1, 1, 8])
// 대략 y = [0.001, 0.001, 0.998] 
// 실제 y = [9.10221936e-04, 9.10221936e-04, 9.98179556e-01]
sum(y) // 1
</code></pre>

<h2 id="softmax-and-cross-entropy-nll-loss">Softmax and cross-entropy / NLL loss</h2>
<h3 id="_4">예측</h3>
<ul>
<li>
<p>우리는 Linear layer + softmax 을 합치면multinomial logistic regression 또는 multi-class classification 이 가능해진다.
$$
y_{i} = \frac{e^{\sum_{j}w_{ij}x_{j} + b_{i}}}{\sum_{k=1}^{K}e^{\sum_{j}w_{kj}x_{j} + b_{k}}}
$$
위의 식을 사용해 nn을 구성 할 수 있다.</p>
</li>
<li>
<p>MNIST 데이터에 적용한다고 생각해보자.</p>
<ul>
<li>input: 0~9 까지의 손글씨 사진.</li>
<li>output: 0~9 까지의 손글씨 사진이 나타내는 숫자.</li>
</ul>
</li>
</ul>
<pre><code>//예제를 간단하게 하기 위해 0~2번까지의 숫자로 구성된 사진만 있다고 해보자.
X = [(raw values represent 2),...,(raw values represent 1)] //training data 
y = [(0,0,1),...,(0,1,0)] // X 에 대응하는 label
model = train(X, y)  // w를 구함 아래에서 설명함.
model.predict((raw values represent 0)) // (1, 0, 0) 을 해석하면 0 임을 알 수 있음.
</code></pre>

<h3 id="_5">학습</h3>
<ul>
<li>loss function 으로 negative log likelihood(NLL) / cross-entropy of true labels 을 사용 한다.
$$
 NLL(t, y) = Xent(t, y) = - \sum_{t}^{classes:C} t_{i}\text{log }y_{i}
$$</li>
</ul>
<h2 id="rectified-linear-layer">Rectified-linear layer</h2>
<p>최소 0, 아니면 $x_{i}$
$$
y = relu(x) \text{, where:} y_{i} = \text{maximum}(0, x_{i})
$$
<img alt="relu" src="../img/3_relu.svg" /></p>
<h1 id="networks-with-one-hidden-layer">Networks with one hidden layer</h1>
<ul>
<li>인풋을 선형으로 분리 불가능 할때 사용.</li>
<li>Hindden layer nets 은 "universal function approximators" 라고 도 함.</li>
<li>hidden layer == linear + non-linearity == separte layers == modules</li>
</ul>
<h2 id="hidden-layers">Hidden Layers</h2>
<ul>
<li>Single hidden layer (linear + non-linear)</li>
</ul>
<p><img alt="hidden" src="../img/hidden_layer.svg" title="opt title" /></p>
<ul>
<li>Hidden.h 첫번째 선형 변환 식의 아웃풋이다.</li>
<li>아웃풋이 다른 레이어의 인풋이 된다.</li>
<li>위와 같이 구성하면 인풋을 다른 방식으로 표현 할 수 있다.<ul>
<li>우리의 문제가 선형 변환을 통해 생성된 중간 표현형 에서는 심플 해지길 기대 할 수 있다.</li>
<li>문제를 주어진 인풋에서 바로 푸는게 아니라 연속적인 변형을 통해서 문제가 쉬워지길 기대 할 수 있다.</li>
<li>예를 들어 input 에서는 선형 불리가 불가능하지만 중간 표현형에서는 선형 분리가 가능 하게 변환</li>
</ul>
</li>
</ul>
<h3 id="example">Example</h3>
<p>아래와 같은 인풋 표현을 선형 변환을 통해 히든 레이어에서 다른 표현으로 바꿀수 있다.</p>
<ul>
<li>인풋 표현형 에서는 선형으로 구분이 불가능</li>
<li>한번의 선형 변환 후 히든레이어의 결과 값에서는 선형 구분이 가능한 표현 형으로 변경됨</li>
<li>중간 표현형에 선형식을 만들어 클래스 구분</li>
</ul>
<table>
<thead>
<tr>
<th align="left">Point</th>
<th align="left">Input space</th>
<th align="left">Hidden space</th>
<th align="left">class</th>
</tr>
</thead>
<tbody>
<tr>
<td align="left">A</td>
<td align="left">(1, 1)</td>
<td align="left">(1, 0)</td>
<td align="left">0</td>
</tr>
<tr>
<td align="left">B</td>
<td align="left">(-1, -1)</td>
<td align="left">(1, 0)</td>
<td align="left">0</td>
</tr>
<tr>
<td align="left">C</td>
<td align="left">(-1, 1)</td>
<td align="left">(0, 0)</td>
<td align="left">1</td>
</tr>
<tr>
<td align="left">D</td>
<td align="left">(1, -1)</td>
<td align="left">(1, 1)</td>
<td align="left">1</td>
</tr>
</tbody>
</table>
<p><img alt="hidden" src="../img/hidden_intutiion.svg" title="opt title" /></p>
<h1 id="modern-deep-net">Modern deep net</h1>
<ul>
<li>한개의 히든 레이어를 사용해서 히든유닛이 많다면 우리는 universal function approximation 을 할 수 있다.</li>
<li>네트워크가 깊어 지면 더 강력해지고 효율적이 된다.</li>
<li>복잡합 함수 맵핑을 여러개의 작은 재표현된 단계로 분리 할 수 있다.<ul>
<li>edges -&gt; junctions -&gt; parts -&gt; objects -&gt; scences</li>
</ul>
</li>
</ul>
<h2 id="_6">네트워크의 깊이가 끼치는 좋은 영향</h2>
<p><a href="https://arxiv.org/pdf/1402.1869.pdf">why adding depth helps doc</a></p>
<ul>
<li>여러개의 인풋이 같은 아웃풋에 맵핑된다. </li>
<li>그렇다면 함수를 재활용 할 수 있을것이다.</li>
<li>넓이가 아니라 깊이를 깊게 한다면 그런 함수들을 많이 재활용 할 수 있을 것이다.</li>
</ul>
<p><a href="https://arxiv.org/pdf/1602.07261.pdf">Inception-v4</a></p>
<p>$$
f(|x|) = f(|-x|) \\
f(|x|,|y|) = f(|-x|,|y|) = f(|x|,|-y|) = f(|-x|,|-y|) 
$$</p>
<h2 id="nn">NN을 표현 하는 여러가지 방식</h2>
<p>아래의 식을 여러가지로 표현 할 수 있다.
$$
\begin{align}
    h^{(1)} &amp; = \sigma(W^{(1)}x) \\
    h^{(2)} &amp; = \text{relu}(W^{(2)}x) \\
    h^{(3)} &amp; = \sigma(W^{(3)}h^{(1)}) \\
    y &amp; = (W^{(4)}h^{(3)} + W^{(5)}h^{(2)})
\end{align}
$$</p>
<p><img alt="nn_representaion" src="../img/nn_representations.svg" title="opt title" /></p>
<p>위의 그래프 방식으로 NN을 표현 하게 되면 </p>
<ul>
<li>각각을 모듈로 생각하고 레고 처럼 필요한곳에 끼어 넣으면 된다.</li>
<li>OOP 로 접근해서 추상화 할 수 있다.<ul>
<li>foward_pass() # predict</li>
<li>backward_pass() # learning</li>
<li>compute_gradients() # update parameter</li>
</ul>
</li>
<li>새로운 모듈을 추가 하기 쉽다.</li>
</ul>
<h1 id="learning">Learning</h1>
<ul>
<li>우리의 데이터와 모델 파라미터에 따라 로스 펑션을 정의하고 <ul>
<li>해당 로스 함수를 최적화 방법론을 사용하여 loss 를 최소화 하는것.</li>
</ul>
</li>
</ul>
<h2 id="linear-algebra-recap-notation">Linear algebra recap / notation</h2>
<ul>
<li>Gradient vector<ul>
<li>Entries -&gt; 특정 scalar function 에 대한 vector arguments들의 편미분 값들.</li>
<li>한개의 y 값에 대한 x 백터의 편미분 값들</li>
</ul>
</li>
</ul>
<p>$$
y = f(\mathbb{x}) \\
\mathit{f} : \mathbb{R}^{m} \to \mathbb{R} \\
\frac{\partial y}{\partial \mathbb{x}} = \nabla^{(x)}y = \left[ \frac{\partial y}{\partial x_{1}},...,\frac{\partial y}{\partial x_{m}} \right]
$$</p>
<ul>
<li>Jacobian matrix<ul>
<li>Entries -&gt; vector function 에 대한 vector arguments 의 편미분 값들.</li>
<li>y 벡터 값에 대한 x 백터의 편미분 값.</li>
<li>Multi classificaion 일 때.
$$
\mathtt{y} = \mathit{f}(\mathbb{x}) \\
f = \mathbb{R}^{m} \to \mathbb{R}^{n} \\
\frac{\partial \mathbb{y}}{\partial \mathbb{x}} = \pmb{J}^{(x)}\mathbb{(y)} = 
\begin{bmatrix}
\frac{\partial y_{1}}{\partial x_{1}} &amp; \cdots &amp; \frac{\partial y_{1}}{\partial x_{m}} \\
\vdots                                &amp; \ddots &amp; \vdots                                \\
\frac{\partial y_{n}}{\partial x_{1}} &amp; \cdots &amp; \frac{\partial y_{n}}{\partial x_{m}}  \\
\end{bmatrix}
$$</li>
</ul>
</li>
</ul>
<h2 id="_7">경사 하강법을 사용한 최적화</h2>
<ul>
<li>한개의 데이터 경사 하강법<ul>
<li>online gradient descent</li>
</ul>
</li>
</ul>
<p>$$
\theta \leftarrow \theta - \eta \nabla^{(\theta)} \mathit{L} ( \theta, \mathbb{x}, y )
$$</p>
<ul>
<li>여러개의 데이터를 사용한 경사 하강법<ul>
<li>Full/mini batch gradient descent</li>
</ul>
</li>
</ul>
<p>$$
\theta \leftarrow \theta - \eta \nabla^{(\theta)} \mathit{L} \left( \theta, \left\{ \mathbb{x}^{(i)}, y^{(i)} \right\}_{i=1}^{m} \right)
$$</p>
<h2 id="chain-rule-backprop-and-automatic-differentiation">Chain rule, backprop and automatic differentiation</h2>
<ul>
<li>
<p>연쇄 법칙을 사용한 간단한 미분</p>
<ul>
<li>x 가 변하면 g가 조금 변한다. g 가 조금 변하면 f 가 조금 변한다.
$$
y = f(g(x));  \\
\frac{\mathbf{d} y}{\mathbf{d} x} = 
\frac{\mathbf{d} f}{\mathbf{d} g}
\frac{\mathbf{d} g}{\mathbf{d} x}
$$</li>
</ul>
</li>
<li>
<p>Multivariate: 편미분</p>
<ul>
<li>y 의 변화량은 각각의 함수의 변화량을 더한 것과 같다.</li>
<li>각각의 함수를 미분 할 때 다른 함수들은 상수 취급 한다.
$$
y = f(g^{(1)}(x),...,g^{(m)}(x));  \\
\frac{\partial y}{\partial x} = 
\sum_{i=1}^{i=m}
\frac{\partial f}{\partial g^{(i)}}
\frac{\partial g^{(i)}}{\partial x}
$$</li>
</ul>
</li>
<li>
<p>Computer graph</p>
<ul>
<li>각각의 path는  따라가며 미분하고, 가능한 모든 path 를 더한다.</li>
<li>Traverse from Input $\to$ Output == forward moard AD</li>
<li>Traverse from Output $\to$ Input == reverse mode AD == backprop</li>
</ul>
</li>
<li>텐서 플로우가 자동으로 분기문, 반복문들을 맞게 미분해준다.</li>
</ul>
<h3 id="_8">예제</h3>
<ul>
<li>y 가 이런 수식일때 </li>
</ul>
<p>$$
y = g(
e(d(c(b(a(x))))),
f(j(i(h(x))))
$$</p>
<ul>
<li>그래프 표현</li>
</ul>
<p><img alt="graph_backprop" src="../img/3_graph_backprop.svg" title="opt title" /></p>
<ul>
<li>아래는 y 에서 부터 그래프를 따라 올라 오면 완성되는 backprop 식</li>
</ul>
<p>$$
\frac{\partial y}{\partial x} = 
\frac{\partial h}{\partial x}
\frac{\partial i}{\partial h}
\frac{\partial j}{\partial i}
\frac{\partial f}{\partial j}
\frac{\partial g}{\partial f}
\frac{\partial y}{\partial g} +
\frac{\partial a}{\partial x}
\frac{\partial b}{\partial a}
\frac{\partial c}{\partial b}
\frac{\partial d}{\partial c}
\frac{\partial e}{\partial d}
\frac{\partial f}{\partial e}
\frac{\partial g}{\partial f}
\frac{\partial y}{\partial g}
$$</p>
<h3 id="forward-mode-adautomatic-differentiation">Forward mode AD(automatic differentiation)</h3>
<ul>
<li>Traverse graph from each input to output.<br />
$
\frac{\partial a}{\partial x}, 
\frac{\partial b}{\partial x}, 
..., 
\frac{\partial y}{\partial x}
$</li>
<li>각각의 노드들을 input 으로 미분한값</li>
<li>거의 안씀, x 값이 결과에 얼마나 영향을 주는지 정도.</li>
</ul>
<h3 id="backword-mode-ad">Backword mode AD</h3>
<ul>
<li>Traverse graph from ouptut to input</li>
<li>ouput 을 각각의 노드들로 미분한값<br />
$
\frac{\partial y}{\partial g}, 
\frac{\partial y}{\partial f}, 
..., 
\frac{\partial y}{\partial x}
$</li>
<li>학습에 사용. </li>
</ul>
<h2 id="modular-backprop-with-vector-inputoutputs">Modular backprop with vector input/outputs</h2>
<h3 id="forward-pass">Forward-pass</h3>
<p>$ \mathbb{y} = f (\mathbb{x}) $
$$
\text{Input : } \mathbb{y} \\
\text{Output : } \mathbb{x} \\
\mathbb{y} = f (\mathbb{x}) 
$$</p>
<pre><code class="python">def forward_pass(x):
 # input 을 계산해서 ouptput 리턴
 return y
</code></pre>

<h3 id="backward-pass">Backward-pass</h3>
<p>$$
\text{Input : } \frac{ \partial L }{ \partial \mathbb{y}} \\
\text{Output : } \frac{ \partial L }{ \partial \mathbb{x} } \\
\frac{ \partial L }{ \partial x_{i}}  = \sum_{j=1}^{J} \frac{ \partial L }{ \partial y_{j}} \frac{ \partial y_{j} }{ \partial x_{i}} \\
\frac{ \partial L }{ \partial \mathbb{x}}  = \frac{ \partial L }{ \partial \mathbb{y}} ( J^{\mathbb{(x)}} \mathbb{(y)})
$$</p>
<pre><code class="python">def backward_pass(dL_dy):
    # 로스 함수를 아웃풋 값으로 미분한 값을 받아.
    # 로스 함수를 인풋값 으로 미분한 값을 리턴.
    return dL_dx
</code></pre>

<h3 id="parameter-gradients">Parameter gradients</h3>
<p>$$
\text{Input : } \frac{ \partial L }{ \partial \mathbb{y}} \\
\text{Output : } \frac{ \partial L }{ \partial \theta } \\
\frac{ \partial L }{ \partial \theta_{i}}  = \sum_{j=1}^{J} \frac{ \partial L }{ \partial y_{j}} \frac{ \partial y_{j} }{ \partial \theta_{i}} \\
\frac{ \partial L }{ \partial \theta }  = \frac{ \partial L }{ \partial \mathbb{y}} ( J^{(\theta)} \mathbb{(y)})
$$</p>
<pre><code class="python">def parameter_gradients(dL_dy):
    # 로스 함수를 아웃풋 값으로 미분한 값을 받아.
    # 로스 함수를 세타값 으로 미분한 값을 리턴.
    return dl_dtheta
</code></pre>

<h2 id="_9">모듈화</h2>
<p>각각의 모듈들이 아래의 3개 인터페이스를 구현하면 연결(chaining) 하여 계산 할 수 있다.</p>
<pre><code>class module:
    interface forward_pass(x)
    interface backward_pass(dL_dy)
    interface parameter_gradients(dL_dy)
</code></pre>

<p><img alt="module interface" src="../img/3_module_interface.svg" title="opt title" /></p>
<ul>
<li>x-ent: cross-entorpy</li>
<li>학습이란 아래 3개의 API를 반복 호출 하면된다.<ul>
<li>각 모듈들의 forward_pass 를 연결해서 작동시키고</li>
<li>각 모듈들의 backward_pass 를 작동 시키고.</li>
<li>각 모듈들의parameter_gradients 를 작동시키면 학습이 된다.</li>
</ul>
</li>
</ul>
<h3 id="linear-module">Linear module</h3>
<ul>
<li>forward_pass</li>
</ul>
<p>$$
y = Wx + b \\
y_{n} = \sum_{m} W_{nm} x_{m} + b_{n}
$$</p>
<ul>
<li>jacobian elements<ul>
<li>x 미분</li>
<li>b 미분</li>
<li>$\theta$ 미분</li>
</ul>
</li>
</ul>
<p>$$
\frac{ \partial y_{i} }{ \partial x_{j}} = W_{ij} \\
\frac{ \partial y_{i} }{ \partial b_{j}} = \delta_{ij} \\
\frac{ \partial y_{i} }{ \partial W_{jk}} = x_{k} \delta_{ij} \\
$$</p>
<ul>
<li>
<p>backward_pass
$$
\frac{ \partial L }{ \partial \mathbb{x}}  = \frac{ \partial L }{ \partial \mathbb{y}} W \\
\frac{ \partial L }{ \partial x_{j}}  = 
\sum_{i} \frac{ \partial L }{ \partial y_{i}} \frac{ \partial y_{i} }{ \partial x_{j}} =
\sum_{i} \frac{ \partial L }{ \partial y_{i}} W_{ij}
$$</p>
</li>
<li>
<p>param_gradients - $W$
$$
\frac{ \partial L }{ \partial W}  = \left( \frac{ \partial L }{ \partial \mathbb{y}} \right)^{T} \mathbb{x}^{T} \\
\frac{ \partial L }{ \partial W_{jk}}  = 
\sum_{i} \frac{ \partial L }{ \partial y_{i}} \frac{ \partial y_{i} }{ \partial W_{jk}} =
\sum_{i} \frac{ \partial L }{ \partial y_{i}} x_{k} \delta_{ij}  =
\frac{ \partial L }{ \partial y_{j}} x_{k}
$$</p>
</li>
<li>
<p>param_gradients - $\mathbb{b}$
$$
\frac{ \partial L }{ \partial \mathbb{b}}  = \frac{ \partial L }{ \partial \mathbb{y}} 
$$</p>
</li>
</ul>
<h3 id="relu-module">Relu module</h3>
<ul>
<li>forward_pass</li>
</ul>
<p>$$
y_{i} = \text{max}(0, x_{i})
$$</p>
<ul>
<li>backward_pass<ul>
<li>0 보다 크면 그냥 $y_{i}$</li>
<li>0 보다 작으면 0</li>
</ul>
</li>
</ul>
<p>$$
\frac{ \partial L }{ \partial x_{i}}  = (y_{i} &gt; 0)
$$</p>
<h3 id="softmax-module">Softmax module</h3>
<ul>
<li>forward_pass</li>
</ul>
<p>$$
y_{n} = \frac{e^{x_{n}}}{\sum_{m}e^{x_{m}}}
$$</p>
<ul>
<li>
<p>jacobian elements
$$
\frac{ \partial y_{i} }{ \partial x_{j}} = 
\frac{ \partial }{ \partial x_{j}} \left( \frac{e^{x_{i}}}{\sum_{m}e^{x_{m}}} \right) = 
\frac{ \delta_{ij} e^{x_{i}} }{ \sum_{m}e^{x_{m}} } - 
\frac{ e^{x_{i}} e^{x_{j}} }{ (\sum_{m} e^{x_{m}})^{2} } = 
y_{i} (\delta_{ij} - y_{j})
$$</p>
</li>
<li>
<p>backward_pass</p>
</li>
</ul>
<p>$$
\frac{ \partial L }{ \partial \mathbb{x}}  =  s - \sum_{i} s_{i} \text{; where} s_{i} = 
\frac{ \partial L }{ \partial y_{i}}  y_{i}
$$</p>
<h3 id="cross-entropy-loss-module">Cross-entropy loss module</h3>
<ul>
<li>forward_pass</li>
</ul>
<pre><code>y = L = Xent(p, x)
</code></pre>

<p>$$
y  = - \sum_{i}^{\text{classes:C}} p_{i}\text{log }x_{i}
$$</p>
<ul>
<li>backward_pass<ul>
<li>아래의 식에서 $x_{i}$가 너무 작으면 소수점 관련 이슈가 발생 될 수 있다.
$$
\frac{ \partial L }{ \partial x_{i}}  =  - \frac{ p_{i}}{ x_{i}}
$$</li>
</ul>
</li>
</ul>
<h3 id="cross-entropy-softmax-loss-module">Cross-entropy + softmax loss module</h3>
<ul>
<li>위의 소수점 이슈 때문에 복합 로스 함수를 사용한다.</li>
<li>forward_pass</li>
</ul>
<pre><code>y = L = XentLogits(p, x)
</code></pre>

<p>$$
y  = - \sum_{i}^{\text{classes:C}} p_{i}\text{log } \left( \frac{e^{x_{i}}}{\sum_{m}e^{x_{m}}} \right) 
$$</p>
<ul>
<li>backward_pass</li>
</ul>
<p>$$
\frac{ \partial L }{ \partial \mathbb{x}}   =  \mathbb{y} - \mathbb{p}
$$</p>
<h1 id="module-zoo">Module Zoo</h1>
<h2 id="elementwise-ops">Elementwise ops</h2>
<h3 id="add">Add</h3>
<ul>
<li>forward_pass: $ y  = a + b $</li>
<li>backward_pass: $ \frac{ \partial L }{ \partial a}  = \frac{ \partial L }{ \partial y} $</li>
</ul>
<h3 id="multiply">Multiply</h3>
<ul>
<li>forward_pass: $ y  = a \odot b $</li>
<li>backward_pass: $ \frac{ \partial L }{ \partial a}  = b \odot \frac{ \partial L }{ \partial y} $</li>
</ul>
<h2 id="groupwise-ops">Groupwise ops</h2>
<h3 id="sum">Sum:</h3>
<ul>
<li>forward_pass: $ y  = \sum x_{i} $</li>
<li>backward_pass: $ \frac{ \partial L }{ \partial x}  = \frac{ \partial L }{ \partial y} 1^{T} $</li>
</ul>
<h3 id="max">Max:</h3>
<ul>
<li>forward_pass: $ y  = max_{i} \{ x_{i} \} $</li>
<li>backward_pass: $ \frac{ \partial L }{ \partial x}  = \frac{ \partial L }{ \partial y} $ if i was maximal, 0 otherwise</li>
</ul>
<h3 id="switchconditional">Switch/Conditional:</h3>
<ul>
<li>활성된 branch 를 one-hot vector 인코딩 s 벡터로 표현</li>
<li>forward_pass: $ y  = \mathbb{s} \odot \mathbb{x} $</li>
<li>backward_pass: $ \frac{ \partial L }{ \partial \mathbb{x}}  = \frac{ \partial L }{ \partial \mathbb{y}} \odot \mathbb{s}^{T} $ </li>
</ul>
<h2 id="loss-ops">Loss ops</h2>
<h3 id="squared-error-mse">Squared Error (MSE)</h3>
<ul>
<li>forward_pass: $ L  = y = ||\mathbb{t} - \mathbb{x}||^{2} = \sum_{j}(t_{j} - x_{j})^{2}$</li>
<li>backward_pass: $ \frac{ \partial L }{ \partial \mathbb{x}}  = -2(\mathbb{t} - \mathbb{x})^{T} $ </li>
</ul>
<h2 id="activation-functions">Activation functions</h2>
<h3 id="tanh">tanh</h3>
<p>sigomoid 를 0.0 으로 내리고 조금 y 축에 가깝게 세운정도.</p>
<p><img alt="tanh" src="../img/3_tanh.svg" /></p>
<h3 id="leaky-relu">Leaky relu</h3>
<p>input 이 음수일때 경사도가 0 이 되는걸 처리 하기 위해</p>
<p><img alt="Leaky relu" src="../img/3_leaky_relu.svg" /></p>
<h1 id="practical-tips">Practical tips</h1>
<h3 id="overfitting-regularization">Overfitting &amp; regularization</h3>
<ul>
<li>Weight decay</li>
<li>Dropout</li>
<li>Data augmentation</li>
</ul>
<h3 id="_10">좋은 초기값 설정을 위해</h3>
<ul>
<li>Scaling schemas</li>
<li>Batch-norm</li>
</ul>
<h3 id="hyper-parameter-optimization-architecture-design">Hyper-parameter optimization &amp; architecture design</h3>
<ul>
<li>d &gt; 1 일 경우 그리드 탐색보다 랜덤 탐색을 더 추천 한다.</li>
</ul>
<h3 id="a-few-tips-for-diagnosingdebugging">A few tips for diagnosing/debugging</h3>
<ul>
<li>Check for dead units</li>
<li>Be aware of vanishing/exploding gradients.</li>
<li>Try to overfit on a very small subset of data or a very simple version of your task.</li>
</ul>
<h2 id="overfitting-regularization_1">Overfitting &amp; regularization</h2>
<p>트레인 데이터에는 좋은 점수를 받는대 테스트 데이터 에서는 나쁜 점수를 받을 경우.</p>
<ul>
<li>Early stopping</li>
<li>Weight decay<ul>
<li>weight 가 너무 커지지 않게 조절 하는것</li>
<li>sigmoid/than/softmax 같은 경우 linear region 에 가깝게 머물게 하는것.<ul>
<li>변환이 선형에 가깝게 되게 유도 함으로 함수의 복잡도가 떨어트려 regularization 한다.</li>
</ul>
</li>
<li>relu 에는 별 효과 없음</li>
</ul>
</li>
<li>Noise addition $\to$ dropout<ul>
<li>트래인 하는 도중에 noise 를 더해준다.<ul>
<li>피쳐의 특정 값 또는 결합 값들에 지나치게 의존 하는걸 방지</li>
<li>간단한 방식의 앙상블 방법이라고 볼 수도 있다.</li>
</ul>
</li>
<li>Dropout<ul>
<li>Training: 랜덤하게 특정 레이어의 부분들을 0으로 설정.</li>
<li>Testing: 모든 유닛을 사용하나, 일정 부분을 0으로 변하게 하는 정도를 변경 하거나.<ul>
<li>랜덤하게 0 으로 세팅할 부분의 정도를 변환 시켜 여러번 실행 한다.(앙상블)</li>
</ul>
</li>
<li>Batch-norm 때문에 요즘은 많이 사용하지 않음.</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="the-importance-of-good-initialization">The importance of good initialization</h2>
<ul>
<li>최초 초기값은 작아야 한다. 하지만 분포에 따라 얼마나 작아야 하는지는 측정해야 한다.<ul>
<li>얼마나 정보들이 잘 전달되는지 가 중요하다.<ul>
<li>Too big -&gt; exploid, Too small -&gt; vanish</li>
</ul>
</li>
</ul>
</li>
<li>여러 종류의 heuristic 있다.<ul>
<li>Xavier initialization</li>
<li>He initialization</li>
<li>LSUV</li>
</ul>
</li>
<li>Batch-norm (loffe &amp; Szegedy, 2015)<ul>
<li>엄청 중요함!</li>
<li>Scale and offset 이 적절한지 지속적으로 확인하자.<ul>
<li>각각의 레이어 별로 input 이 얼마나 비선형 적인지 확인하고 scale 과 offse 을 변경해 적절하게 만들어 주자.<ul>
<li>예를 들어 데이터의 통계를 사용해 선형 변환 뒤에 평균을 0 으로 하고 분산을 1로 하는 레이어를 네트워크에서 필요한 부분에 모두 더해준다. </li>
</ul>
</li>
</ul>
</li>
<li>초기값 설정 뿐만 아니라 트래이닝 중 에도 중요하다고 밝혀졌다.<ul>
<li>batch-norm 작업을 하면 자동으로 noise 가 더해지는 셈이 된다.</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="hyperparameter-search">Hyperparameter search</h2>
<p>어떻게 좋은 hyperparameter (learning rates, dropout-fractions, weight-decay, etc) 값을 찾을 것인가.</p>
<ul>
<li>많은 조합을 특정 데이터에 실험해서 가장 좋은 걸 뽑는게 기본 전략이다.<ul>
<li>하이퍼 파라미터가 많아진다면 다차원의 저주로 인해 탐색해야하는 값들의 조합이 거대해진다.</li>
<li>랜덤 서치가 그리드 서치보다 좋다.</li>
</ul>
</li>
<li>Meta-learning: 좋은 하이퍼파라미터를 찾는 알고리즘도 한창 개발 중.</li>
</ul>
<h2 id="simple-debugging-and-performance-diagnostics">Simple debugging and performance diagnostics</h2>
<ul>
<li>죽은 units 들을 체크해라.<ul>
<li>histogram/visualize gradient update over large minibatch</li>
</ul>
</li>
<li>Vanishing/exploding gradients 를 주의 해라.<ul>
<li>histogram/visualize gradient update over large minibatch</li>
<li>$10^{-3} * \text{paramter scale}$</li>
</ul>
</li>
<li>일단 아주 작은 일부 데이터센 또는 심플한 버전의 테스크에 overfit 시켜라.<ul>
<li>작은 데이터셋 또는 심플한 버전에서 우리의 모델을 training error 를 0으로 맞추어야 한다.</li>
</ul>
</li>
</ul>
<h1 id="reference">Reference</h1>
<ul>
<li><a href="https://www.youtube.com/watch?v=5eAXoPSBgnE&amp;t=1s">참조</a></li>
<li><a href="https://github.com/resoliwan/ML_Assignment">Assignment</a></li>
</ul></div>
            </div>
        </div>

        <footer class="col-md-12">
            <hr>
            <p>Documentation built with <a href="https://www.mkdocs.org/">MkDocs</a>.</p>
        </footer>
        <script>
            var base_url = "../..",
                shortcuts = {"help": 191, "next": 78, "previous": 80, "search": 83};
        </script>
        <script src="../../js/base.js" defer></script>
        <script src="../../js/mathjax_config.js" defer></script>
        <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML" defer></script>
        <script src="https://unpkg.com/mermaid@8.0.0/dist/mermaid.js" defer></script>
        <script src="../../search/main.js" defer></script>

        <div class="modal" id="mkdocs_search_modal" tabindex="-1" role="dialog" aria-labelledby="searchModalLabel" aria-hidden="true">
    <div class="modal-dialog modal-lg">
        <div class="modal-content">
            <div class="modal-header">
                <h4 class="modal-title" id="searchModalLabel">Search</h4>
                <button type="button" class="close" data-dismiss="modal"><span aria-hidden="true">&times;</span><span class="sr-only">Close</span></button>
            </div>
            <div class="modal-body">
                <p>
                    From here you can search these documents. Enter
                    your search terms below.
                </p>
                <form>
                    <div class="form-group">
                        <input type="text" class="form-control" placeholder="Search..." id="mkdocs-search-query" title="Type search term here">
                    </div>
                </form>
                <div id="mkdocs-search-results"></div>
            </div>
            <div class="modal-footer">
            </div>
        </div>
    </div>
</div><div class="modal" id="mkdocs_keyboard_modal" tabindex="-1" role="dialog" aria-labelledby="keyboardModalLabel" aria-hidden="true">
    <div class="modal-dialog">
        <div class="modal-content">
            <div class="modal-header">
                <h4 class="modal-title" id="keyboardModalLabel">Keyboard Shortcuts</h4>
                <button type="button" class="close" data-dismiss="modal"><span aria-hidden="true">&times;</span><span class="sr-only">Close</span></button>
            </div>
            <div class="modal-body">
              <table class="table">
                <thead>
                  <tr>
                    <th style="width: 20%;">Keys</th>
                    <th>Action</th>
                  </tr>
                </thead>
                <tbody>
                  <tr>
                    <td class="help shortcut"><kbd>?</kbd></td>
                    <td>Open this help</td>
                  </tr>
                  <tr>
                    <td class="next shortcut"><kbd>n</kbd></td>
                    <td>Next page</td>
                  </tr>
                  <tr>
                    <td class="prev shortcut"><kbd>p</kbd></td>
                    <td>Previous page</td>
                  </tr>
                  <tr>
                    <td class="search shortcut"><kbd>s</kbd></td>
                    <td>Search</td>
                  </tr>
                </tbody>
              </table>
            </div>
            <div class="modal-footer">
            </div>
        </div>
    </div>
</div>

    </body>
</html>
